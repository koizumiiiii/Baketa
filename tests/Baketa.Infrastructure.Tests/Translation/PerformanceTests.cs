using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Threading.Tasks;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece.Native;
using FluentAssertions;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Logging.Abstractions;
using Xunit;
using Xunit.Abstractions;

namespace Baketa.Infrastructure.Tests.Translation;

/// <summary>
/// OPUS-MT Native Tokenizer ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
/// å¤§é‡ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã§ã®æ€§èƒ½æ¸¬å®šã¨æœ€é©åŒ–ãƒã‚¤ãƒ³ãƒˆç‰¹å®š
/// </summary>
public class PerformanceTests(ITestOutputHelper output) : IDisposable
{
    private readonly string _projectRoot = GetProjectRootDirectory();
    private bool _disposed;

    [Fact]
    public async Task OpusMtNativeTokenizer_BulkProcessing_ShouldMeetPerformanceRequirements()
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        // å¤§é‡ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆå®Ÿéš›ã®ã‚²ãƒ¼ãƒ ç’°å¢ƒã‚’æ¨¡æ“¬ï¼‰
        var testTexts = GenerateGameTextDataset(1000); // 1000ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
        output.WriteLine($"ğŸš€ Bulk processing performance test");
        output.WriteLine($"ğŸ“Š Dataset size: {testTexts.Count:N0} texts");
        output.WriteLine($"ğŸ“‚ Model: {Path.GetFileName(modelPath)}");

        using var tokenizer = await OpusMtNativeTokenizer.CreateAsync(modelPath);
        
        // Warm-up run (JITæœ€é©åŒ–)
        output.WriteLine($"ğŸ”¥ Warm-up run...");
        for (int i = 0; i < Math.Min(10, testTexts.Count); i++)
        {
            tokenizer.Tokenize(testTexts[i]);
        }

        // Act - æ€§èƒ½æ¸¬å®š
        var stopwatch = Stopwatch.StartNew();
        var results = new List<PerformanceResult>();
        
        foreach (var text in testTexts)
        {
            var textStopwatch = Stopwatch.StartNew();
            
            var tokens = tokenizer.Tokenize(text);
            var decoded = tokenizer.Decode(tokens);
            
            textStopwatch.Stop();
            
            results.Add(new PerformanceResult
            {
                Text = text,
                TextLength = text.Length,
                TokenCount = tokens.Length,
                ProcessingTimeMs = textStopwatch.Elapsed.TotalMilliseconds,
                TokensPerSecond = tokens.Length / Math.Max(textStopwatch.Elapsed.TotalSeconds, 0.001)
            });
        }
        
        stopwatch.Stop();

        // Assert & Analysis
        var totalTime = stopwatch.Elapsed.TotalMilliseconds;
        var avgTimePerText = totalTime / testTexts.Count;
        var textsPerSecond = testTexts.Count / stopwatch.Elapsed.TotalSeconds;
        var totalTokens = results.Sum(r => r.TokenCount);
        var tokensPerSecond = totalTokens / stopwatch.Elapsed.TotalSeconds;

        output.WriteLine($"\nğŸ“ˆ Performance Results:");
        output.WriteLine($"  Total processing time: {totalTime:F2} ms");
        output.WriteLine($"  Average time per text: {avgTimePerText:F3} ms");
        output.WriteLine($"  Texts per second: {textsPerSecond:F1}");
        output.WriteLine($"  Total tokens processed: {totalTokens:N0}");
        output.WriteLine($"  Tokens per second: {tokensPerSecond:F0}");

        // Performance requirements
        avgTimePerText.Should().BeLessThan(10.0, "Average processing time should be under 10ms per text");
        textsPerSecond.Should().BeGreaterThan(100, "Should process at least 100 texts per second");
        tokensPerSecond.Should().BeGreaterThan(1000, "Should process at least 1000 tokens per second");

        // Detailed analysis
        AnalyzePerformanceCharacteristics(results);
    }

    [Theory]
    [InlineData(100)]
    [InlineData(500)]
    [InlineData(1000)]
    [InlineData(2000)]
    public async Task OpusMtNativeTokenizer_ScalabilityTest_ShouldScaleLinearly(int textCount)
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        var testTexts = GenerateGameTextDataset(textCount);
        
        output.WriteLine($"ğŸ“Š Scalability test: {textCount:N0} texts");

        using var tokenizer = await OpusMtNativeTokenizer.CreateAsync(modelPath);

        // Act
        var stopwatch = Stopwatch.StartNew();
        
        foreach (var text in testTexts)
        {
            tokenizer.Tokenize(text);
        }
        
        stopwatch.Stop();

        // Assert
        var totalTime = stopwatch.Elapsed.TotalMilliseconds;
        var avgTimePerText = totalTime / textCount;
        var textsPerSecond = textCount / stopwatch.Elapsed.TotalSeconds;

        output.WriteLine($"  Total time: {totalTime:F2} ms");
        output.WriteLine($"  Avg per text: {avgTimePerText:F3} ms");
        output.WriteLine($"  Texts/sec: {textsPerSecond:F1}");

        // Scalability assertions
        avgTimePerText.Should().BeLessThan(5.0, $"Average time should remain low even with {textCount} texts");
        textsPerSecond.Should().BeGreaterThan(200, $"Throughput should remain high with {textCount} texts");
    }

    [Fact]
    public async Task OpusMtNativeTokenizer_MemoryUsage_ShouldRemainStable()
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        var testTexts = GenerateGameTextDataset(500);
        
        output.WriteLine($"ğŸ§  Memory usage stability test");

        using var tokenizer = await OpusMtNativeTokenizer.CreateAsync(modelPath);

        // Measure memory before processing
        GC.Collect();
        GC.WaitForPendingFinalizers();
        GC.Collect();
        
        var initialMemory = GC.GetTotalMemory(false);
        output.WriteLine($"  Initial memory: {initialMemory / 1024 / 1024:F2} MB");

        // Act - Process texts multiple times
        for (int iteration = 0; iteration < 5; iteration++)
        {
            foreach (var text in testTexts)
            {
                var tokens = tokenizer.Tokenize(text);
                var decoded = tokenizer.Decode(tokens);
            }
            
            var currentMemory = GC.GetTotalMemory(false);
            output.WriteLine($"  After iteration {iteration + 1}: {currentMemory / 1024 / 1024:F2} MB");
        }

        // Force garbage collection and measure final memory
        GC.Collect();
        GC.WaitForPendingFinalizers();
        GC.Collect();
        
        var finalMemory = GC.GetTotalMemory(false);
        var memoryIncrease = finalMemory - initialMemory;
        
        output.WriteLine($"  Final memory: {finalMemory / 1024 / 1024:F2} MB");
        output.WriteLine($"  Memory increase: {memoryIncrease / 1024 / 1024:F2} MB");

        // Assert
        memoryIncrease.Should().BeLessThan(50 * 1024 * 1024, "Memory increase should be less than 50MB");
    }

    [Fact]
    public async Task OpusMtNativeTokenizer_ConcurrentAccess_ShouldBeThreadSafe()
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        var testTexts = GenerateGameTextDataset(100);
        
        output.WriteLine($"ğŸ”„ Concurrent access test");

        using var tokenizer = await OpusMtNativeTokenizer.CreateAsync(modelPath);

        // Act - Concurrent processing
        var tasks = Enumerable.Range(0, 10).Select(async threadId =>
        {
            await Task.Yield(); // éåŒæœŸå‡¦ç†ã‚’è¿½åŠ 
            
            var threadStopwatch = Stopwatch.StartNew();
            var results = new List<int[]>();
            
            foreach (var text in testTexts)
            {
                var tokens = tokenizer.Tokenize(text);
                results.Add(tokens);
            }
            
            threadStopwatch.Stop();
            
            return new
            {
                ThreadId = threadId,
                ProcessingTime = threadStopwatch.Elapsed.TotalMilliseconds,
                Results = results
            };
        }).ToArray();

        var allResults = await Task.WhenAll(tasks);

        // Assert
        allResults.Should().HaveCount(10, "All threads should complete successfully");
        
        foreach (var result in allResults)
        {
            result.Results.Should().HaveCount(testTexts.Count, $"Thread {result.ThreadId} should process all texts");
            result.ProcessingTime.Should().BeLessThan(5000, $"Thread {result.ThreadId} should complete within 5 seconds");
            
            output.WriteLine($"  Thread {result.ThreadId}: {result.ProcessingTime:F2} ms");
        }

        // Verify consistency
        var firstThreadResults = allResults[0].Results;
        foreach (var otherResult in allResults.Skip(1))
        {
            for (int i = 0; i < firstThreadResults.Count; i++)
            {
                otherResult.Results[i].Should().BeEquivalentTo(firstThreadResults[i], 
                    $"Results should be consistent across threads for text {i}");
            }
        }
        
        output.WriteLine($"âœ… All threads produced consistent results");
    }

    [Fact]
    public void RealSentencePieceTokenizer_PerformanceComparison_WithNativeTokenizer()
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        var testTexts = GenerateGameTextDataset(100).Take(50).ToList(); // å°ã•ã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        var logger = NullLogger<RealSentencePieceTokenizer>.Instance;
        
        output.WriteLine($"âš–ï¸  Performance comparison: Real vs Native");

        using var realTokenizer = new RealSentencePieceTokenizer(modelPath, logger);

        // Measure RealSentencePieceTokenizer performance
        var realStopwatch = Stopwatch.StartNew();
        foreach (var text in testTexts)
        {
            realTokenizer.Tokenize(text);
        }
        realStopwatch.Stop();

        var realTime = realStopwatch.Elapsed.TotalMilliseconds;
        var realTextsPerSecond = testTexts.Count / realStopwatch.Elapsed.TotalSeconds;

        output.WriteLine($"  RealSentencePieceTokenizer:");
        output.WriteLine($"    Total time: {realTime:F2} ms");
        output.WriteLine($"    Texts/sec: {realTextsPerSecond:F1}");

        // Performance should be reasonable even with fallback implementation
        realTime.Should().BeLessThan(1000, "RealSentencePieceTokenizer should complete within 1 second");
        realTextsPerSecond.Should().BeGreaterThan(50, "Should process at least 50 texts per second");
    }

    private List<string> GenerateGameTextDataset(int count)
    {
        var gameTexts = new[]
        {
            // çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆ
            "HPå›å¾©",
            "ãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—",
            "ã‚¢ã‚¤ãƒ†ãƒ å…¥æ‰‹",
            "æˆ¦é—˜é–‹å§‹",
            "ãƒŸãƒƒã‚·ãƒ§ãƒ³å®Œäº†",
            "ã‚»ãƒ¼ãƒ–ã—ã¾ã—ãŸ",
            
            // ä¸­ç¨‹åº¦ã®ãƒ†ã‚­ã‚¹ãƒˆ
            "ã“ã‚“ã«ã¡ã¯ã€å†’é™ºè€…ã‚ˆï¼",
            "æ–°ã—ã„ã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚",
            "ã‚ãªãŸã®ãƒ¬ãƒ™ãƒ«ãŒä¸ŠãŒã‚Šã¾ã—ãŸï¼",
            "ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªã«è¿½åŠ ã—ã¾ã—ãŸã€‚",
            "ã“ã®è¡—ã¸ã‚ˆã†ã“ãï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            "å±é™ºãªæ•µãŒè¿‘ã¥ã„ã¦ã„ã¾ã™ã€‚æˆ¦é—˜ã®æº–å‚™ã‚’ã—ã¦ãã ã•ã„ã€‚",
            
            // é•·ã„ãƒ†ã‚­ã‚¹ãƒˆ
            "é ã„æ˜”ã€ã“ã®å¤§é™¸ã«ã¯å¹³å’ŒãŒè¨ªã‚Œã¦ã„ã¾ã—ãŸã€‚ã—ã‹ã—ã€é—‡ã®å‹¢åŠ›ãŒå¾©æ´»ã—ã€ä¸–ç•Œã¯å†ã³æ··æ²Œã«åŒ…ã¾ã‚Œã‚ˆã†ã¨ã—ã¦ã„ã¾ã™ã€‚",
            "ã‚ãªãŸã¯é¸ã°ã‚Œã—å‹‡è€…ã¨ã—ã¦ã€ã“ã®ä¸–ç•Œã‚’æ•‘ã†ä½¿å‘½ã‚’è² ã£ã¦ã„ã¾ã™ã€‚é•·ã„æ—…ãŒå§‹ã¾ã‚Šã¾ã™ãŒã€ä»²é–“ãŸã¡ã¨å…±ã«ç«‹ã¡å‘ã‹ã„ã¾ã—ã‚‡ã†ã€‚",
            "å¤ä»£ã®é­”æ³•æ›¸ã«ã¯ã€å¤±ã‚ã‚ŒãŸæ–‡æ˜ã®ç§˜å¯†ãŒè¨˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®çŸ¥è­˜ã‚’ä½¿ã£ã¦ã€å¼·å¤§ãªæ•µã‚’æ‰“ã¡å€’ã™ã“ã¨ãŒã§ãã‚‹ã§ã—ã‚‡ã†ã€‚",
            "ã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Œäº†ã™ã‚‹ã¨ã€çµŒé¨“å€¤ã¨ã‚´ãƒ¼ãƒ«ãƒ‰ãŒç²å¾—ã§ãã¾ã™ã€‚ã¾ãŸã€ã¾ã‚Œã«å¼·åŠ›ãªè£…å‚™å“ã‚‚æ‰‹ã«å…¥ã‚Œã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚",
            
            // ç‰¹æ®Šæ–‡å­—ãƒ»è¨˜å·ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆ
            "HP: 100/100",
            "çµŒé¨“å€¤: 1,250 XP",
            "ã‚´ãƒ¼ãƒ«ãƒ‰: ï¿¥50,000",
            "æ”»æ’ƒåŠ›+25%ã‚¢ãƒƒãƒ—ï¼",
            "ãƒ¬ã‚¢è£…å‚™ã€ç¥å‰£ã‚¨ã‚¯ã‚¹ã‚«ãƒªãƒãƒ¼ã€‘ã‚’å…¥æ‰‹ã—ã¾ã—ãŸï¼",
            "ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ’ãƒƒãƒˆï¼ãƒ€ãƒ¡ãƒ¼ã‚¸Ã—2.5å€ï¼",
            
            // è‹±èªæ··ã˜ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆ
            "Newã‚²ãƒ¼ãƒ ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ",
            "Statusã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ãã¾ã—ãŸ",
            "Saveãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...",
            "Battle SystemãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ",
            "Quest Logã‚’ç¢ºèªã—ã¦ãã ã•ã„",
            "Game Overã§ã™ã€‚Continue ã—ã¾ã™ã‹ï¼Ÿ"
        };

        var random = new Random(42); // å›ºå®šã‚·ãƒ¼ãƒ‰ã§å†ç¾å¯èƒ½æ€§ã‚’ç¢ºä¿
        var result = new List<string>();
        
        for (int i = 0; i < count; i++)
        {
            // ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã€ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
            var baseText = gameTexts[random.Next(gameTexts.Length)];
            
            // 20%ã®ç¢ºç‡ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¹°ã‚Šè¿”ã—
            if (random.NextDouble() < 0.2)
            {
                var repeatCount = random.Next(2, 4);
                baseText = string.Join(" ", Enumerable.Repeat(baseText, repeatCount));
            }
            
            result.Add(baseText);
        }
        
        return result;
    }

    private void AnalyzePerformanceCharacteristics(List<PerformanceResult> results)
    {
        output.WriteLine($"\nğŸ” Performance Analysis:");
        
        // Text length vs processing time correlation
        var shortTexts = results.Where(r => r.TextLength <= 10).ToList();
        var mediumTexts = results.Where(r => r.TextLength > 10 && r.TextLength <= 50).ToList();
        var longTexts = results.Where(r => r.TextLength > 50).ToList();
        
        if (shortTexts.Count > 0)
        {
            var avgShortTime = shortTexts.Average(r => r.ProcessingTimeMs);
            output.WriteLine($"  Short texts (â‰¤10 chars): {avgShortTime:F3} ms avg");
        }
        
        if (mediumTexts.Count > 0)
        {
            var avgMediumTime = mediumTexts.Average(r => r.ProcessingTimeMs);
            output.WriteLine($"  Medium texts (11-50 chars): {avgMediumTime:F3} ms avg");
        }
        
        if (longTexts.Count > 0)
        {
            var avgLongTime = longTexts.Average(r => r.ProcessingTimeMs);
            output.WriteLine($"  Long texts (>50 chars): {avgLongTime:F3} ms avg");
        }

        // Token processing rate
        var avgTokensPerSecond = results.Average(r => r.TokensPerSecond);
        var maxTokensPerSecond = results.Max(r => r.TokensPerSecond);
        var minTokensPerSecond = results.Min(r => r.TokensPerSecond);
        
        output.WriteLine($"  Token processing rate:");
        output.WriteLine($"    Average: {avgTokensPerSecond:F0} tokens/sec");
        output.WriteLine($"    Max: {maxTokensPerSecond:F0} tokens/sec");
        output.WriteLine($"    Min: {minTokensPerSecond:F0} tokens/sec");

        // Identify potential bottlenecks
        var slowestTexts = results.OrderByDescending(r => r.ProcessingTimeMs).Take(5).ToList();
        if (slowestTexts.Count > 0)
        {
            output.WriteLine($"  Slowest processing times:");
            foreach (var slow in slowestTexts)
            {
                output.WriteLine($"    {slow.ProcessingTimeMs:F3} ms: \"{slow.Text[..Math.Min(50, slow.Text.Length)]}...\"");
            }
        }
    }

    private static string GetProjectRootDirectory()
    {
        var currentDir = Directory.GetCurrentDirectory();
        while (currentDir != null && !File.Exists(Path.Combine(currentDir, "Baketa.sln")))
        {
            currentDir = Directory.GetParent(currentDir)?.FullName;
        }
        return currentDir ?? throw new DirectoryNotFoundException("Project root not found");
    }

    public void Dispose()
    {
        if (_disposed)
            return;
            
        _disposed = true;
        GC.SuppressFinalize(this);
    }

    private sealed record PerformanceResult
    {
        public string Text { get; init; } = string.Empty;
        public int TextLength { get; init; }
        public int TokenCount { get; init; }
        public double ProcessingTimeMs { get; init; }
        public double TokensPerSecond { get; init; }
    }
}
