using System;
using System.IO;
using System.Threading.Tasks;
using Baketa.Core.Translation.Models;
using Baketa.Infrastructure.Translation.Local.Onnx;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece.Native;
using FluentAssertions;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using Xunit;
using Xunit.Abstractions;

namespace Baketa.Infrastructure.Tests.Translation;

/// <summary>
/// å®Ÿé‹ç”¨ç’°å¢ƒã§ã®OPUS-MT Native Tokenizerçµ±åˆãƒ†ã‚¹ãƒˆ
/// å®Ÿéš›ã®ç¿»è¨³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®å‹•ä½œç¢ºèª
/// </summary>
public class ProductionIntegrationTests : IDisposable
{
    private readonly ITestOutputHelper _output;
    private readonly string _projectRoot;
    private readonly ServiceProvider _serviceProvider;
    private bool _disposed;

    public ProductionIntegrationTests(ITestOutputHelper output)
    {
        _output = output;
        _projectRoot = GetProjectRootDirectory();
        
        // DI ã‚³ãƒ³ãƒ†ãƒŠã®è¨­å®š
        var services = new ServiceCollection();
        services.AddLogging(builder => builder.AddConsole().SetMinimumLevel(LogLevel.Information));
        _serviceProvider = services.BuildServiceProvider();
    }

    [Fact]
    public void OpusMtModelsDirectory_ShouldExist()
    {
        // Arrange
        var modelsDir = Path.Combine(_projectRoot, "Models", "SentencePiece");
        
        // Act & Assert
        Directory.Exists(modelsDir).Should().BeTrue($"Models directory should exist at: {modelsDir}");
        
        var modelFiles = Directory.GetFiles(modelsDir, "*.model");
        modelFiles.Should().NotBeEmpty("At least one OPUS-MT model file should exist");
        
        _output.WriteLine($"ğŸ“ Models directory: {modelsDir}");
        _output.WriteLine($"ğŸ” Found {modelFiles.Length} model files:");
        
        foreach (var file in modelFiles)
        {
            var fileInfo = new FileInfo(file);
            _output.WriteLine($"  âœ“ {Path.GetFileName(file)} ({fileInfo.Length:N0} bytes)");
        }
    }

    [Fact]
    public async Task OpusMtNativeTokenizer_ShouldWorkInProductionScenario()
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            _output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        var logger = _serviceProvider.GetRequiredService<ILogger<OpusMtNativeTokenizer>>();
        
        // å®Ÿéš›ã®ã‚²ãƒ¼ãƒ ã‹ã‚‰æŠ½å‡ºã•ã‚Œã‚‹ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«
        var testTexts = new[]
        {
            "ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œï¼",           // åŸºæœ¬çš„ãªæ—¥æœ¬èª
            "ãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ",         // ã‚²ãƒ¼ãƒ ç”¨èª
            "HPãŒå›å¾©ã—ã¾ã—ãŸ",           // è‹±èªæ··ã˜ã‚Š
            "ã‚¢ã‚¤ãƒ†ãƒ ã‚’å…¥æ‰‹ã—ã¾ã—ãŸ",       // ã‚«ã‚¿ã‚«ãƒŠ
            "æˆ¦é—˜é–‹å§‹",                  // çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆ
            "ã‚ãªãŸã®å†’é™ºãŒå§‹ã¾ã‚Šã¾ã™ã€‚æ–°ã—ã„ä¸–ç•Œã¸ã‚ˆã†ã“ãï¼" // é•·ã„ãƒ†ã‚­ã‚¹ãƒˆ
        };

        _output.WriteLine($"ğŸš€ Production scenario test with OPUS-MT Native Tokenizer");
        _output.WriteLine($"ğŸ“‚ Model: {Path.GetFileName(modelPath)}");

        // Act & Assert
        using var tokenizer = await OpusMtNativeTokenizer.CreateAsync(modelPath);
        
        tokenizer.Should().NotBeNull();
        tokenizer.IsInitialized.Should().BeTrue();
        
        _output.WriteLine($"âœ… Tokenizer initialized successfully");
        _output.WriteLine($"   VocabularySize: {tokenizer.VocabularySize:N0}");

        foreach (var text in testTexts)
        {
            try
            {
                var startTime = DateTime.UtcNow;
                
                // ãƒˆãƒ¼ã‚¯ãƒ³åŒ–å®Ÿè¡Œ
                var tokens = tokenizer.Tokenize(text);
                var decoded = tokenizer.Decode(tokens);
                
                var elapsed = DateTime.UtcNow - startTime;
                
                // åŸºæœ¬çš„ãªæ¤œè¨¼
                tokens.Should().NotBeNull();
                decoded.Should().NotBeNull();
                
                if (!string.IsNullOrEmpty(text))
                {
                    tokens.Length.Should().BeGreaterThan(0, "Non-empty text should produce tokens");
                }
                
                _output.WriteLine($"ğŸ§ª '{text}' â†’ [{string.Join(", ", tokens)}] ({elapsed.TotalMilliseconds:F2}ms)");
                _output.WriteLine($"   Decoded: '{decoded}'");
                
                // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèªï¼ˆ100msä»¥ä¸‹ãŒç›®æ¨™ï¼‰
                elapsed.TotalMilliseconds.Should().BeLessThan(100, 
                    $"Tokenization should be fast for production use: {text}");
                
            }
            catch (Exception ex)
            {
                _output.WriteLine($"âŒ Failed to process '{text}': {ex.Message}");
                throw;
            }
        }
    }

    [Fact]
    public void RealSentencePieceTokenizer_ShouldWorkWithFallback()
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            _output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        var logger = _serviceProvider.GetRequiredService<ILogger<RealSentencePieceTokenizer>>();
        var testText = "ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œï¼";
        
        _output.WriteLine($"ğŸ”§ Testing RealSentencePieceTokenizer fallback behavior");

        // Act
        using var tokenizer = new RealSentencePieceTokenizer(modelPath, logger);
        
        // Assert
        tokenizer.Should().NotBeNull();
        tokenizer.ModelPath.Should().Be(modelPath);
        
        var normalized = tokenizer.NormalizeText(testText);
        var tokens = tokenizer.Tokenize(testText);
        var decoded = tokenizer.Decode(tokens);
        
        normalized.Should().NotBeNullOrEmpty();
        tokens.Should().NotBeNull();
        decoded.Should().NotBeNull();
        
        _output.WriteLine($"ğŸ“ Input: '{testText}'");
        _output.WriteLine($"ğŸ”„ Normalized: '{normalized}'");
        _output.WriteLine($"ğŸ”¢ Tokens: [{string.Join(", ", tokens)}]");
        _output.WriteLine($"ğŸ“¤ Decoded: '{decoded}'");
        _output.WriteLine($"âœ… Fallback implementation working correctly");
        
        // SentencePieceæ­£è¦åŒ–ã®ç¢ºèª
        normalized.Should().StartWith("â–", "SentencePiece normalization should add prefix space symbol");
    }

    [Fact]
    public void SentencePieceTokenizerFactory_ShouldCreateCorrectImplementation()
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            _output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        using var loggerFactory = LoggerFactory.Create(builder => builder.AddConsole());
        
        _output.WriteLine($"ğŸ­ Testing SentencePieceTokenizerFactory in production scenario");

        // Act
        var nativeTokenizer = SentencePieceTokenizerFactory.Create(
            modelPath, "production-test-native", loggerFactory, useNative: true);
        
        var fallbackTokenizer = SentencePieceTokenizerFactory.Create(
            modelPath, "production-test-fallback", loggerFactory, useTemporary: true);

        // Assert
        nativeTokenizer.Should().NotBeNull();
        fallbackTokenizer.Should().NotBeNull();
        
        nativeTokenizer.Should().BeAssignableTo<ITokenizer>();
        fallbackTokenizer.Should().BeAssignableTo<ITokenizer>();
        
        _output.WriteLine($"âœ… Native tokenizer type: {nativeTokenizer.GetType().Name}");
        _output.WriteLine($"âœ… Fallback tokenizer type: {fallbackTokenizer.GetType().Name}");
        
        // ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆã§ã®å‹•ä½œç¢ºèª
        var testText = "ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ";
        
        var nativeTokens = nativeTokenizer.Tokenize(testText);
        nativeTokens.Should().NotBeNull();
        
        _output.WriteLine($"ğŸ“ Test text: '{testText}'");
        _output.WriteLine($"ğŸ”¢ Native tokens: [{string.Join(", ", nativeTokens)}]");
        
        // Fallback tokenizer (TemporarySentencePieceTokenizer) ã¯åˆæœŸåŒ–ãŒå¿…è¦
        try
        {
            var fallbackTokens = fallbackTokenizer.Tokenize(testText);
            fallbackTokens.Should().NotBeNull();
            _output.WriteLine($"ğŸ”¢ Fallback tokens: [{string.Join(", ", fallbackTokens)}]");
        }
        catch (InvalidOperationException ex) when (ex.Message.Contains("åˆæœŸåŒ–"))
        {
            _output.WriteLine($"âš ï¸  Fallback tokenizer requires initialization: {ex.Message}");
            _output.WriteLine($"â„¹ï¸  This is expected behavior for TemporarySentencePieceTokenizer");
        }
        
        // Cleanup
        if (nativeTokenizer is IDisposable nativeDisposable)
            nativeDisposable.Dispose();
        if (fallbackTokenizer is IDisposable fallbackDisposable)
            fallbackDisposable.Dispose();
    }

    [Theory]
    [InlineData("")]
    [InlineData("ã“ã‚“ã«ã¡ã¯")]
    [InlineData("Hello, World!")]
    [InlineData("éå¸¸ã«é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã®ä¾‹ã¨ã—ã¦ã€ã“ã®æ–‡ç« ã‚’ä½¿ç”¨ã—ã¦å®Ÿéš›ã®ã‚²ãƒ¼ãƒ ç’°å¢ƒã§ã‚ˆãè¦‹ã‚‰ã‚Œã‚‹ã‚ˆã†ãªçŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¾ã™ã€‚")]
    public async Task OpusMtNativeTokenizer_ShouldHandleEdgeCases(string input)
    {
        // Arrange
        var modelPath = Path.Combine(_projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            _output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        _output.WriteLine($"ğŸ§ª Edge case test: '{input}' (length: {input.Length})");

        // Act & Assert
        using var tokenizer = await OpusMtNativeTokenizer.CreateAsync(modelPath);
        
        var action = () =>
        {
            var tokens = tokenizer.Tokenize(input);
            var decoded = tokenizer.Decode(tokens);
            return (tokens, decoded);
        };
        
        action.Should().NotThrow("Tokenizer should handle edge cases gracefully");
        
        var (tokens, decoded) = action();
        
        tokens.Should().NotBeNull();
        decoded.Should().NotBeNull();
        
        _output.WriteLine($"ğŸ”¢ Tokens: [{string.Join(", ", tokens)}] (count: {tokens.Length})");
        _output.WriteLine($"ğŸ“¤ Decoded: '{decoded}'");
        _output.WriteLine($"âœ… Edge case handled successfully");
    }

    private static string GetProjectRootDirectory()
    {
        var currentDir = Directory.GetCurrentDirectory();
        while (currentDir != null && !File.Exists(Path.Combine(currentDir, "Baketa.sln")))
        {
            currentDir = Directory.GetParent(currentDir)?.FullName;
        }
        return currentDir ?? throw new DirectoryNotFoundException("Project root not found");
    }

    public void Dispose()
    {
        if (_disposed)
            return;
            
        _serviceProvider?.Dispose();
        _disposed = true;
        GC.SuppressFinalize(this);
    }
}