using System;
using System.IO;
using System.Threading.Tasks;
using Baketa.Core.Translation.Models;
using Baketa.Infrastructure.Translation.Local.Onnx;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece.Native;
using FluentAssertions;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Logging.Abstractions;
using Xunit;
using Xunit.Abstractions;

namespace Baketa.Infrastructure.Tests.Translation.Local.Onnx.SentencePiece.Native;

/// <summary>
/// Native Tokenizerçµ±åˆç¿»è¨³ãƒ†ã‚¹ãƒˆ
/// å®Ÿéš›ã®OPUS-MTã‚¨ãƒ³ã‚¸ãƒ³ã§ã®ç¿»è¨³å‹•ä½œã‚’æ¤œè¨¼
/// </summary>
public class TranslationIntegrationTests(ITestOutputHelper output)
{
    [Fact]
    public async Task AlphaOpusMtTranslationEngine_WithNativeTokenizer_ShouldTranslateCorrectly()
    {
        // Arrange
        var projectRoot = GetProjectRootDirectory();
        var modelPath = Path.Combine(projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        var onnxModelPath = Path.Combine(projectRoot, "Models", "ONNX", "opus-mt-ja-en.onnx");
        
        if (!File.Exists(modelPath))
        {
            output.WriteLine($"âš ï¸  Skipping test: Tokenizer model not found at {modelPath}");
            return;
        }
        
        if (!File.Exists(onnxModelPath))
        {
            output.WriteLine($"âš ï¸  Skipping test: ONNX model not found at {onnxModelPath}");
            return;
        }

        using var loggerFactory = LoggerFactory.Create(builder => 
            builder.AddConsole().SetMinimumLevel(LogLevel.Debug));
        var logger = loggerFactory.CreateLogger<AlphaOpusMtTranslationEngine>();

        // ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
        var options = new AlphaOpusMtOptions
        {
            MaxSequenceLength = 512
        };

        var languagePair = new LanguagePair
        {
            SourceLanguage = Language.Japanese,
            TargetLanguage = Language.English
        };

        // Act - AlphaOpusMtTranslationEngineã‚’ä½œæˆ
        var engine = new AlphaOpusMtTranslationEngine(
            onnxModelPath, 
            modelPath, 
            languagePair, 
            options, 
            logger);

        var testTexts = new[]
        {
            "ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œï¼",
            "ã“ã‚Œã¯ç¿»è¨³ãƒ†ã‚¹ãƒˆã§ã™ã€‚",
            "æ—¥æœ¬èªã‹ã‚‰è‹±èªã¸ã®ç¿»è¨³"
        };

        output.WriteLine("ğŸ”„ Translation Integration Test");
        output.WriteLine($"ğŸ“‚ ONNX Model: {Path.GetFileName(onnxModelPath)}");
        output.WriteLine($"ğŸ“‚ Tokenizer: {Path.GetFileName(modelPath)}");
        output.WriteLine("");

        foreach (var text in testTexts)
        {
            try
            {
                output.WriteLine($"ğŸ“ Input: '{text}'");
                
                var request = new TranslationRequest
                {
                    SourceText = text,
                    SourceLanguage = Language.Japanese,
                    TargetLanguage = Language.English
                };
                
                var response = await engine.TranslateAsync(request);
                var result = response.TranslatedText ?? string.Empty;
                
                output.WriteLine($"âœ… Output: '{result}'");
                output.WriteLine($"ğŸ” Output Type: {(result.StartsWith("tok_", StringComparison.Ordinal) ? "Token Format" : "Actual Translation")}");
                
                // Assert
                result.Should().NotBeNull();
                result.Should().NotBeEmpty();
                
                // Native TokenizerãŒå‹•ä½œã—ã¦ã„ã‚Œã°ã€tok_XXXXã§ã¯ãªã„çµæœãŒæœŸå¾…ã•ã‚Œã‚‹
                if (!result.StartsWith("tok_", StringComparison.Ordinal))
                {
                    output.WriteLine("ğŸ‰ Native Tokenizer working - actual translation generated!");
                }
                else
                {
                    output.WriteLine("âš ï¸  Still generating token format - needs investigation");
                }
                
                output.WriteLine("");
            }
            catch (Exception ex)
            {
                output.WriteLine($"âŒ Error: {ex.Message}");
                output.WriteLine($"ğŸ“‹ Stack: {ex.StackTrace}");
                throw;
            }
        }

        engine.Dispose();
    }

    [Fact]
    public async Task NativeTokenizer_DirectTest_ShouldGenerateActualText()
    {
        // Arrange
        var projectRoot = GetProjectRootDirectory();
        var modelPath = Path.Combine(projectRoot, "Models", "SentencePiece", "opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            output.WriteLine($"âš ï¸  Skipping test: Model file not found at {modelPath}");
            return;
        }

        // Act - Native Tokenizerã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
        using var tokenizer = await OpusMtNativeTokenizer.CreateAsync(modelPath);
        
        var testText = "ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œï¼";
        var tokens = tokenizer.Tokenize(testText);
        var decoded = tokenizer.Decode(tokens);
        
        output.WriteLine("ğŸ” Native Tokenizer Direct Test");
        output.WriteLine($"ğŸ“ Input: '{testText}'");
        output.WriteLine($"ğŸ”¢ Tokens: [{string.Join(", ", tokens)}]");
        output.WriteLine($"âœ… Decoded: '{decoded}'");
        
        // Assert
        tokens.Should().NotBeEmpty();
        decoded.Should().NotBeNull();
        decoded.Should().NotStartWith("tok_");
        
        // å®Ÿéš›ã®æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        decoded.Should().Contain("ã“ã‚“ã«ã¡ã¯");
    }
    
    private static string GetProjectRootDirectory()
    {
        var currentDir = Directory.GetCurrentDirectory();
        while (currentDir != null && !File.Exists(Path.Combine(currentDir, "Baketa.sln")))
        {
            currentDir = Directory.GetParent(currentDir)?.FullName;
        }
        return currentDir ?? throw new DirectoryNotFoundException("Project root not found");
    }
}