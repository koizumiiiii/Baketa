using System;
using System.IO;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece.Native;
using Microsoft.Extensions.Logging.Abstractions;
using Xunit;
using Xunit.Abstractions;

namespace Baketa.Infrastructure.Tests.Translation.Local.Onnx.SentencePiece.Native;

/// <summary>
/// Native Tokenizer„ÅÆ„Éá„Éê„ÉÉ„Ç∞„ÉÜ„Çπ„Éà
/// </summary>
public class NativeTokenizerDebugTests(ITestOutputHelper output)
{
    [Fact]
    public void Debug_NativeTokenizer_BasicOperation()
    {
        // Arrange
        var projectRoot = GetProjectRootDirectory();
        var modelPath = Path.Combine(projectRoot, "Models", "SentencePiece", "helsinki-opus-mt-ja-en.model");
        
        if (!File.Exists(modelPath))
        {
            output.WriteLine($"‚ö†Ô∏è  Skipping test: Model not found at {modelPath}");
            return;
        }

        output.WriteLine($"üìÇ Model path: {modelPath}");
        output.WriteLine($"üìÅ Model exists: {File.Exists(modelPath)}");
        output.WriteLine($"üìÑ Model size: {new FileInfo(modelPath).Length / 1024} KB");

        try
        {
            // Act - Native TokenizerÂàùÊúüÂåñ
            using var tokenizer = new OpusMtNativeTokenizer(modelPath);
            
            output.WriteLine($"‚úÖ Tokenizer initialized successfully");
            output.WriteLine($"üîß Tokenizer ID: {tokenizer.TokenizerId}");

            // „ÉÜ„Çπ„Éà„ÉÜ„Ç≠„Çπ„Éà
            var testTexts = new[]
            {
                "hello",
                "„Åì„Çì„Å´„Å°„ÅØ",
                "hello world",
                "„Åì„Çå„ÅØ",
                "a"
            };

            foreach (var text in testTexts)
            {
                output.WriteLine($"üìù Testing: '{text}'");
                
                try
                {
                    var tokens = tokenizer.Tokenize(text);
                    output.WriteLine($"   ‚úÖ Tokens: [{string.Join(", ", tokens)}] (count: {tokens.Length})");
                    
                    if (tokens.Length > 0)
                    {
                        var decoded = tokenizer.Decode(tokens);
                        output.WriteLine($"   üîÑ Decoded: '{decoded}'");
                    }
                }
                catch (Exception ex)
                {
                    output.WriteLine($"   ‚ùå Error: {ex.Message}");
                }
                
                output.WriteLine("");
            }

            // ÁâπÊÆä„Éà„Éº„ÇØ„É≥IDÁ¢∫Ë™ç
            try
            {
                var bosId = tokenizer.GetSpecialTokenId("BOS");
                var eosId = tokenizer.GetSpecialTokenId("EOS");
                var unkId = tokenizer.GetSpecialTokenId("UNK");
                var padId = tokenizer.GetSpecialTokenId("PAD");
                
                output.WriteLine($"üéØ Special tokens: BOS={bosId}, EOS={eosId}, UNK={unkId}, PAD={padId}");
            }
            catch (Exception ex)
            {
                output.WriteLine($"‚ùå Special token error: {ex.Message}");
            }
        }
        catch (Exception ex)
        {
            output.WriteLine($"‚ùå Tokenizer initialization failed: {ex.Message}");
            output.WriteLine($"üìã Stack trace: {ex.StackTrace}");
            throw;
        }
    }
    
    private static string GetProjectRootDirectory()
    {
        var currentDir = Directory.GetCurrentDirectory();
        while (currentDir != null && !File.Exists(Path.Combine(currentDir, "Baketa.sln")))
        {
            currentDir = Directory.GetParent(currentDir)?.FullName;
        }
        return currentDir ?? throw new DirectoryNotFoundException("Project root not found");
    }
}