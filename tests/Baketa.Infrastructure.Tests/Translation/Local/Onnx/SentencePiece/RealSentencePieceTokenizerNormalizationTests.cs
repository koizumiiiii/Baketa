using System;
using System.IO;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece;
using FluentAssertions;
using Microsoft.Extensions.Logging;
using Moq;
using Xunit;
using Xunit.Abstractions;

namespace Baketa.Infrastructure.Tests.Translation.Local.Onnx.SentencePiece;

/// <summary>
/// RealSentencePieceTokenizerã®æ­£è¦åŒ–æ©Ÿèƒ½ã®å˜ä½“ãƒ†ã‚¹ãƒˆ
/// </summary>
public class RealSentencePieceTokenizerNormalizationTests : SentencePieceTestBase, IDisposable
{
    private readonly ITestOutputHelper _output;
    private readonly Mock<ILogger<RealSentencePieceTokenizer>> _mockLogger;
    private readonly string _tempModelPath;
    private bool _disposed;

    public RealSentencePieceTokenizerNormalizationTests(ITestOutputHelper output)
    {
        _output = output;
        _mockLogger = new Mock<ILogger<RealSentencePieceTokenizer>>();
        
        // ãƒ†ã‚¹ãƒˆç”¨ã®ä¸€æ™‚ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        _tempModelPath = Path.GetTempFileName();
        File.WriteAllBytes(_tempModelPath, [0x1A, 0x02, 0x08, 0x01]); // æœ€å°é™ã®Protobufãƒ˜ãƒƒãƒ€ãƒ¼
    }

    [Theory]
    [InlineData("hello", "â–hello")]
    [InlineData("Hello World", "â–Helloâ–World")]
    [InlineData("ã“ã‚“ã«ã¡ã¯", "â–ã“ã‚“ã«ã¡ã¯")]
    [InlineData("ã“ã‚“ã«ã¡ã¯ ä¸–ç•Œ", "â–ã“ã‚“ã«ã¡ã¯â–ä¸–ç•Œ")]
    public void NormalizeText_BasicTexts_ShouldAddPrefixSpaceSymbol(string input, string expected)
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.NormalizeText(input);

        // Assert
        result.Should().Be(expected);
        _output.WriteLine($"âœ“ Basic normalization: '{input}' -> '{result}'");
    }

    [Theory]
    [InlineData("ï½ˆï½…ï½Œï½Œï½", "â–hello")] // å…¨è§’è‹±å­— -> åŠè§’è‹±å­—
    [InlineData("ï¼‘ï¼’ï¼“", "â–123")] // å…¨è§’æ•°å­— -> åŠè§’æ•°å­—
    [InlineData("ï¼¨ï½…ï½Œï½Œï½ã€€ï¼·ï½ï½’ï½Œï½„", "â–Helloâ–World")] // å…¨è§’ç©ºç™½ -> åŠè§’ç©ºç™½
    public void NormalizeText_UnicodeCharacters_ShouldApplyNfkcNormalization(string input, string expected)
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.NormalizeText(input);

        // Assert
        result.Should().Be(expected);
        _output.WriteLine($"âœ“ NFKC normalization: '{input}' -> '{result}'");
    }

    [Theory]
    [InlineData("hello\tworld", "â–helloâ–world")] // ã‚¿ãƒ– -> ç©ºç™½
    [InlineData("hello\nworld", "â–helloâ–world")] // æ”¹è¡Œ -> ç©ºç™½
    [InlineData("hello\rworld", "â–helloâ–world")] // å¾©å¸°æ–‡å­— -> ç©ºç™½
    [InlineData("hello\u0000world", "â–helloworld")] // NULLæ–‡å­— -> é™¤å»
    public void NormalizeText_ControlCharacters_ShouldBeProcessedCorrectly(string input, string expected)
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.NormalizeText(input);

        // Assert
        result.Should().Be(expected);
        _output.WriteLine($"âœ“ Control char normalization: '{input.Replace("\u0000", "\\0")}' -> '{result}'");
    }

    [Theory(Skip = "OPUS-MTãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™ã€‚scripts/download_opus_mt_models.ps1ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")]
    [InlineData("hello   world", "â–helloâ–world")] // è¤‡æ•°ç©ºç™½ -> å˜ä¸€ç©ºç™½
    [InlineData("  hello  world  ", "â–helloâ–world")] // å‰å¾Œç©ºç™½ + è¤‡æ•°ç©ºç™½
    [InlineData("hello\u3000world", "â–helloâ–world")] // å…¨è§’ç©ºç™½ -> åŠè§’ç©ºç™½
    public void NormalizeText_WhitespaceCharacters_ShouldBeNormalized(string input, string expected)
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.NormalizeText(input);

        // Assert
        result.Should().Be(expected);
        _output.WriteLine($"âœ“ Whitespace normalization: '{input}' -> '{result}'");
    }

    [Fact]
    public void ValidateNormalization_WithoutParameters_ShouldReturnTrue()
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.ValidateNormalization();

        // Assert
        result.Should().BeTrue();
        _output.WriteLine("âœ“ Normalization validation (parameterless) passed");
    }

    [Theory]
    [InlineData("hello", "â–hello")]
    [InlineData("ï½ˆï½…ï½Œï½Œï½", "â–hello")]
    [InlineData("hello\tworld", "â–helloâ–world")]
    public void ValidateNormalization_WithParameters_ShouldValidateCorrectly(string input, string expected)
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.ValidateNormalization(input, expected);

        // Assert
        result.Should().BeTrue();
        _output.WriteLine($"âœ“ Normalization validation: '{input}' == '{expected}'");
    }

    [Fact]
    public void ValidateNormalization_WithIncorrectExpected_ShouldReturnFalse()
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.ValidateNormalization("hello", "wrong_result");

        // Assert
        result.Should().BeFalse();
        _output.WriteLine("âœ“ Normalization validation correctly failed for wrong expected result");
    }

    [Fact]
    public void Tokenize_WithNormalization_ShouldApplyNormalizationBeforeTokenizing()
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);
        const string input = "ï½ˆï½…ï½Œï½Œï½ã€€ï½—ï½ï½’ï½Œï½„"; // å…¨è§’æ–‡å­—

        // Act
        var tokens = tokenizer.Tokenize(input);

        // Assert
        tokens.Should().NotBeNull();
        tokens.Length.Should().BeGreaterThan(0);
        _output.WriteLine($"âœ“ Tokenization with normalization: '{input}' -> [{string.Join(", ", tokens)}]");
    }

    [Fact(Skip = "OPUS-MTãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™ã€‚scripts/download_opus_mt_models.ps1ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")]
    public void NormalizeText_ComplexRealWorldText_ShouldHandleCorrectly()
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);
        const string input = "ï¼¨ï½…ï½Œï½Œï½ï¼Œã€€ï½—ï½ï½’ï½Œï½„!\nã“ã‚“ã«ã¡ã¯\tä¸–ç•Œï¼";
        const string expected = "â–Hello,â–world!â–ã“ã‚“ã«ã¡ã¯â–ä¸–ç•Œï¼";

        // Act
        var result = tokenizer.NormalizeText(input);

        // Assert
        result.Should().Be(expected);
        _output.WriteLine($"âœ“ Complex text normalization: '{input}' -> '{result}'");
    }

    [Fact]
    public void NormalizeText_EmojisAndSpecialCharacters_ShouldPreserveCorrectly()
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);
        const string input = "Hello ğŸ˜€ World! ğŸŒ";
        const string expected = "â–Helloâ–ğŸ˜€â–World!â–ğŸŒ";

        // Act
        var result = tokenizer.NormalizeText(input);

        // Assert
        result.Should().Be(expected);
        _output.WriteLine($"âœ“ Emoji normalization: '{input}' -> '{result}'");
    }

    [Fact]
    public void UnknownTokenId_ShouldReturnValidId()
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var unknownId = tokenizer.UnknownTokenId;

        // Assert
        unknownId.Should().BeGreaterThanOrEqualTo(0);
        _output.WriteLine($"âœ“ Unknown token ID: {unknownId}");
    }

    [Fact]
    public void NormalizeText_EmptyString_ShouldReturnEmpty()
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.NormalizeText("");

        // Assert
        result.Should().Be("");
        _output.WriteLine("âœ“ Empty string normalization handled correctly");
    }

    [Fact]
    public void NormalizeText_NullString_ShouldReturnEmpty()
    {
        // Arrange
        using var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);

        // Act
        var result = tokenizer.NormalizeText(null!);

        // Assert
        result.Should().Be("");
        _output.WriteLine("âœ“ Null string normalization handled correctly");
    }

    [Fact]
    public void NormalizeText_AfterDispose_ShouldThrowObjectDisposedException()
    {
        // Arrange
        var tokenizer = new RealSentencePieceTokenizer(_tempModelPath, _mockLogger.Object);
        tokenizer.Dispose();

        // Act & Assert
        var action = () => tokenizer.NormalizeText("test");
        action.Should().Throw<ObjectDisposedException>();
        _output.WriteLine("âœ“ Disposed tokenizer correctly throws ObjectDisposedException");
    }

    public void Dispose()
    {
        if (_disposed)
            return;

        if (File.Exists(_tempModelPath))
        {
            try
            {
                File.Delete(_tempModelPath);
            }
            catch
            {
                // ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—ã¯ç„¡è¦–
            }
        }

        _disposed = true;
        GC.SuppressFinalize(this);
    }
}