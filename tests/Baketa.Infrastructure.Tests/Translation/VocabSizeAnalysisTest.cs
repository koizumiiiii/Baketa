using System;
using System.IO;
using System.Threading.Tasks;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece.Native;
using Microsoft.Extensions.Logging;
using Xunit;
using Xunit.Abstractions;

namespace Baketa.Infrastructure.Tests.Translation;

/// <summary>
/// å„SentencePieceãƒ¢ãƒ‡ãƒ«ã®èªå½™ã‚µã‚¤ã‚ºã‚’åˆ†æã™ã‚‹ãƒ†ã‚¹ãƒˆ
/// </summary>
public class VocabSizeAnalysisTest(ITestOutputHelper output)
{
    [Fact]
    public async Task AnalyzeAllSentencePieceModels_FindCorrectTargetTokenizer()
    {
        output.WriteLine("=== SentencePiece ãƒ¢ãƒ‡ãƒ«èªå½™ã‚µã‚¤ã‚ºåˆ†æ ===");
        
        using var loggerFactory = LoggerFactory.Create(builder =>
            builder.AddConsole()
                   .SetMinimumLevel(LogLevel.Information));

        var modelsToAnalyze = new[]
        {
            // ç¾åœ¨ä½¿ç”¨ä¸­ã®ãƒ¢ãƒ‡ãƒ«
            (@"E:\dev\Baketa\Models\SentencePiece\opus-mt-ja-en.model", "ç¾åœ¨ã®ã‚½ãƒ¼ã‚¹"),
            (@"E:\dev\Baketa\Models\Official_Helsinki\target.spm", "ç¾åœ¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ"),
            
            // HuggingFaceãƒ¢ãƒ‡ãƒ«
            (@"E:\dev\Baketa\Models\HuggingFace\opus-mt-ja-en\source.spm", "HuggingFace ã‚½ãƒ¼ã‚¹"),
            (@"E:\dev\Baketa\Models\HuggingFace\opus-mt-ja-en\target.spm", "HuggingFace ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ"),
            
            // ãã®ä»–ã®ãƒ¢ãƒ‡ãƒ«
            (@"E:\dev\Baketa\Models\Official_Helsinki\source.spm", "Official Helsinki ã‚½ãƒ¼ã‚¹"),
            (@"E:\dev\Baketa\Models\SentencePiece\opus-mt-ja-en-official.model", "Official SentencePiece"),
            (@"E:\dev\Baketa\Models\SentencePiece\helsinki-opus-mt-ja-en.model", "Helsinki SentencePiece"),
            
            // è¿½åŠ å€™è£œï¼šè‹±æ—¥ãƒ¢ãƒ‡ãƒ«ï¼ˆé€†æ–¹å‘ï¼‰
            (@"E:\dev\Baketa\Models\SentencePiece\opus-mt-en-ja.model", "è‹±æ—¥ã‚½ãƒ¼ã‚¹"),
            (@"E:\dev\Baketa\Models\HuggingFace\opus-mt-en-ja\pytorch_model.bin", "HuggingFace è‹±æ—¥æ¨¡å‹"),
            
            // è¿½åŠ å€™è£œï¼šãã®ä»–ã®SentencePieceãƒ¢ãƒ‡ãƒ«
            (@"E:\dev\Baketa\Models\SentencePiece\opus-mt-en-jap.model", "è‹±æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«"),
            (@"E:\dev\Baketa\Models\SentencePiece\opus-mt-zh-en.model", "ä¸­è‹±ãƒ¢ãƒ‡ãƒ«"),
            (@"E:\dev\Baketa\Models\SentencePiece\opus-mt-tc-big-zh-ja.model", "ä¸­æ—¥å¤§å‹ãƒ¢ãƒ‡ãƒ«"),
            (@"E:\dev\Baketa\Models\SentencePiece\test-ja-en.model", "ãƒ†ã‚¹ãƒˆæ—¥è‹±ãƒ¢ãƒ‡ãƒ«"),
            (@"E:\dev\Baketa\Models\SentencePiece\test-en-ja.model", "ãƒ†ã‚¹ãƒˆè‹±æ—¥ãƒ¢ãƒ‡ãƒ«")
        };

        output.WriteLine($"åˆ†æå¯¾è±¡ãƒ¢ãƒ‡ãƒ«æ•°: {modelsToAnalyze.Length}");
        output.WriteLine($"ç›®æ¨™èªå½™ã‚µã‚¤ã‚º: 60,716 (ONNXãƒ¢ãƒ‡ãƒ«ã¨ä¸€è‡´)");
        output.WriteLine("");

        string? bestMatchPath = null;
        int bestMatchVocabSize = 0;
        double bestMatchScore = 0.0;

        foreach (var (modelPath, description) in modelsToAnalyze)
        {
            var analysisResult = AnalyzeModel(modelPath, description, loggerFactory);
            
            if (analysisResult.Success && analysisResult.MatchScore > bestMatchScore)
            {
                bestMatchPath = modelPath;
                bestMatchVocabSize = analysisResult.VocabSize;
                bestMatchScore = analysisResult.MatchScore;
            }
            
            output.WriteLine("");
        }

        output.WriteLine("=== åˆ†æçµæœã‚µãƒãƒªãƒ¼ ===");
        if (bestMatchPath != null)
        {
            output.WriteLine($"ğŸ¯ æœ€é©ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆTokenizer:");
            output.WriteLine($"ãƒ‘ã‚¹: {bestMatchPath}");
            output.WriteLine($"èªå½™ã‚µã‚¤ã‚º: {bestMatchVocabSize:N0}");
            output.WriteLine($"ä¸€è‡´åº¦: {bestMatchScore:F2}%");
        }
        else
        {
            output.WriteLine("âŒ é©åˆ‡ãªTokenizerãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ");
        }

        await Task.CompletedTask;
    }

    private AnalysisResult AnalyzeModel(string modelPath, string description, ILoggerFactory loggerFactory)
    {
        try
        {
            output.WriteLine($"=== {description} ===");
            output.WriteLine($"ãƒ‘ã‚¹: {modelPath}");
            
            if (!File.Exists(modelPath))
            {
                output.WriteLine("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“");
                return new AnalysisResult { Success = false };
            }

            var fileInfo = new FileInfo(modelPath);
            output.WriteLine($"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {fileInfo.Length:N0} bytes");
            
            // SentencePieceãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ
            var logger = loggerFactory.CreateLogger<OpusMtNativeTokenizer>();
            var tokenizer = new OpusMtNativeTokenizer(modelPath, "Vocab Analysis", logger);
            
            output.WriteLine($"âœ… èªå½™ã‚µã‚¤ã‚º: {tokenizer.VocabularySize:N0}");
            
            // ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³IDç¢ºèª
            var bosId = tokenizer.GetSpecialTokenId("BOS");
            var eosId = tokenizer.GetSpecialTokenId("EOS");
            var unkId = tokenizer.GetSpecialTokenId("UNK");
            var padId = tokenizer.GetSpecialTokenId("PAD");
            
            output.WriteLine($"ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ - BOS: {bosId}, EOS: {eosId}, UNK: {unkId}, PAD: {padId}");
            
            // ONNXãƒ¢ãƒ‡ãƒ«ã¨ã®ä¸€è‡´åº¦ãƒã‚§ãƒƒã‚¯
            const int targetVocabSize = 60716;
            var difference = Math.Abs(tokenizer.VocabularySize - targetVocabSize);
            var matchPercentage = (1.0 - (double)difference / targetVocabSize) * 100;
            
            output.WriteLine($"ONNXä¸€è‡´åº¦: {matchPercentage:F2}% (å·®åˆ†: {difference:N0})");
            
            if (tokenizer.VocabularySize == targetVocabSize)
            {
                output.WriteLine("ğŸ¯ PERFECT MATCH! ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã¹ãã§ã™");
            }
            else if (difference < 1000)
            {
                output.WriteLine("âœ… éå¸¸ã«è¿‘ã„ - ä½¿ç”¨å¯èƒ½ãªå€™è£œ");
            }
            else if (difference < 10000)
            {
                output.WriteLine("âš ï¸ ã‚„ã‚„å·®ãŒã‚ã‚‹ - è¦æ¤œè¨");
            }
            else
            {
                output.WriteLine("âŒ å¤§ããªå·® - ä½¿ç”¨éæ¨å¥¨");
            }
            
            // ãƒ†ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³åŒ–
            var testText = "ãƒ†ã‚¹ãƒˆ";
            var tokens = tokenizer.Tokenize(testText);
            output.WriteLine($"ãƒ†ã‚¹ãƒˆ '{testText}' -> [{string.Join(", ", tokens)}]");

            return new AnalysisResult
            {
                Success = true,
                VocabSize = tokenizer.VocabularySize,
                MatchScore = matchPercentage,
                ModelPath = modelPath
            };

        }
        catch (Exception ex)
        {
            output.WriteLine($"âŒ ã‚¨ãƒ©ãƒ¼: {ex.Message}");
            if (ex.InnerException != null)
            {
                output.WriteLine($"   è©³ç´°: {ex.InnerException.Message}");
            }
            return new AnalysisResult { Success = false };
        }
    }

    private sealed record AnalysisResult
    {
        public bool Success { get; init; }
        public int VocabSize { get; init; }
        public double MatchScore { get; init; }
        public string ModelPath { get; init; } = string.Empty;
    }
}
