# Baketa gRPC Translation Server Dependencies
# Phase 2.2: Python gRPCã‚µãƒ¼ãƒãƒ¼å®Ÿè£…

# gRPC (æœ€æ–°ç‰ˆ)
# protobuf 5.xç³»ã«å›ºå®šï¼ˆGoogle AI, grpcio-status, open-clip-torchã¨ã®äº’æ›æ€§ã®ãŸã‚ï¼‰
grpcio>=1.60.0
# ðŸ”¥ [ISSUE#164 PROTOBUF_FIX] grpcio-tools 1.69.xã«åˆ¶é™ - Protobuf 5.xäº’æ›ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ãŸã‚
# 1.70ä»¥é™ã¯Protobuf 6.xã§ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã—ã¦ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ
grpcio-tools>=1.60.0,<1.70.0
protobuf>=5.26.1,<6.0

# NLLB-200 Translation Model (æ—¢å­˜requirements.txtãƒ™ãƒ¼ã‚¹)
transformers>=4.30.0
# ðŸ”¥ [HOTFIX alpha-0.1.10] torch CPUç‰ˆã‚’è¿½åŠ ï¼ˆtransformersãŒtorchã‚’æš—é»™çš„ã«å¿…è¦ã¨ã™ã‚‹ãŸã‚ï¼‰
# æ ¹æœ¬åŽŸå› : transformersã®AutoTokenizer.from_pretrained()ã¯å†…éƒ¨ã§torchã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã€
#           torchãªã—ã§ã¯ImportErrorã§èµ·å‹•ç›´å¾Œã«ExitCode 1ã§å¤±æ•—ã™ã‚‹ã€‚
# å¯¾ç­–: CPUå°‚ç”¨ç‰ˆã‚’ä½¿ç”¨ã—ã¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’æŠ‘åˆ¶ï¼ˆCUDAç‰ˆã¨ã®å·®åˆ† ç´„50-100MBå‰Šæ¸›ï¼‰
# æ’ä¹…å¯¾å¿œ: Issue #171ã§SentencePieceProcessorã«ã‚ˆã‚‹AutoTokenizerç½®ãæ›ãˆã‚’å®Ÿæ–½äºˆå®š
torch>=2.0.0 --index-url https://download.pytorch.org/whl/cpu
sentencepiece>=0.1.99

# Data Processing
numpy>=1.24.0

# System Monitoring
psutil>=5.9.0

# ðŸ”¥ [PHASE1.1] GPU/VRAMç›£è¦–ç”¨ï¼ˆNVIDIA GPUç’°å¢ƒï¼‰
pynvml>=11.5.0

# Optional: GPU support (uncomment if CUDA is available)
# torch[cuda]>=2.0.0

# Phase 2.2.1: CTranslate2 for optimized inference (80% memory reduction: 2.4GB -> 500MB)
ctranslate2>=3.20.0

# ðŸ”¥ [ALPHA_0.1.2] HuggingFace Hub integration for automatic model download
huggingface_hub>=0.20.0

# Development & Testing
pytest>=7.0.0
pytest-asyncio>=0.23.0
