# üî• [ULTRATHINK_FIX] Phase 6: ÂÖ®warningsÂÆåÂÖ®ÊäëÂà∂ÔºàimportÊñá„Çà„ÇäÂâç„Å´ÂÆüË°åÔºâ
# ÂïèÈ°å: torch.cuda/transformers„ÅÆË≠¶Âëä„Ååstderr„Åß„Éè„É≥„Ç∞ ‚Üí C#„Éó„É≠„Çª„ÇπËµ∑ÂãïÂ§±Êïó
# Ëß£Ê±∫Á≠ñ: importÂâç„Å´warningsÊäëÂà∂ + Áí∞Â¢ÉÂ§âÊï∞PYTHONWARNINGSË®≠ÂÆö
import warnings
warnings.filterwarnings('ignore')

# üî• [ULTRATHINK_FIX] Phase 6: PythonÁµÑ„ÅøËæº„ÅøwarningsÁí∞Â¢ÉÂ§âÊï∞Ë®≠ÂÆö
import os
os.environ["PYTHONWARNINGS"] = "ignore"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"  # TensorFlowË≠¶ÂëäÊäëÂà∂
os.environ["TOKENIZERS_PARALLELISM"] = "false"  # HuggingFace‰∏¶ÂàóÂåñÁÑ°Âäπ

"""
gRPC Translation Server Startup Script
Phase 2.2: „Çµ„Éº„Éê„ÉºËµ∑Âãï„Ç®„É≥„Éà„É™„Éº„Éù„Ç§„É≥„Éà

Usage:
    python start_server.py [--port PORT] [--host HOST] [--heavy-model]

Examples:
    python start_server.py
    python start_server.py --port 50051 --host localhost
    python start_server.py --heavy-model  # Use 1.3B model instead of 600M
"""

import asyncio
import argparse
import logging
import signal
import sys
import faulthandler  # üî• [PHASE1.3] WindowsÂõ∫Êúâ„ÇØ„É©„ÉÉ„Ç∑„É•Ê§úÂá∫Áî®
import traceback  # üî• [PHASE1.3] ‰æãÂ§ñ„Çπ„Çø„ÉÉ„ÇØ„Éà„É¨„Éº„ÇπÂá∫ÂäõÁî®
from pathlib import Path

# üî• [HOTFIX alpha-0.1.12] Python EmbeddableÁâà„Åß„ÅÆprotos„É¢„Ç∏„É•„Éº„É´„Ç§„É≥„Éù„Éº„Éà‰øÆÊ≠£
# Root cause: python310._pth„ÅÆ"."„ÅØvendor/python/„ÇíÂü∫Ê∫ñ„Å®„Åô„Çã„Åü„ÇÅ„ÄÅ
#             WorkingDirectory=grpc_server„Åß„ÇÇ„Ç´„É¨„É≥„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„Ååsys.path„Å´Âê´„Åæ„Çå„Å™„ÅÑ
# Fix: ÊòéÁ§∫ÁöÑ„Å´„Ç´„É¨„É≥„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„Çísys.path„Å´ËøΩÂä†
if os.getcwd() not in sys.path:
    sys.path.insert(0, os.getcwd())

import grpc
from grpc import aio
# üî• [PACKAGE_SIZE_FIX] torchÂâäÈô§ÔºàÁ¥Ñ200MBÂâäÊ∏õÔºâ
# GPUÊ§úÂá∫„ÅØctranslate2.get_device_count()„Çí‰ΩøÁî®
import ctranslate2

# ProtoÁîüÊàê„Éï„Ç°„Ç§„É´Ôºà„Ç≥„É≥„Éë„Ç§„É´Âæå„Å´„Ç§„É≥„Éù„Éº„ÉàÂèØËÉΩ„Å´„Å™„Çä„Åæ„ÅôÔºâ
from protos import translation_pb2_grpc

from translation_server import TranslationServicer
from engines.nllb_engine import NllbEngine
from engines.ctranslate2_engine import CTranslate2Engine
from resource_monitor import ResourceMonitor  # Phase 1.1: GPU/VRAMÁõ£Ë¶ñ

# üîß [UNICODE_FIX] WindowsÁí∞Â¢É„Åß„ÅÆUnicodeEncodeErrorÂØæÁ≠ñ
# sys.stdout/stderr„ÇíUTF-8„Å´ÂÜçË®≠ÂÆöÔºàcp932 ‚Üí utf-8Ôºâ
# „Åì„Çå„Å´„Çà„Çä„ÄÅ„É≠„Ç∞Âá∫ÂäõÊôÇ„ÅÆUnicode„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„Ç®„É©„Éº„ÇíÈò≤Ê≠¢
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# „É≠„ÇÆ„É≥„Ç∞Ë®≠ÂÆö
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('translation_server.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class GracefulShutdown:
    """„Ç∞„É¨„Éº„Çπ„Éï„É´„Ç∑„É£„ÉÉ„Éà„ÉÄ„Ç¶„É≥„Éè„É≥„Éâ„É©„Éº"""

    def __init__(self):
        self.shutdown_event = asyncio.Event()

    def __enter__(self):
        loop = asyncio.get_event_loop()

        def signal_handler(signum, frame):
            logger.info(f"Received signal {signum}, shutting down gracefully...")
            asyncio.create_task(self._async_shutdown())

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

        return self

    def __exit__(self, exc_type, exc_value, traceback):
        pass

    async def _async_shutdown(self):
        self.shutdown_event.set()

    async def wait_for_shutdown(self):
        await self.shutdown_event.wait()


async def serve(host: str, port: int, use_heavy_model: bool = False, use_ctranslate2: bool = False):
    """gRPC„Çµ„Éº„Éê„ÉºËµ∑Âãï

    Args:
        host: „Éê„Ç§„É≥„Éâ„Éõ„Çπ„ÉàÔºà‰æã: "localhost", "0.0.0.0"Ôºâ
        port: „Éù„Éº„ÉàÁï™Âè∑Ôºà‰æã: 50051Ôºâ
        use_heavy_model: True„Åß1.3B„É¢„Éá„É´„ÄÅFalse„Åß600M„É¢„Éá„É´‰ΩøÁî®
        use_ctranslate2: True„ÅßCTranslate2„Ç®„É≥„Ç∏„É≥„ÄÅFalse„Åßtransformers„Ç®„É≥„Ç∏„É≥‰ΩøÁî®
    """
    logger.info("=" * 80)
    logger.info("Baketa gRPC Translation Server Starting...")
    logger.info("=" * 80)

    # „Ç®„É≥„Ç∏„É≥ÈÅ∏Êäû
    if use_ctranslate2:
        logger.info("Initializing CTranslate2 translation engine...")

        # üî• [ALPHA_0.1.2] HuggingFace HubÁµ±Âêà: „É¢„Éá„É´‰øùÂ≠òÂÖà„Çí%APPDATA%\Baketa\Models„Å´Â§âÊõ¥
        # GeminiÊé®Â•®: „Ç§„É≥„Çπ„Éà„Éº„É´ÂÖà„Å∏„ÅÆÊõ∏„ÅçËæº„Åø„ÅØÁÆ°ÁêÜËÄÖÊ®©Èôê„ÅåÂøÖË¶Å„Å™„Åü„ÇÅ„ÄÅAPPDATA„Çí‰ΩøÁî®
        appdata = os.environ.get('APPDATA', os.path.expanduser('~'))
        model_path = Path(appdata) / "Baketa" / "Models" / "nllb-200-ct2"
        logger.info(f"Model path resolved: {model_path}")

        # „É¢„Éá„É´Â≠òÂú®„ÉÅ„Çß„ÉÉ„ÇØ„ÉªËá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
        if not model_path.exists() or not (model_path / "model.bin").exists():
            logger.info("=" * 80)
            logger.info("Model not found. Downloading from HuggingFace Hub...")
            logger.info("Repository: JustFrederik/nllb-200-distilled-600M-ct2-int8")
            logger.info("Size: ~600MB | This may take several minutes...")
            logger.info("=" * 80)
            model_path.mkdir(parents=True, exist_ok=True)

            try:
                # üî• [GEMINI_RECOMMENDATION] ÈùûÂêåÊúü„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÔºà„Ç§„Éô„É≥„Éà„É´„Éº„Éó„Éñ„É≠„ÉÉ„Ç≠„É≥„Ç∞ÂõûÈÅøÔºâ
                from huggingface_hub import snapshot_download
                from functools import partial

                loop = asyncio.get_running_loop()
                download_func = partial(
                    snapshot_download,
                    repo_id="JustFrederik/nllb-200-distilled-600M-ct2-int8",
                    local_dir=str(model_path),
                    revision="main"  # TODO: ÁâπÂÆö„ÅÆ„Ç≥„Éü„ÉÉ„Éà„Éè„ÉÉ„Ç∑„É•„Å´Âõ∫ÂÆöÔºà„Çª„Ç≠„É•„É™„ÉÜ„Ç£Âêë‰∏äÔºâ
                )
                await loop.run_in_executor(None, download_func)
                logger.info("=" * 80)
                logger.info("Model download completed successfully.")
                logger.info("=" * 80)
            except Exception as e:
                logger.error("=" * 80)
                logger.error(f"Model download failed: {e}")
                logger.error("Please check:")
                logger.error("  1. Internet connection is available")
                logger.error("  2. Disk space is sufficient (~600MB)")
                logger.error("  3. HuggingFace Hub is accessible")
                logger.error("=" * 80)
                raise RuntimeError(f"Failed to download model from HuggingFace Hub: {e}")
        else:
            logger.info("Model found locally. Skipping download.")

        # üî• [PACKAGE_SIZE_FIX] GPUÊ§úÂá∫„Çíctranslate2ÁµÑ„ÅøËæº„ÅøÈñ¢Êï∞„ÅßÂÆüË°åÔºàtorch‰∏çË¶ÅÔºâ
        is_cuda_available = ctranslate2.get_device_count("cuda") > 0

        engine = CTranslate2Engine(
            model_path=str(model_path),  # %APPDATA%\Baketa\Models\nllb-200-ct2
            device="cuda" if is_cuda_available else "cpu",
            compute_type="int8"
        )
    else:
        logger.info("Initializing NLLB translation engine...")
        engine = NllbEngine(use_heavy_model=use_heavy_model)

    logger.info("Loading NLLB model (this may take a few minutes)...")
    await engine.load_model()
    logger.info("NLLB model loaded successfully")

    # gRPC„Çµ„Éº„Éê„Éº‰ΩúÊàê
    logger.info("Creating gRPC server...")
    # üîß [GEMINI_DEEP_FIX] ÂÆåÂÖ®„Å™KeepAliveË®≠ÂÆö - ‰∏≠ÈñìÊ©üÂô®„Å´„Çà„ÇãÂàáÊñ≠„ÇíÈò≤Ê≠¢
    # Ê†πÊú¨ÂéüÂõ†: ‰∏≠ÈñìÊ©üÂô®Ôºà„Éï„Ç°„Ç§„Ç¢„Ç¶„Ç©„Éº„É´„ÄÅNATÁ≠âÔºâ„Åå112Áßí„Ç¢„Ç§„Éâ„É´„ÅßTCPÂàáÊñ≠
    # Ëß£Ê±∫Á≠ñ: „Çµ„Éº„Éê„ÉºÂÅ¥„Åã„Çâ30ÁßíÈñìÈöî„ÅßPING„ÇíÈÄÅ‰ø°„Åó„ÄÅ„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åã„Çâ„ÅÆPING„ÇÇË®±ÂèØ
    server = aio.server(options=[
        # ‚òÖ‚òÖ‚òÖ „Çµ„Éº„Éê„ÉºÂÅ¥„ÅÆKeepAliveË®≠ÂÆö ‚òÖ‚òÖ‚òÖ
        ('grpc.keepalive_time_ms', 30000),  # 30Áßí„Åî„Å®„Å´„ÇØ„É©„Ç§„Ç¢„É≥„Éà„ÅÆÁîüÂ≠òÁ¢∫Ë™çPING„ÇíÈÄÅ‰ø°
        ('grpc.keepalive_timeout_ms', 10000),  # PING„ÅÆÂøúÁ≠îÂæÖ„Å°ÊôÇÈñì
        ('grpc.keepalive_permit_without_calls', True),  # RPC„Åå„Å™„Åè„Å¶„ÇÇPING„ÇíË®±ÂèØÔºà„Ç¢„Ç§„Éâ„É´‰∏≠„ÇÇÊé•Á∂öÁ∂≠ÊåÅÔºâ
        ('grpc.http2.min_time_between_pings_ms', 10000),  # PING„ÅÆÊúÄ‰ΩéÈñìÈöî
        ('grpc.http2.max_pings_without_data', 0),  # „Éá„Éº„Çø„Å™„Åó„Åß„ÅÆPINGÂõûÊï∞Âà∂Èôê„ÇíÁÑ°ÂäπÂåñ
        ('grpc.http2.min_ping_interval_without_data_ms', 10000),  # „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åã„Çâ„ÅÆPINGÊúÄ‰ΩéÈñìÈöî
    ])

    # TranslationService„ÇíÁôªÈå≤
    servicer = TranslationServicer(engine)
    translation_pb2_grpc.add_TranslationServiceServicer_to_server(servicer, server)

    # „É™„Çπ„Éã„É≥„Ç∞„Ç¢„Éâ„É¨„ÇπË®≠ÂÆö
    listen_addr = f'{host}:{port}'
    server.add_insecure_port(listen_addr)

    logger.info(f"Starting gRPC server on {listen_addr}...")
    await server.start()

    logger.info("=" * 80)
    logger.info(f"gRPC Translation Server is running on {listen_addr}")
    logger.info(f"   Engine: {engine.__class__.__name__}")
    logger.info(f"   Model: {engine.model_name}")
    logger.info(f"   Device: {engine.device}")

    # üî• [PHASE8_FIX] PythonServerManager.WaitForServerReadyAsync()‰∫íÊèõÊÄß„ÅÆ„Åü„ÇÅ[SERVER_START]Âá∫Âäõ
    # C#ÂÅ¥„ÅåStdErr„ÇíÁõ£Ë¶ñ„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅsys.stderr„Å´Áõ¥Êé•Âá∫Âäõ
    sys.stderr.write("[SERVER_START]\n")
    sys.stderr.flush()  # Âç≥Â∫ß„Å´Âá∫Âäõ
    logger.info("[SERVER_START] signal sent to stderr for C# detection")
    logger.info(f"   Supported languages: {', '.join(engine.get_supported_languages())}")
    logger.info("=" * 80)
    logger.info("Press Ctrl+C to stop the server")

    # üî• [PHASE1.1] GPU/VRAM„É°„É¢„É™Áõ£Ë¶ñÈñãÂßãÔºàGeminiÊúÄÈáçË¶ÅÊé®Â•®Ôºâ
    resource_monitor = ResourceMonitor(enable_gpu_monitoring=True)
    await resource_monitor.start_monitoring(interval_seconds=300)  # 5ÂàÜ„Åî„Å®
    logger.info("[PHASE1.1] Resource monitoring started (CPU RAM + GPU VRAM + Handles)")

    # „Ç∞„É¨„Éº„Çπ„Éï„É´„Ç∑„É£„ÉÉ„Éà„ÉÄ„Ç¶„É≥ÂæÖÊ©ü
    with GracefulShutdown() as shutdown_handler:
        try:
            await shutdown_handler.wait_for_shutdown()
        except KeyboardInterrupt:
            logger.info("Received KeyboardInterrupt, shutting down...")

    # „Çµ„Éº„Éê„ÉºÂÅúÊ≠¢
    logger.info("Stopping gRPC server...")
    await server.stop(grace=5.0)  # 5Áßí„ÅÆ„Ç∞„É¨„Éº„Çπ„Éî„É™„Ç™„Éâ
    logger.info("gRPC server stopped")

    # üî• [PHASE1.1] „É™„ÇΩ„Éº„ÇπÁõ£Ë¶ñ„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
    await resource_monitor.stop_monitoring()
    resource_monitor.cleanup()
    logger.info("[PHASE1.1] Resource monitoring cleanup completed")


def global_exception_handler(exc_type, exc_value, exc_traceback):
    """üî• [PHASE1.3] „Ç∞„É≠„Éº„Éê„É´‰æãÂ§ñ„Éè„É≥„Éâ„É©„Éº - „Åô„Åπ„Å¶„ÅÆÊú™Âá¶ÁêÜ‰æãÂ§ñ„Çí„É≠„Ç∞Âá∫Âäõ"""
    if issubclass(exc_type, KeyboardInterrupt):
        # KeyboardInterrupt„ÅØÈÄöÂ∏∏Âá¶ÁêÜ
        sys.__excepthook__(exc_type, exc_value, exc_traceback)
        return

    logger.critical("=" * 80)
    logger.critical("üö® [PHASE1.3] UNCAUGHT EXCEPTION - CRITICAL ERROR")
    logger.critical("=" * 80)
    logger.critical(f"Exception Type: {exc_type.__name__}")
    logger.critical(f"Exception Value: {exc_value}")
    logger.critical("Traceback:")
    logger.critical("".join(traceback.format_exception(exc_type, exc_value, exc_traceback)))
    logger.critical("=" * 80)


def main():
    """„Ç≥„Éû„É≥„Éâ„É©„Ç§„É≥ÂºïÊï∞„Éë„Éº„Çπ & „Çµ„Éº„Éê„ÉºËµ∑Âãï"""
    # üî• [PHASE1.3] faulthandlerÊúâÂäπÂåñ - SIGSEGVÁ≠â„ÅÆOS-level„ÇØ„É©„ÉÉ„Ç∑„É•„ÇíÊ§úÂá∫
    faulthandler.enable(file=sys.stderr, all_threads=True)
    logger.info("[PHASE1.3] faulthandler enabled - OS-level crash detection active")

    # üî• [PHASE1.3] „Ç∞„É≠„Éº„Éê„É´‰æãÂ§ñ„Éè„É≥„Éâ„É©„ÉºË®≠ÁΩÆ
    sys.excepthook = global_exception_handler
    logger.info("[PHASE1.3] Global exception handler installed")

    parser = argparse.ArgumentParser(
        description="Baketa gRPC Translation Server"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=50051,
        help="gRPC server port (default: 50051)"
    )
    parser.add_argument(
        "--host",
        type=str,
        default="0.0.0.0",
        help="gRPC server host (default: 0.0.0.0 for all interfaces)"
    )
    parser.add_argument(
        "--heavy-model",
        action="store_true",
        help="Use 1.3B model instead of 600M model (requires more memory)"
    )
    parser.add_argument(
        "--use-ctranslate2",
        action="store_true",
        help="Use CTranslate2 engine for 80%% memory reduction (2.4GB -> 500MB)"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug logging"
    )

    args = parser.parse_args()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.setLevel(logging.DEBUG)

    # Ë®≠ÂÆöÊÉÖÂ†±Ë°®Á§∫
    logger.info("Server configuration:")
    logger.info(f"  Host: {args.host}")
    logger.info(f"  Port: {args.port}")
    logger.info(f"  Heavy model: {args.heavy_model}")
    logger.info(f"  Use CTranslate2: {args.use_ctranslate2}")
    logger.info(f"  Debug mode: {args.debug}")

    # asyncio„Ç§„Éô„É≥„Éà„É´„Éº„Éó„Åß„Çµ„Éº„Éê„ÉºËµ∑Âãï
    try:
        asyncio.run(
            serve(
                host=args.host,
                port=args.port,
                use_heavy_model=args.heavy_model,
                use_ctranslate2=args.use_ctranslate2
            )
        )
    except KeyboardInterrupt:
        logger.info("Server interrupted by user")
    except Exception as e:
        logger.exception(f"Server error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
