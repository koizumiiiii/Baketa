#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Baketa Unified AI Server
Issue #292: OCR+ç¿»è¨³çµ±åˆAIã‚µãƒ¼ãƒãƒ¼

Phase 1: OCR (Surya) ã¨ç¿»è¨³ (NLLB-200) ã‚’å˜ä¸€ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œ
- VRAMå‰Šæ¸›: 2ãƒ—ãƒ­ã‚»ã‚¹(~1GB) â†’ 1ãƒ—ãƒ­ã‚»ã‚¹(~500MB)
- CUDAã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå…±æœ‰ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
- ä¸¦åˆ—ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã«ã‚ˆã‚‹èµ·å‹•æ™‚é–“çŸ­ç¸®

ä½¿ç”¨æ–¹æ³•:
    python unified_server.py [--port PORT] [--host HOST]

ä¾‹:
    python unified_server.py
    python unified_server.py --port 50051 --host 127.0.0.1
"""

# Phase 6: å…¨warningså®Œå…¨æŠ‘åˆ¶ï¼ˆimportæ–‡ã‚ˆã‚Šå‰ã«å®Ÿè¡Œï¼‰
import warnings
warnings.filterwarnings('ignore')

import os
os.environ["PYTHONWARNINGS"] = "ignore"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

import sys
import io
import time
import asyncio
import argparse
import logging
import signal
import faulthandler
import traceback
from pathlib import Path
from datetime import datetime
from typing import Optional, List
from concurrent.futures import ThreadPoolExecutor

# Issue #293: stdout/stderrã®ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç„¡åŠ¹åŒ–ï¼ˆã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰ã®ãƒ­ã‚°å³æ™‚å‡ºåŠ›ç”¨ï¼‰
# Windowsã§ã¯reconfigure()ã§line_bufferingã‚’è¨­å®š
try:
    sys.stdout.reconfigure(line_buffering=True)
    sys.stderr.reconfigure(line_buffering=True)
except AttributeError:
    # Python 3.6ä»¥å‰ or ç‰¹æ®Šç’°å¢ƒã§ã¯ç„¡è¦–
    pass

# miniconda CUDA DLLç«¶åˆé˜²æ­¢
def _sanitize_path_for_cuda():
    """minicondaã®CUDA DLLãƒ‘ã‚¹ã‚’PATHã‹ã‚‰é™¤å¤–"""
    path = os.environ.get("PATH", "")
    path_parts = path.split(os.pathsep)
    sanitized_parts = []
    excluded_parts = []
    for part in path_parts:
        part_lower = part.lower()
        if "miniconda" in part_lower or "anaconda" in part_lower:
            excluded_parts.append(part)
        else:
            sanitized_parts.append(part)
    if excluded_parts:
        print(f"[INFO] CUDA DLLç«¶åˆé˜²æ­¢: PATH ã‹ã‚‰é™¤å¤–ã—ã¾ã—ãŸ", file=sys.stderr)
        os.environ["PATH"] = os.pathsep.join(sanitized_parts)
        return True
    return False

_sanitize_path_for_cuda()

# Python Embeddableç‰ˆå¯¾å¿œ
if os.getcwd() not in sys.path:
    sys.path.insert(0, os.getcwd())

import grpc
from grpc import aio
from google.protobuf.timestamp_pb2 import Timestamp

# Protoç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«
from protos import translation_pb2, translation_pb2_grpc
from protos import ocr_pb2, ocr_pb2_grpc

# ã‚¨ãƒ³ã‚¸ãƒ³
# ğŸ”¥ [Issue #337] LazyLoadingTranslatorè¿½åŠ ï¼ˆé…å»¶èª­ã¿è¾¼ã¿/è‡ªå‹•ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
from engines.ctranslate2_engine import CTranslate2Engine, LazyLoadingTranslator
from translation_server import TranslationServicer
from resource_monitor import ResourceMonitor

# UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¼·åˆ¶ï¼ˆWindowså¯¾å¿œï¼‰
try:
    if sys.stdout is not None and hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
    if sys.stderr is not None and hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8')
except (AttributeError, OSError):
    pass

# [Gemini Review Fix] ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¯10MB x 5ä¸–ä»£ã§ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
from logging.handlers import RotatingFileHandler

_log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Issue #293: ãƒ­ã‚°ã‚’å³åº§ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ³ãƒ‰ãƒ©
class FlushingStreamHandler(logging.StreamHandler):
    """ãƒ­ã‚°å‡ºåŠ›å¾Œã«å³åº§ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã™ã‚‹StreamHandler"""
    def emit(self, record):
        super().emit(record)
        self.flush()

_console_handler = FlushingStreamHandler(sys.stdout)
_console_handler.setFormatter(_log_formatter)
_console_handler.setLevel(logging.INFO)

_file_handler = RotatingFileHandler(
    'unified_server.log',
    maxBytes=10 * 1024 * 1024,  # 10MB
    backupCount=5,
    encoding='utf-8'
)
_file_handler.setFormatter(_log_formatter)
_file_handler.setLevel(logging.DEBUG)  # ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯è©³ç´°ãƒ­ã‚°

logging.basicConfig(
    level=logging.DEBUG,
    handlers=[_console_handler, _file_handler]
)
logger = logging.getLogger(__name__)


# ============================================================================
# Surya OCR Engine (çµ±åˆç‰ˆ)
# ============================================================================

class SuryaOcrEngine:
    """Surya OCRã‚¨ãƒ³ã‚¸ãƒ³ãƒ©ãƒƒãƒ‘ãƒ¼ (v0.17.0+ APIå¯¾å¿œ)"""

    VERSION = "0.17.x"
    MAX_IMAGE_SIZE = 10 * 1024 * 1024  # 10MB
    MAX_IMAGE_DIMENSION = 2048

    def __init__(self, device: str = "cuda"):
        self.device = device
        self.foundation_predictor = None
        self.recognition_predictor = None
        self.detection_predictor = None
        self.is_loaded = False
        self.logger = logging.getLogger(f"{__name__}.SuryaOcrEngine")

    async def load_model(self) -> bool:
        """éåŒæœŸã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, self._load_model_sync)

    def _load_model_sync(self) -> bool:
        """åŒæœŸçš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ (Surya v0.17.0+ API)"""
        try:
            self.logger.info(f"Surya OCRãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... (device: {self.device})")
            total_start = time.time()

            # CUDAåˆ©ç”¨å¯å¦ãƒã‚§ãƒƒã‚¯
            use_cuda = False
            if self.device == "cuda":
                try:
                    import torch
                    if torch.cuda.is_available():
                        use_cuda = True
                        gpu_name = torch.cuda.get_device_name(0)
                        self.logger.info(f"CUDAåˆ©ç”¨å¯èƒ½: GPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ ({gpu_name})")
                    else:
                        self.logger.info("CUDAåˆ©ç”¨ä¸å¯: CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
                except OSError as e:
                    self.logger.warning(f"CUDA DLLãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                    self.logger.info("CPUãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                    os.environ["CUDA_VISIBLE_DEVICES"] = ""

            # ãƒ‡ãƒã‚¤ã‚¹è¨­å®šã®ç¢ºå®š
            if use_cuda:
                os.environ["TORCH_DEVICE"] = "cuda"
            else:
                os.environ["TORCH_DEVICE"] = "cpu"
                self.device = "cpu"

            # Surya OCR v0.17.0+ APIã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            self.logger.info("[OCR] Importing Surya modules...")
            sys.stdout.flush()
            from surya.foundation import FoundationPredictor
            from surya.recognition import RecognitionPredictor
            from surya.detection import DetectionPredictor
            self.logger.info("[OCR] Surya modules imported successfully")
            sys.stdout.flush()

            # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«
            self.logger.info("[OCR] Creating DetectionPredictor (may download models)...")
            sys.stdout.flush()
            det_start = time.time()
            self.detection_predictor = DetectionPredictor()
            self.logger.info(f"[Timing] DetectionPredictor: {time.time() - det_start:.2f}ç§’")
            sys.stdout.flush()

            # èªè­˜ãƒ¢ãƒ‡ãƒ« (FoundationPredictorçµŒç”±)
            self.logger.info("[OCR] Creating FoundationPredictor...")
            sys.stdout.flush()
            found_start = time.time()
            self.foundation_predictor = FoundationPredictor()
            self.logger.info(f"[Timing] FoundationPredictor: {time.time() - found_start:.2f}ç§’")
            sys.stdout.flush()

            self.logger.info("[OCR] Creating RecognitionPredictor...")
            sys.stdout.flush()
            rec_start = time.time()
            self.recognition_predictor = RecognitionPredictor(self.foundation_predictor)
            self.logger.info(f"[Timing] RecognitionPredictor: {time.time() - rec_start:.2f}ç§’")
            sys.stdout.flush()

            elapsed = time.time() - total_start
            self.logger.info(f"Surya OCRãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº† (åˆè¨ˆ: {elapsed:.2f}ç§’)")
            sys.stdout.flush()
            self.is_loaded = True
            return True

        except ImportError as e:
            self.logger.error(f"Surya OCRãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            return False
        except Exception as e:
            self.logger.exception(f"ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _resize_image_if_needed(self, image: "Image.Image") -> tuple:
        """ç”»åƒãŒå¤§ãã™ãã‚‹å ´åˆã¯ãƒªã‚µã‚¤ã‚º"""
        from PIL import Image
        width, height = image.size
        max_dim = max(width, height)

        if max_dim <= self.MAX_IMAGE_DIMENSION:
            return image, 1.0

        scale = self.MAX_IMAGE_DIMENSION / max_dim
        new_width = int(width * scale)
        new_height = int(height * scale)

        self.logger.info(f"ç”»åƒãƒªã‚µã‚¤ã‚º: {width}x{height} â†’ {new_width}x{new_height}")
        resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)

        return resized, scale

    def recognize(self, image_bytes: bytes, languages: Optional[List[str]] = None) -> dict:
        """ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’èªè­˜"""
        if not self.is_loaded:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒæœªãƒ­ãƒ¼ãƒ‰ã§ã™")

        if len(image_bytes) > self.MAX_IMAGE_SIZE:
            raise ValueError(f"ç”»åƒã‚µã‚¤ã‚ºãŒä¸Šé™ã‚’è¶…ãˆã¦ã„ã¾ã™: {len(image_bytes)} bytes")

        try:
            from PIL import Image

            image = Image.open(io.BytesIO(image_bytes))
            if image.mode != "RGB":
                image = image.convert("RGB")

            image, scale = self._resize_image_if_needed(image)

            self.logger.info(f"OCRå®Ÿè¡Œä¸­... (ã‚µã‚¤ã‚º: {image.size})")
            start_time = time.time()

            predictions = self.recognition_predictor(
                [image],
                det_predictor=self.detection_predictor
            )

            elapsed = time.time() - start_time

            regions = []
            if predictions and len(predictions) > 0:
                ocr_result = predictions[0]
                text_lines = getattr(ocr_result, 'text_lines', [])
                if not text_lines:
                    text_lines = getattr(ocr_result, 'lines', [])

                inv_scale = 1.0 / scale if scale != 1.0 else 1.0

                for idx, line in enumerate(text_lines):
                    bbox = getattr(line, 'bbox', None)
                    polygon = getattr(line, 'polygon', None)
                    confidence = getattr(line, 'confidence', 0.0)
                    text = getattr(line, 'text', '')

                    region = {
                        "text": text,
                        "confidence": float(confidence) if confidence else 0.0,
                        "bbox": {
                            "points": [
                                {"x": float(p[0]) * inv_scale, "y": float(p[1]) * inv_scale}
                                for p in polygon
                            ] if polygon else [],
                            "x": int(bbox[0] * inv_scale) if bbox else 0,
                            "y": int(bbox[1] * inv_scale) if bbox else 0,
                            "width": int((bbox[2] - bbox[0]) * inv_scale) if bbox and len(bbox) >= 4 else 0,
                            "height": int((bbox[3] - bbox[1]) * inv_scale) if bbox and len(bbox) >= 4 else 0,
                        },
                        "line_index": idx
                    }
                    regions.append(region)

            self.logger.info(f"OCRå®Œäº†: {len(regions)}é ˜åŸŸæ¤œå‡º ({elapsed*1000:.0f}ms)")

            return {
                "success": True,
                "regions": regions,
                "processing_time_ms": int(elapsed * 1000),
                "engine_name": "Surya OCR",
                "engine_version": self.VERSION
            }

        except Exception as e:
            self.logger.exception(f"OCRã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e),
                "regions": [],
                "processing_time_ms": 0,
                "engine_name": "Surya OCR",
                "engine_version": self.VERSION
            }

    def detect_only(self, image_bytes: bytes) -> dict:
        """[Issue #320] ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã®ä½ç½®ã®ã¿ã‚’æ¤œå‡ºï¼ˆRecognitionã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰

        ROIå­¦ç¿’ç”¨ã®é«˜é€Ÿæ¤œå‡ºãƒ¡ã‚½ãƒƒãƒ‰ã€‚
        é€šå¸¸ã®recognize()ãŒ~1000msã‹ã‹ã‚‹ã®ã«å¯¾ã—ã€~100msã§å®Œäº†ã€‚

        Args:
            image_bytes: ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆPNG/JPEGï¼‰

        Returns:
            dict: æ¤œå‡ºçµæœ
                - success: bool
                - regions: List[dict] (bbox, confidence, region_index ã®ã¿)
                - processing_time_ms: int
        """
        if not self.is_loaded:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒæœªãƒ­ãƒ¼ãƒ‰ã§ã™")

        if len(image_bytes) > self.MAX_IMAGE_SIZE:
            raise ValueError(f"ç”»åƒã‚µã‚¤ã‚ºãŒä¸Šé™ã‚’è¶…ãˆã¦ã„ã¾ã™: {len(image_bytes)} bytes")

        try:
            from PIL import Image

            image = Image.open(io.BytesIO(image_bytes))
            if image.mode != "RGB":
                image = image.convert("RGB")

            image, scale = self._resize_image_if_needed(image)

            self.logger.info(f"Detection-Onlyå®Ÿè¡Œä¸­... (ã‚µã‚¤ã‚º: {image.size})")
            start_time = time.time()

            # Detection ã®ã¿å®Ÿè¡Œï¼ˆRecognition ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            # detection_predictor ã‚’ç›´æ¥ä½¿ç”¨
            detection_results = self.detection_predictor([image])

            elapsed = time.time() - start_time

            regions = []
            if detection_results and len(detection_results) > 0:
                det_result = detection_results[0]
                bboxes = getattr(det_result, 'bboxes', [])

                inv_scale = 1.0 / scale if scale != 1.0 else 1.0

                for idx, polygon_box in enumerate(bboxes):
                    # Surya detection ã® PolygonBox.bbox ã¯ [x_min, y_min, x_max, y_max] å½¢å¼
                    bbox = polygon_box.bbox
                    confidence = polygon_box.confidence if polygon_box.confidence is not None else 0.5
                    if len(bbox) >= 4:
                        x1, y1, x2, y2 = bbox[:4]
                        region = {
                            "bbox": {
                                "x": int(x1 * inv_scale),
                                "y": int(y1 * inv_scale),
                                "width": int((x2 - x1) * inv_scale),
                                "height": int((y2 - y1) * inv_scale),
                                "points": [
                                    {"x": float(x1 * inv_scale), "y": float(y1 * inv_scale)},
                                    {"x": float(x2 * inv_scale), "y": float(y1 * inv_scale)},
                                    {"x": float(x2 * inv_scale), "y": float(y2 * inv_scale)},
                                    {"x": float(x1 * inv_scale), "y": float(y2 * inv_scale)},
                                ]
                            },
                            # Detection confidenceï¼ˆPolygonBoxã‹ã‚‰å–å¾—ï¼‰
                            "confidence": confidence,
                            "region_index": idx
                        }
                        regions.append(region)

            self.logger.info(f"Detection-Onlyå®Œäº†: {len(regions)}é ˜åŸŸæ¤œå‡º ({elapsed*1000:.0f}ms)")

            return {
                "success": True,
                "regions": regions,
                "processing_time_ms": int(elapsed * 1000),
                "engine_name": "Surya OCR (Detection-Only)",
                "engine_version": self.VERSION
            }

        except Exception as e:
            self.logger.exception(f"Detection-Onlyã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e),
                "regions": [],
                "processing_time_ms": 0,
                "engine_name": "Surya OCR (Detection-Only)",
                "engine_version": self.VERSION
            }


# ============================================================================
# OCR Servicer (éåŒæœŸç‰ˆ)
# ============================================================================

class AsyncOcrServiceServicer(ocr_pb2_grpc.OcrServiceServicer):
    """gRPC OCRã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£… (éåŒæœŸç‰ˆ)"""

    def __init__(self, engine: SuryaOcrEngine):
        self.engine = engine
        self.executor = ThreadPoolExecutor(max_workers=1)
        self.logger = logging.getLogger(f"{__name__}.AsyncOcrServiceServicer")

    async def Recognize(self, request, context):
        """OCRèªè­˜ã‚’å®Ÿè¡Œ"""
        self.logger.info(f"Recognize RPC called - request_id: {request.request_id}")

        try:
            languages = list(request.languages) if request.languages else None

            # åŒæœŸå‡¦ç†ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§å®Ÿè¡Œ
            loop = asyncio.get_running_loop()
            result = await loop.run_in_executor(
                self.executor,
                self.engine.recognize,
                request.image_data,
                languages
            )

            response = ocr_pb2.OcrResponse()
            response.request_id = request.request_id
            response.is_success = result["success"]
            response.processing_time_ms = result["processing_time_ms"]
            response.engine_name = result["engine_name"]
            response.engine_version = result["engine_version"]
            response.region_count = len(result["regions"])

            for region_data in result["regions"]:
                region = response.regions.add()
                region.text = region_data["text"]
                region.confidence = region_data["confidence"]
                region.line_index = region_data["line_index"]

                bbox = region_data["bbox"]
                region.bounding_box.x = bbox["x"]
                region.bounding_box.y = bbox["y"]
                region.bounding_box.width = bbox["width"]
                region.bounding_box.height = bbox["height"]

                for point in bbox["points"]:
                    p = region.bounding_box.points.add()
                    p.x = point["x"]
                    p.y = point["y"]

            response.timestamp.FromDatetime(datetime.utcnow())
            return response

        except Exception as e:
            self.logger.error(f"Recognize error: {e}")
            response = ocr_pb2.OcrResponse()
            response.request_id = request.request_id
            response.is_success = False
            response.error.error_type = ocr_pb2.OCR_ERROR_TYPE_PROCESSING_ERROR
            response.error.message = str(e)
            response.timestamp.FromDatetime(datetime.utcnow())
            return response

    async def HealthCheck(self, request, context):
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        response = ocr_pb2.OcrHealthCheckResponse()
        response.is_healthy = self.engine.is_loaded
        response.status = "healthy" if self.engine.is_loaded else "unhealthy"
        response.details["engine"] = "Surya OCR"
        response.details["loaded"] = str(self.engine.is_loaded)
        response.timestamp.FromDatetime(datetime.utcnow())
        return response

    async def IsReady(self, request, context):
        """æº–å‚™çŠ¶æ…‹ç¢ºèª"""
        response = ocr_pb2.OcrIsReadyResponse()
        response.is_ready = self.engine.is_loaded
        response.status = "ready" if self.engine.is_loaded else "loading"
        response.details["engine"] = "Surya OCR"
        response.details["version"] = self.engine.VERSION
        response.timestamp.FromDatetime(datetime.utcnow())
        return response

    async def RecognizeBatch(self, request, context):
        """[Issue #330] ãƒãƒƒãƒèªè­˜RPC

        è¤‡æ•°ã®ç”»åƒé ˜åŸŸã‚’ä¸€æ‹¬ã§OCRå‡¦ç†ã—ã€gRPCå‘¼ã³å‡ºã—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å‰Šæ¸›ã€‚
        éƒ¨åˆ†OCRã§15é ˜åŸŸã‚’å‡¦ç†ã™ã‚‹å ´åˆ: 15å›â†’1å›ã®gRPCå‘¼ã³å‡ºã—ã«å‰Šæ¸›ã€‚

        Note: Pythonã‚µãƒ¼ãƒãƒ¼ã¯max_workers=1ã®ãŸã‚ã€å†…éƒ¨çš„ã«ã¯é€æ¬¡å‡¦ç†ã€‚
        gRPCå‘¼ã³å‡ºã—å›æ•°å‰Šæ¸›ã«ã‚ˆã‚‹é«˜é€ŸåŒ–ãŒãƒ¡ãƒªãƒƒãƒˆã€‚
        """
        batch_start = time.time()
        self.logger.info(f"RecognizeBatch RPC called - batch_id: {request.batch_id}, count: {len(request.requests)}")

        response = ocr_pb2.RecognizeBatchResponse()
        response.batch_id = request.batch_id
        response.total_count = len(request.requests)

        try:
            success_count = 0
            loop = asyncio.get_running_loop()

            for ocr_request in request.requests:
                try:
                    languages = list(ocr_request.languages) if ocr_request.languages else None

                    # åŒæœŸå‡¦ç†ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§å®Ÿè¡Œï¼ˆé€æ¬¡ï¼‰
                    result = await loop.run_in_executor(
                        self.executor,
                        self.engine.recognize,
                        ocr_request.image_data,
                        languages
                    )

                    ocr_response = response.responses.add()
                    ocr_response.request_id = ocr_request.request_id
                    ocr_response.is_success = result["success"]
                    ocr_response.processing_time_ms = result["processing_time_ms"]
                    ocr_response.engine_name = result["engine_name"]
                    ocr_response.engine_version = result["engine_version"]
                    ocr_response.region_count = len(result["regions"])

                    for region_data in result["regions"]:
                        region = ocr_response.regions.add()
                        region.text = region_data["text"]
                        region.confidence = region_data["confidence"]
                        region.line_index = region_data["line_index"]

                        bbox = region_data["bbox"]
                        region.bounding_box.x = bbox["x"]
                        region.bounding_box.y = bbox["y"]
                        region.bounding_box.width = bbox["width"]
                        region.bounding_box.height = bbox["height"]

                        for point in bbox["points"]:
                            p = region.bounding_box.points.add()
                            p.x = point["x"]
                            p.y = point["y"]

                    ocr_response.timestamp.FromDatetime(datetime.utcnow())

                    if result["success"]:
                        success_count += 1

                except Exception as e:
                    self.logger.error(f"RecognizeBatch item error (request_id: {ocr_request.request_id}): {e}")
                    ocr_response = response.responses.add()
                    ocr_response.request_id = ocr_request.request_id
                    ocr_response.is_success = False
                    ocr_response.error.error_type = ocr_pb2.OCR_ERROR_TYPE_PROCESSING_ERROR
                    ocr_response.error.message = str(e)
                    ocr_response.timestamp.FromDatetime(datetime.utcnow())

            response.success_count = success_count
            response.is_success = success_count > 0
            response.total_processing_time_ms = int((time.time() - batch_start) * 1000)
            response.timestamp.FromDatetime(datetime.utcnow())

            self.logger.info(f"RecognizeBatch completed: {success_count}/{len(request.requests)} success, {response.total_processing_time_ms}ms total")
            return response

        except Exception as e:
            self.logger.error(f"RecognizeBatch error: {e}")
            response.is_success = False
            response.error.error_type = ocr_pb2.OCR_ERROR_TYPE_PROCESSING_ERROR
            response.error.message = str(e)
            response.timestamp.FromDatetime(datetime.utcnow())
            return response

    async def Detect(self, request, context):
        """[Issue #320] Detection-Only RPC

        ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã®ä½ç½®ã®ã¿ã‚’æ¤œå‡ºï¼ˆRecognitionã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰ã€‚
        ROIå­¦ç¿’ç”¨ã®é«˜é€Ÿæ¤œå‡ºã«ä½¿ç”¨ã€‚
        å‡¦ç†æ™‚é–“: ~100msï¼ˆé€šå¸¸ã®Recognize: ~1000msï¼‰
        """
        self.logger.info(f"Detect RPC called - request_id: {request.request_id}")

        try:
            # åŒæœŸå‡¦ç†ã‚’ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã§å®Ÿè¡Œ
            loop = asyncio.get_running_loop()
            result = await loop.run_in_executor(
                self.executor,
                self.engine.detect_only,
                request.image_data
            )

            response = ocr_pb2.DetectResponse()
            response.request_id = request.request_id
            response.is_success = result["success"]
            response.processing_time_ms = result["processing_time_ms"]
            response.engine_name = result["engine_name"]
            response.region_count = len(result["regions"])

            for region_data in result["regions"]:
                region = response.regions.add()
                region.confidence = region_data["confidence"]
                region.region_index = region_data["region_index"]

                bbox = region_data["bbox"]
                region.bounding_box.x = bbox["x"]
                region.bounding_box.y = bbox["y"]
                region.bounding_box.width = bbox["width"]
                region.bounding_box.height = bbox["height"]

                for point in bbox["points"]:
                    p = region.bounding_box.points.add()
                    p.x = point["x"]
                    p.y = point["y"]

            response.timestamp.FromDatetime(datetime.utcnow())
            return response

        except Exception as e:
            self.logger.error(f"Detect error: {e}")
            response = ocr_pb2.DetectResponse()
            response.request_id = request.request_id
            response.is_success = False
            response.error.error_type = ocr_pb2.OCR_ERROR_TYPE_PROCESSING_ERROR
            response.error.message = str(e)
            response.timestamp.FromDatetime(datetime.utcnow())
            return response


# ============================================================================
# Graceful Shutdown Handler
# ============================================================================

class GracefulShutdown:
    """ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""

    def __init__(self):
        self.shutdown_event = asyncio.Event()

    def __enter__(self):
        def signal_handler(signum, frame):
            logger.info(f"Received signal {signum}, shutting down gracefully...")
            asyncio.create_task(self._async_shutdown())

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        pass

    async def _async_shutdown(self):
        self.shutdown_event.set()

    async def wait_for_shutdown(self):
        await self.shutdown_event.wait()


# ============================================================================
# Device Detection (Gemini Review: torch.cuda.is_available()æ¨å¥¨)
# ============================================================================

def detect_device() -> tuple[str, str | None]:
    """ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡ºï¼ˆCUDA_VISIBLE_DEVICESç’°å¢ƒå¤‰æ•°ã‚’å°Šé‡ï¼‰

    Returns:
        tuple: (device, gpu_name)
            - device: "cuda" or "cpu"
            - gpu_name: GPUåï¼ˆCPUãƒ¢ãƒ¼ãƒ‰æ™‚ã¯Noneï¼‰
    """
    import torch

    # torch.cuda.is_available() ã¯ CUDA_VISIBLE_DEVICES="" ã‚’è‡ªå‹•çš„ã«è§£é‡ˆ
    if not torch.cuda.is_available():
        cuda_visible = os.environ.get("CUDA_VISIBLE_DEVICES", None)
        if cuda_visible == "" or cuda_visible == "-1":
            logger.info(f"CUDA_VISIBLE_DEVICES='{cuda_visible}' - CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
        else:
            logger.info("CUDAåˆ©ç”¨ä¸å¯ - CPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
        return "cpu", None

    # GPUæƒ…å ±å–å¾—
    gpu_name = torch.cuda.get_device_name(0)
    logger.info(f"CUDAåˆ©ç”¨å¯èƒ½: {gpu_name}")
    return "cuda", gpu_name


def get_available_vram_mb() -> float:
    """åˆ©ç”¨å¯èƒ½ãªVRAMé‡ã‚’å–å¾— (MB)"""
    try:
        import torch
        if torch.cuda.is_available():
            props = torch.cuda.get_device_properties(0)
            return props.total_memory / 1024 / 1024  # MB
    except Exception:
        pass
    return 0.0


def should_use_parallel_loading(device: str) -> bool:
    """ä¸¦åˆ—ãƒ­ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š

    Args:
        device: "cuda" or "cpu"

    Returns:
        True: ä¸¦åˆ—ãƒ­ãƒ¼ãƒ‰ï¼ˆVRAM 8GBä»¥ä¸Šã®GPUï¼‰
        False: é€æ¬¡ãƒ­ãƒ¼ãƒ‰ï¼ˆVRAMä¸è¶³ã¾ãŸã¯CPUãƒ¢ãƒ¼ãƒ‰ï¼‰
    """
    if device == "cpu":
        logger.info("CPUãƒ¢ãƒ¼ãƒ‰ - é€æ¬¡ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚’ä½¿ç”¨")
        return False

    vram_mb = get_available_vram_mb()
    if vram_mb >= 8192:  # 8GB
        logger.info(f"VRAM: {vram_mb:.0f}MB - ä¸¦åˆ—ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚’ä½¿ç”¨")
        return True
    elif vram_mb > 0:
        logger.info(f"VRAM: {vram_mb:.0f}MB - é€æ¬¡ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ (VRAMç¯€ç´„)")
        return False
    else:
        logger.info("VRAMæ¤œå‡ºå¤±æ•— - é€æ¬¡ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚’ä½¿ç”¨")
        return False


# ============================================================================
# Main Server
# ============================================================================

async def serve(host: str, port: int, model_path_arg: str | None = None):
    """çµ±åˆgRPCã‚µãƒ¼ãƒãƒ¼èµ·å‹•"""
    logger.info("=" * 80)
    logger.info("Baketa Unified AI Server Starting...")
    logger.info("Issue #292: OCR + Translation in single process")
    logger.info("=" * 80)

    # ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡ºï¼ˆCUDA_VISIBLE_DEVICESç’°å¢ƒå¤‰æ•°ã‚’å°Šé‡ï¼‰
    device, gpu_name = detect_device()
    if gpu_name:
        logger.info(f"GPU: {gpu_name}")

    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹æ±ºå®š (ç¿»è¨³ç”¨)
    if model_path_arg:
        translation_model_path = Path(model_path_arg)
    else:
        appdata = os.environ.get('APPDATA', os.path.expanduser('~'))
        # ğŸ”¥ [Issue #337] 600Mãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´ï¼ˆ5.5GB â†’ 1GBï¼‰
        translation_model_path = Path(appdata) / "Baketa" / "Models" / "nllb-200-distilled-600M-ct2"

    logger.info(f"Translation model path: {translation_model_path}")
    logger.info(f"Device: {device}")

    # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    # ğŸ”¥ [Issue #337] CTranslate2Engineã‚’LazyLoadingTranslatorã§ãƒ©ãƒƒãƒ—
    # ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã¯åˆå›ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã«ãƒ­ãƒ¼ãƒ‰ã€5åˆ†ã‚¢ã‚¤ãƒ‰ãƒ«ã§ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰
    base_translation_engine = CTranslate2Engine(
        model_path=str(translation_model_path),
        device=device,
        compute_type="int8",
        enable_flash_attention=False  # RTX 40ã‚·ãƒªãƒ¼ã‚ºã§Flash Attention 2éå¯¾å¿œã®ãŸã‚ç„¡åŠ¹åŒ–
    )
    translation_engine = LazyLoadingTranslator(
        engine=base_translation_engine,
        idle_timeout_seconds=300  # 5åˆ†ã‚¢ã‚¤ãƒ‰ãƒ«ã§ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰
    )

    ocr_engine = SuryaOcrEngine(device=device)

    # ğŸ”¥ [Issue #337] OCRã®ã¿äº‹å‰ãƒ­ãƒ¼ãƒ‰ï¼ˆç¿»è¨³ã¯é…å»¶ãƒ­ãƒ¼ãƒ‰ï¼‰
    # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ (ä¸¦åˆ— or é€æ¬¡)
    use_parallel = should_use_parallel_loading(device)

    logger.info("=" * 80)
    logger.info("Loading AI Models...")
    logger.info("=" * 80)

    load_start = time.time()

    # [Gemini Review Fix] åˆæœŸåŒ–å¤±æ•—æ™‚ã¯ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã—ã¦C#å´ã«é€šçŸ¥
    # ğŸ”¥ [Issue #337] OCRã®ã¿äº‹å‰ãƒ­ãƒ¼ãƒ‰ã€ç¿»è¨³ã¯é…å»¶ãƒ­ãƒ¼ãƒ‰
    try:
        # ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã¯é…å»¶ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã«LazyLoadingTranslatorãŒãƒ­ãƒ¼ãƒ‰ï¼‰
        logger.info("[Translation] Lazy loading enabled - will load on first request")
        logger.info("[Translation] Model: NLLB-200-distilled-600M (~1GB)")
        logger.info("[Translation] Idle timeout: 300 seconds (auto-unload)")

        # OCRãƒ¢ãƒ‡ãƒ«ã®ã¿äº‹å‰ãƒ­ãƒ¼ãƒ‰
        logger.info("[OCR] Loading Surya OCR...")
        sys.stdout.flush()
        await ocr_engine.load_model()
        logger.info("[OCR] Model loaded successfully")

        load_elapsed = time.time() - load_start
        logger.info(f"OCR model loaded in {load_elapsed:.2f} seconds")
        sys.stdout.flush()

    except Exception as e:
        logger.critical("=" * 80)
        logger.critical("INITIALIZATION FAILED - CRITICAL ERROR")
        logger.critical("=" * 80)
        logger.critical(f"Failed to load AI models: {e}")
        logger.critical(traceback.format_exc())
        logger.critical("Server cannot start without models. Exiting...")
        sys.exit(1)

    # gRPCã‚µãƒ¼ãƒãƒ¼ä½œæˆ
    logger.info("Creating unified gRPC server...")

    MAX_MESSAGE_LENGTH = 50 * 1024 * 1024  # 50MB (é«˜è§£åƒåº¦ç”»åƒå¯¾å¿œ)

    server = aio.server(options=[
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚µã‚¤ã‚ºåˆ¶é™
        ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),
        ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),
        # KeepAliveè¨­å®š
        ('grpc.keepalive_time_ms', 30000),
        ('grpc.keepalive_timeout_ms', 10000),
        ('grpc.keepalive_permit_without_calls', True),
        ('grpc.http2.min_time_between_pings_ms', 10000),
        ('grpc.http2.max_pings_without_data', 0),
        ('grpc.http2.min_ping_interval_without_data_ms', 10000),
    ])

    # ã‚µãƒ¼ãƒ“ã‚¹ç™»éŒ²
    translation_servicer = TranslationServicer(translation_engine)
    translation_pb2_grpc.add_TranslationServiceServicer_to_server(translation_servicer, server)

    ocr_servicer = AsyncOcrServiceServicer(ocr_engine)
    ocr_pb2_grpc.add_OcrServiceServicer_to_server(ocr_servicer, server)

    # ãƒªã‚¹ãƒ‹ãƒ³ã‚°ã‚¢ãƒ‰ãƒ¬ã‚¹è¨­å®š
    listen_addr = f'{host}:{port}'
    server.add_insecure_port(listen_addr)

    logger.info(f"Starting unified gRPC server on {listen_addr}...")
    sys.stdout.flush()
    await server.start()

    logger.info("=" * 80)
    logger.info(f"Baketa Unified AI Server is running on {listen_addr}")
    sys.stdout.flush()
    # ğŸ”¥ [Issue #337] LazyLoadingTranslatorä½¿ç”¨
    logger.info(f"   Translation Engine: {translation_engine.__class__.__name__}")
    logger.info(f"   Translation Model: {translation_engine.engine.model_name} (lazy loading)")
    logger.info(f"   OCR Engine: Surya OCR v{ocr_engine.VERSION}")
    logger.info(f"   Device: {device}")

    # C#å´ã¸ã®èµ·å‹•å®Œäº†ã‚·ã‚°ãƒŠãƒ«
    try:
        if sys.stderr is not None:
            sys.stderr.write("[SERVER_START]\n")
            sys.stderr.flush()
            logger.info("[SERVER_START] signal sent to stderr for C# detection")
    except (OSError, AttributeError):
        logger.info("[SERVER_START] signal skipped (stderr unavailable)")

    logger.info("=" * 80)
    logger.info("Services available:")
    logger.info("   - TranslationService (Translate, TranslateBatch, HealthCheck, IsReady)")
    logger.info("   - OcrService (Recognize, RecognizeBatch, Detect, HealthCheck, IsReady)")
    logger.info("   [Issue #320] Detect RPC: Detection-only for ROI learning (~10x faster)")
    logger.info("   [Issue #330] RecognizeBatch RPC: Batch OCR for partial regions")
    logger.info("   [Issue #337] Translation lazy loading: ~1GB memory saved until first use")
    logger.info("=" * 80)
    logger.info("Press Ctrl+C to stop the server")

    # ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–é–‹å§‹
    resource_monitor = ResourceMonitor(enable_gpu_monitoring=(device == "cuda"))
    await resource_monitor.start_monitoring(interval_seconds=300)
    logger.info("[Resource Monitor] Started (5-minute interval)")

    # [Gemini Review Fix] try-finallyã§ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ä¿è¨¼
    try:
        # ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å¾…æ©Ÿ
        with GracefulShutdown() as shutdown_handler:
            try:
                await shutdown_handler.wait_for_shutdown()
            except KeyboardInterrupt:
                logger.info("Received KeyboardInterrupt, shutting down...")
    finally:
        # ã‚µãƒ¼ãƒãƒ¼åœæ­¢ï¼ˆä¾‹å¤–ç™ºç”Ÿæ™‚ã‚‚å¿…ãšå®Ÿè¡Œï¼‰
        logger.info("Stopping unified gRPC server...")
        try:
            await server.stop(grace=5.0)
            logger.info("gRPC server stopped")
        except Exception as e:
            logger.warning(f"Error stopping gRPC server: {e}")

        # ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆä¾‹å¤–ç™ºç”Ÿæ™‚ã‚‚å¿…ãšå®Ÿè¡Œï¼‰
        try:
            await resource_monitor.stop_monitoring()
            resource_monitor.cleanup()
            logger.info("Resource monitoring cleanup completed")
        except Exception as e:
            logger.warning(f"Error cleaning up resource monitor: {e}")


def global_exception_handler(exc_type, exc_value, exc_traceback):
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¾‹å¤–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    if issubclass(exc_type, KeyboardInterrupt):
        sys.__excepthook__(exc_type, exc_value, exc_traceback)
        return

    logger.critical("=" * 80)
    logger.critical("UNCAUGHT EXCEPTION - CRITICAL ERROR")
    logger.critical("=" * 80)
    logger.critical(f"Exception Type: {exc_type.__name__}")
    logger.critical(f"Exception Value: {exc_value}")
    logger.critical("Traceback:")
    logger.critical("".join(traceback.format_exception(exc_type, exc_value, exc_traceback)))
    logger.critical("=" * 80)


def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãƒ‘ãƒ¼ã‚¹ & ã‚µãƒ¼ãƒãƒ¼èµ·å‹•"""
    faulthandler.enable(file=sys.stderr, all_threads=True)
    sys.excepthook = global_exception_handler

    parser = argparse.ArgumentParser(
        description="Baketa Unified AI Server (OCR + Translation)"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=50051,
        help="gRPC server port (default: 50051)"
    )
    parser.add_argument(
        "--host",
        type=str,
        default="127.0.0.1",
        help="gRPC server host (default: 127.0.0.1)"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug logging"
    )
    parser.add_argument(
        "--model-path",
        type=str,
        default=None,
        help="Path to translation model directory"
    )

    args = parser.parse_args()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    logger.info("Server configuration:")
    logger.info(f"  Host: {args.host}")
    logger.info(f"  Port: {args.port}")
    logger.info(f"  Model path: {args.model_path or '(default)'}")
    logger.info(f"  Debug mode: {args.debug}")

    try:
        asyncio.run(serve(
            host=args.host,
            port=args.port,
            model_path_arg=args.model_path
        ))
    except KeyboardInterrupt:
        logger.info("Server interrupted by user")
    except Exception as e:
        logger.exception(f"Server error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
