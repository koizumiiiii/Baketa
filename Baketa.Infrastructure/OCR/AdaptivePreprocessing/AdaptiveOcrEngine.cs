using System.Diagnostics;
using System.Drawing;
using Baketa.Core.Abstractions.Imaging;
using Baketa.Core.Abstractions.OCR;
using Baketa.Core.Models.OCR;
using Microsoft.Extensions.Logging;

namespace Baketa.Infrastructure.OCR.AdaptivePreprocessing;

/// <summary>
/// é©å¿œçš„å‰å‡¦ç†æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸOCRã‚¨ãƒ³ã‚¸ãƒ³ãƒ©ãƒƒãƒ‘ãƒ¼
/// </summary>
public class AdaptiveOcrEngine(
    IOcrEngine baseOcrEngine,
    IAdaptivePreprocessingParameterOptimizer parameterOptimizer,
    ILogger<AdaptiveOcrEngine> logger) : IOcrEngine
{
    private OcrEngineSettings? _currentSettings;

    // IOcrEngineãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å®Ÿè£…
    public string EngineName => $"Adaptive-{baseOcrEngine.EngineName}";
    public string EngineVersion => baseOcrEngine.EngineVersion;
    public bool IsInitialized => baseOcrEngine.IsInitialized;
    public string? CurrentLanguage => baseOcrEngine.CurrentLanguage;

    /// <summary>
    /// åˆæœŸåŒ–
    /// </summary>
    public async Task<bool> InitializeAsync(OcrEngineSettings? settings = null, CancellationToken cancellationToken = default)
    {
        logger.LogInformation("é©å¿œçš„OCRã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–é–‹å§‹");
        _currentSettings = settings;

        var result = await baseOcrEngine.InitializeAsync(settings, cancellationToken).ConfigureAwait(false);

        if (result)
        {
            logger.LogInformation("é©å¿œçš„OCRã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†");
        }
        else
        {
            logger.LogError("ãƒ™ãƒ¼ã‚¹OCRã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ");
        }

        return result;
    }

    public async Task<bool> WarmupAsync(CancellationToken cancellationToken = default)
    {
        return await baseOcrEngine.WarmupAsync(cancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// é©å¿œçš„å‰å‡¦ç†ã‚’é©ç”¨ã—ã¦OCRèªè­˜ã‚’å®Ÿè¡Œ
    /// </summary>
    public async Task<OcrResults> RecognizeAsync(IImage image, IProgress<OcrProgress>? progressCallback = null, CancellationToken cancellationToken = default)
    {
        // IAdvancedImageã«å¤‰æ›ãŒå¿…è¦ãªå ´åˆã®å‡¦ç†
        if (image is not IAdvancedImage advancedImage)
        {
            // ç°¡æ˜“å¤‰æ›ï¼ˆå®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã‚ˆã‚Šé©åˆ‡ãªå¤‰æ›ãŒå¿…è¦ï¼‰
            var imageBytes = await image.ToByteArrayAsync().ConfigureAwait(false);
            advancedImage = new Core.Services.Imaging.AdvancedImage(imageBytes, image.Width, image.Height,
                image.Format == Core.Abstractions.Imaging.ImageFormat.Png
                    ? Core.Abstractions.Imaging.ImageFormat.Png
                    : Core.Abstractions.Imaging.ImageFormat.Rgb24);
        }

        return await RecognizeAdvancedAsync(advancedImage, progressCallback, cancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// é ˜åŸŸæŒ‡å®šã§ã®èªè­˜
    /// </summary>
    public async Task<OcrResults> RecognizeAsync(IImage image, Rectangle? regionOfInterest = null, IProgress<OcrProgress>? progressCallback = null, CancellationToken cancellationToken = default)
    {
        // ç°¡æ˜“å®Ÿè£…ï¼šé ˜åŸŸæŒ‡å®šã¯ç„¡è¦–ã—ã¦ãƒ•ãƒ«ç”»åƒã§å‡¦ç†
        return await RecognizeAsync(image, progressCallback, cancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// [Option B] OcrContextã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’èªè­˜ã—ã¾ã™ï¼ˆåº§æ¨™å•é¡Œæ’ä¹…å¯¾å¿œï¼‰
    /// </summary>
    public async Task<OcrResults> RecognizeAsync(OcrContext context, IProgress<OcrProgress>? progressCallback = null)
    {
        ArgumentNullException.ThrowIfNull(context);

        logger.LogInformation("ğŸ¯ [OPTION_B] AdaptiveOcrEngine - OcrContextä½¿ç”¨ã®RecognizeAsyncå‘¼ã³å‡ºã—");

        // æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã«å§”è­²
        return await RecognizeAsync(
            context.Image,
            context.CaptureRegion,
            progressCallback,
            context.CancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// IAdvancedImageç”¨ã®å†…éƒ¨èªè­˜ãƒ¡ã‚½ãƒƒãƒ‰
    /// </summary>
    private async Task<OcrResults> RecognizeAdvancedAsync(IAdvancedImage image, IProgress<OcrProgress>? progressCallback = null, CancellationToken cancellationToken = default)
    {
        var sw = Stopwatch.StartNew();
        logger.LogInformation("é©å¿œçš„OCRèªè­˜é–‹å§‹: {Width}x{Height}", image.Width, image.Height);

        try
        {
            // Step 1: é©å¿œçš„å‰å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–
            var optimizationResult = await parameterOptimizer.OptimizeWithDetailsAsync(image).ConfigureAwait(false);

            logger.LogInformation(
                "å‰å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–å®Œäº†: æˆ¦ç•¥={Strategy}, æ”¹å–„äºˆæƒ³={Improvement:F2} ({OptimizationMs}ms)",
                optimizationResult.OptimizationStrategy,
                optimizationResult.ExpectedImprovement,
                optimizationResult.OptimizationTimeMs);

            // Step 2: æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§OCRè¨­å®šã‚’èª¿æ•´
            var optimizedSettings = CreateOptimizedSettings(optimizationResult.Parameters);

            // Step 3: å‰å‡¦ç†ã•ã‚ŒãŸç”»åƒã§OCRå®Ÿè¡Œ
            var preprocessedImage = await ApplyPreprocessingAsync(image, optimizationResult.Parameters).ConfigureAwait(false);

            // Step 4: æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§OCRèªè­˜
            var ocrResults = await RecognizeWithOptimizedSettingsAsync(preprocessedImage, optimizedSettings).ConfigureAwait(false);

            // Step 5: çµæœã«æœ€é©åŒ–æƒ…å ±ã‚’ä»˜åŠ 
            var enhancedResults = EnhanceResultsWithOptimizationInfo(ocrResults, optimizationResult);

            logger.LogInformation(
                "é©å¿œçš„OCRèªè­˜å®Œäº†: {Regions}ãƒªãƒ¼ã‚¸ãƒ§ãƒ³æ¤œå‡º, ç·æ™‚é–“={TotalMs}ms (æœ€é©åŒ–={OptMs}ms, OCR={OcrMs}ms)",
                enhancedResults.TextRegions.Count,
                sw.ElapsedMilliseconds,
                optimizationResult.OptimizationTimeMs,
                sw.ElapsedMilliseconds - optimizationResult.OptimizationTimeMs);

            return enhancedResults;
        }
        catch (Exception ex)
        {
            logger.LogError(ex, "é©å¿œçš„OCRèªè­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ");

            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®OCRå‡¦ç†
            logger.LogInformation("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®OCRå‡¦ç†ã‚’å®Ÿè¡Œ");
            return await baseOcrEngine.RecognizeAsync(image, progressCallback, cancellationToken).ConfigureAwait(false);
        }
    }

    /// <summary>
    /// è¨­å®šå–å¾—
    /// </summary>
    public OcrEngineSettings GetSettings()
    {
        return baseOcrEngine.GetSettings() ?? new OcrEngineSettings();
    }

    /// <summary>
    /// è¨­å®šé©ç”¨
    /// </summary>
    public async Task ApplySettingsAsync(OcrEngineSettings settings, CancellationToken cancellationToken = default)
    {
        _currentSettings = settings;
        await baseOcrEngine.ApplySettingsAsync(settings, cancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// åˆ©ç”¨å¯èƒ½è¨€èªå–å¾—
    /// </summary>
    public IReadOnlyList<string> GetAvailableLanguages()
    {
        return [.. baseOcrEngine.GetAvailableLanguages()];
    }

    /// <summary>
    /// åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«å–å¾—
    /// </summary>
    public IReadOnlyList<string> GetAvailableModels()
    {
        return [.. baseOcrEngine.GetAvailableModels()];
    }

    /// <summary>
    /// è¨€èªåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    /// </summary>
    public async Task<bool> IsLanguageAvailableAsync(string languageCode, CancellationToken cancellationToken = default)
    {
        return await baseOcrEngine.IsLanguageAvailableAsync(languageCode, cancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆå–å¾—
    /// </summary>
    public OcrPerformanceStats GetPerformanceStats()
    {
        return baseOcrEngine.GetPerformanceStats() ?? new OcrPerformanceStats();
    }

    /// <summary>
    /// é€²è¡Œä¸­ã®OCRã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    /// </summary>
    public void CancelCurrentOcrTimeout()
    {
        // ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³ãŒPaddleOcrEngineã®å ´åˆã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«å‡¦ç†ã‚’è»¢é€
        baseOcrEngine.CancelCurrentOcrTimeout();
    }

    /// <summary>
    /// ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºã®ã¿ã‚’å®Ÿè¡Œï¼ˆèªè­˜å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    /// </summary>
    public async Task<OcrResults> DetectTextRegionsAsync(IImage image, CancellationToken cancellationToken = default)
    {
        // ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³ã«æ¤œå‡ºå°‚ç”¨å‡¦ç†ã‚’å§”ä»»
        return await baseOcrEngine.DetectTextRegionsAsync(image, cancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// é€£ç¶šå¤±æ•—å›æ•°ã‚’å–å¾—ï¼ˆè¨ºæ–­ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤å®šç”¨ï¼‰
    /// </summary>
    /// <returns>é€£ç¶šå¤±æ•—å›æ•°</returns>
    public int GetConsecutiveFailureCount()
    {
        // ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³ã«å§”è­²
        return baseOcrEngine.GetConsecutiveFailureCount();
    }

    /// <summary>
    /// å¤±æ•—ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆç·Šæ€¥æ™‚å¾©æ—§ç”¨ï¼‰
    /// </summary>
    public void ResetFailureCounter()
    {
        // ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³ã«å§”è­²
        baseOcrEngine.ResetFailureCounter();
    }

    /// <summary>
    /// Disposeå®Ÿè£…
    /// </summary>
    public void Dispose()
    {
        baseOcrEngine?.Dispose();
        GC.SuppressFinalize(this);
    }

    /// <summary>
    /// ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
    /// </summary>
    public async ValueTask DisposeAsync()
    {
        logger.LogInformation("é©å¿œçš„OCRã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã—ã¾ã™");

        if (baseOcrEngine is IAsyncDisposable asyncDisposable)
        {
            await asyncDisposable.DisposeAsync().ConfigureAwait(false);
        }
        else if (baseOcrEngine is IDisposable disposable)
        {
            disposable.Dispose();
        }
    }

    /// <summary>
    /// æœ€é©åŒ–ã•ã‚ŒãŸOCRè¨­å®šã‚’ä½œæˆ
    /// </summary>
    private OcrEngineSettings CreateOptimizedSettings(AdaptivePreprocessingParameters parameters)
    {
        if (_currentSettings == null)
        {
            return new OcrEngineSettings
            {
                DetectionThreshold = parameters.DetectionThreshold,
                RecognitionThreshold = parameters.RecognitionThreshold
            };
        }

        return new OcrEngineSettings
        {
            Language = _currentSettings.Language,
            DetectionThreshold = parameters.DetectionThreshold,
            RecognitionThreshold = parameters.RecognitionThreshold
        };
    }

    /// <summary>
    /// å‰å‡¦ç†ã‚’é©ç”¨ã—ãŸç”»åƒã‚’ä½œæˆ
    /// </summary>
    private async Task<IAdvancedImage> ApplyPreprocessingAsync(
        IAdvancedImage originalImage,
        AdaptivePreprocessingParameters parameters)
    {
        return await Task.Run(() =>
        {
            try
            {
                // å®Ÿéš›ã®ç”»åƒå‰å‡¦ç†ã¯ã“ã“ã§å®Ÿè£…
                // ç¾åœ¨ã¯ç°¡æ˜“å®Ÿè£…ã¨ã—ã¦å…ƒç”»åƒã‚’ãã®ã¾ã¾è¿”ã™
                logger.LogDebug("å‰å‡¦ç†é©ç”¨: Î³={Gamma:F2}, C={Contrast:F2}, B={Brightness:F2}",
                    parameters.Gamma, parameters.Contrast, parameters.Brightness);

                // TODO: å®Ÿéš›ã®å‰å‡¦ç†å®Ÿè£…
                // - ã‚¬ãƒ³ãƒè£œæ­£
                // - ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´  
                // - æ˜åº¦èª¿æ•´
                // - ãƒã‚¤ã‚ºé™¤å»
                // - ã‚·ãƒ£ãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°
                // - äºŒå€¤åŒ–
                // - ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†

                return originalImage; // æš«å®šçš„ã«å…ƒç”»åƒã‚’è¿”ã™
            }
            catch (Exception ex)
            {
                logger.LogWarning(ex, "å‰å‡¦ç†é©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å…ƒç”»åƒã‚’ä½¿ç”¨ã—ã¾ã™");
                return originalImage;
            }
        }).ConfigureAwait(false);
    }

    /// <summary>
    /// æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§OCRèªè­˜ã‚’å®Ÿè¡Œ
    /// </summary>
    private async Task<OcrResults> RecognizeWithOptimizedSettingsAsync(
        IAdvancedImage image,
        OcrEngineSettings optimizedSettings)
    {
        // è¨­å®šã‚’ä¸€æ™‚çš„ã«å¤‰æ›´ã—ã¦OCRå®Ÿè¡Œ
        var originalSettings = _currentSettings;

        try
        {
            // æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§å†åˆæœŸåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            if (ShouldReinitialize(originalSettings, optimizedSettings))
            {
                await baseOcrEngine.InitializeAsync(optimizedSettings).ConfigureAwait(false);
                _currentSettings = optimizedSettings;
            }

            return await baseOcrEngine.RecognizeAsync(image).ConfigureAwait(false);
        }
        finally
        {
            // å¿…è¦ã«å¿œã˜ã¦å…ƒã®è¨­å®šã«æˆ»ã™
            if (originalSettings != null && ShouldReinitialize(optimizedSettings, originalSettings))
            {
                await baseOcrEngine.InitializeAsync(originalSettings).ConfigureAwait(false);
                _currentSettings = originalSettings;
            }
        }
    }

    /// <summary>
    /// è¨­å®šå¤‰æ›´ã®ãŸã‚ã«å†åˆæœŸåŒ–ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
    /// </summary>
    private bool ShouldReinitialize(OcrEngineSettings? current, OcrEngineSettings? target)
    {
        if (current == null || target == null) return true;

        // é–¾å€¤ã®å·®ãŒå¤§ãã„å ´åˆã®ã¿å†åˆæœŸåŒ–
        var detectionDiff = Math.Abs(current.DetectionThreshold - target.DetectionThreshold);
        var recognitionDiff = Math.Abs(current.RecognitionThreshold - target.RecognitionThreshold);

        return detectionDiff > 0.1 || recognitionDiff > 0.1;
    }

    /// <summary>
    /// OCRçµæœã«æœ€é©åŒ–æƒ…å ±ã‚’ä»˜åŠ 
    /// </summary>
    private OcrResults EnhanceResultsWithOptimizationInfo(
        OcrResults originalResults,
        AdaptivePreprocessingResult optimizationResult)
    {
        // æœ€é©åŒ–æƒ…å ±ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿½åŠ ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        // æ³¨ï¼šOcrResultsã«ã¯ç¾åœ¨Metadataãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒãªã„ãŸã‚ã€å…ƒã®çµæœã‚’ãã®ã¾ã¾è¿”ã™
        // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€OcrResultsã«æ‹¡å¼µãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™

        logger.LogInformation(
            "é©å¿œçš„å‰å‡¦ç†ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: æˆ¦ç•¥={Strategy}, ç†ç”±={Reason}, æ”¹å–„äºˆæƒ³={Improvement:F2}, ä¿¡é ¼åº¦={Confidence:F2}",
            optimizationResult.OptimizationStrategy,
            optimizationResult.OptimizationReason,
            optimizationResult.ExpectedImprovement,
            optimizationResult.ParameterConfidence);

        return originalResults;
    }
}
