using System.Buffers;
using System.Diagnostics;
using System.Drawing;
using System.IO;
using Baketa.Core.Abstractions.GPU;
using Baketa.Core.Abstractions.Imaging;
using Baketa.Core.Abstractions.OCR;
using Baketa.Core.Models.OCR;
using Baketa.Infrastructure.OCR.GPU;
using Microsoft.Extensions.Logging;
using Microsoft.ML.OnnxRuntime;
using Microsoft.ML.OnnxRuntime.Tensors;
using OpenCvSharp;
using Baketa.Infrastructure.OCR.Preprocessing;

// å‹ã‚¨ã‚¤ãƒªã‚¢ã‚¹: System.Drawingã¨OpenCvSharpã®æ›–æ˜§ã•è§£æ¶ˆ
using DrawingPoint = System.Drawing.Point;
using CvPoint = OpenCvSharp.Point;

namespace Baketa.Infrastructure.OCR.ONNX;

/// <summary>
/// ONNX Runtime ãƒ™ãƒ¼ã‚¹ã® OCR ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…
/// Issue #181: GPU/CPU è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆå¯¾å¿œ
/// PP-OCRv5 ONNX ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
/// </summary>
public sealed class OnnxOcrEngine : IOcrEngine
{
    #region PP-OCRv5 ãƒ¢ãƒ‡ãƒ«å®šæ•°

    // === æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ï¼ˆDBNetï¼‰å‰å‡¦ç†å®šæ•° ===
    /// <summary>æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ç”»åƒã‚µã‚¤ã‚ºï¼ˆæ­£æ–¹å½¢ï¼‰</summary>
    private const int DetectionTargetSize = 960;

    /// <summary>ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ç”¨ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆ32ã®å€æ•°ã«èª¿æ•´ï¼‰</summary>
    private const int PaddingAlignment = 32;

    // ImageNetæ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆRGBé †ï¼‰
    /// <summary>ImageNetæ­£è¦åŒ– - å¹³å‡å€¤ (R, G, B)</summary>
    private static readonly float[] ImageNetMean = [0.485f, 0.456f, 0.406f];

    /// <summary>ImageNetæ­£è¦åŒ– - æ¨™æº–åå·® (R, G, B)</summary>
    private static readonly float[] ImageNetStd = [0.229f, 0.224f, 0.225f];

    // === èªè­˜ãƒ¢ãƒ‡ãƒ«å‰å‡¦ç†å®šæ•° ===
    /// <summary>èªè­˜ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›é«˜ã•ï¼ˆå›ºå®šï¼‰ - PP-OCRv5ã¯48ã‚’ä½¿ç”¨</summary>
    private const int RecognitionTargetHeight = 48;

    /// <summary>èªè­˜ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§å…¥åŠ›å¹…</summary>
    private const int RecognitionMaxWidth = 320;

    /// <summary>èªè­˜ãƒ¢ãƒ‡ãƒ«æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¹³å‡ãƒ»æ¨™æº–åå·®å…±é€šï¼‰</summary>
    private const float RecognitionNormFactor = 0.5f;

    // === å¾Œå‡¦ç†å®šæ•° ===
    /// <summary>æ¤œå‡ºé ˜åŸŸã®æœ€å°é¢ç©ï¼ˆãƒ”ã‚¯ã‚»ãƒ«^2ï¼‰</summary>
    private const double MinContourArea = 100.0;

    /// <summary>ç¸¦æ›¸ãåˆ¤å®šã®é«˜ã•/å¹…æ¯”é–¾å€¤</summary>
    private const double VerticalTextRatio = 1.5;

    #endregion

    private readonly IUnifiedGpuOptimizer _gpuOptimizer;
    private readonly IPpOcrv5ModelConfiguration _modelConfig;
    private readonly ILogger<OnnxOcrEngine> _logger;

    private InferenceSession? _detectionSession;
    private InferenceSession? _recognitionSession;
    private OcrEngineSettings _settings = new();

    private readonly object _sessionLock = new();
    private bool _isInitialized;
    private bool _disposed;

    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
    private int _totalProcessedImages;
    private double _totalProcessingTimeMs;
    private double _minProcessingTimeMs = double.MaxValue;
    private double _maxProcessingTimeMs;
    private int _errorCount;
    private int _consecutiveFailureCount;
    private DateTime _startTime = DateTime.UtcNow;

    // è¾æ›¸ï¼ˆèªè­˜ç”¨æ–‡å­—ãƒªã‚¹ãƒˆï¼‰
    private string[]? _characterDictionary;

    public string EngineName => "ONNX PP-OCRv5";
    public string EngineVersion => "1.0.0";
    public bool IsInitialized => _isInitialized;
    public string? CurrentLanguage => _settings.Language;

    public OnnxOcrEngine(
        IUnifiedGpuOptimizer gpuOptimizer,
        IPpOcrv5ModelConfiguration modelConfig,
        ILogger<OnnxOcrEngine> logger)
    {
        _gpuOptimizer = gpuOptimizer ?? throw new ArgumentNullException(nameof(gpuOptimizer));
        _modelConfig = modelConfig ?? throw new ArgumentNullException(nameof(modelConfig));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    public async Task<bool> InitializeAsync(OcrEngineSettings? settings = null, CancellationToken cancellationToken = default)
    {
        ObjectDisposedException.ThrowIf(_disposed, this);

        if (_isInitialized)
        {
            _logger.LogDebug("ONNX OCR ã‚¨ãƒ³ã‚¸ãƒ³ã¯æ—¢ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã™");
            return true;
        }

        _settings = settings?.Clone() ?? new OcrEngineSettings();

        try
        {
            _logger.LogInformation("ONNX OCR ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–é–‹å§‹");

            // GPUç’°å¢ƒã«å¿œã˜ãŸæœ€é©ãªSessionOptionsã‚’å–å¾—
            // Issue #181: GPUåˆæœŸåŒ–å¤±æ•—æ™‚ã¯CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            SessionOptions sessionOptions;
            try
            {
                sessionOptions = await _gpuOptimizer.CreateOptimalSessionOptionsAsync(cancellationToken).ConfigureAwait(false);
            }
            catch (Exception gpuEx)
            {
                _logger.LogWarning(gpuEx, "GPU SessionOptionsä½œæˆå¤±æ•—ã€CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨");
                Console.WriteLine($"âš ï¸ [Issue #181] GPUåˆæœŸåŒ–å¤±æ•—: {gpuEx.Message}");
                Console.WriteLine("   â†’ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™");
                sessionOptions = CreateCpuFallbackSessionOptions();
            }

            // æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
            var detModelPath = _modelConfig.GetDetectionModelPath();
            if (!File.Exists(detModelPath))
            {
                _logger.LogWarning("æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {Path}ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚", detModelPath);
                // ãƒ¢ãƒ‡ãƒ«ãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼åˆæœŸåŒ–ï¼ˆå¾Œã§ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’è¿½åŠ ï¼‰
                _isInitialized = false;
                return false;
            }

            _detectionSession = new InferenceSession(detModelPath, sessionOptions);
            _logger.LogInformation("æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {Path}", detModelPath);

            // èªè­˜ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
            var recModelPath = _modelConfig.GetRecognitionModelPath(_settings.Language);
            if (!File.Exists(recModelPath))
            {
                _logger.LogWarning("èªè­˜ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {Path}", recModelPath);
                _isInitialized = false;
                return false;
            }

            _recognitionSession = new InferenceSession(recModelPath, sessionOptions);
            _logger.LogInformation("èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {Path}", recModelPath);

            // æ–‡å­—è¾æ›¸ã®ãƒ­ãƒ¼ãƒ‰
            var dictPath = _modelConfig.GetDictionaryPath(_settings.Language);
            if (File.Exists(dictPath))
            {
                _characterDictionary = await File.ReadAllLinesAsync(dictPath, cancellationToken).ConfigureAwait(false);
                _logger.LogInformation("æ–‡å­—è¾æ›¸ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {Count} æ–‡å­—", _characterDictionary.Length);
            }
            else
            {
                _logger.LogWarning("æ–‡å­—è¾æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {Path}", dictPath);
                _characterDictionary = [];
            }

            _isInitialized = true;
            _startTime = DateTime.UtcNow;
            _logger.LogInformation("ONNX OCR ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†");

            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "ONNX OCR ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å¤±æ•—");
            _isInitialized = false;
            return false;
        }
    }

    public async Task<bool> WarmupAsync(CancellationToken cancellationToken = default)
    {
        if (!_isInitialized)
        {
            _logger.LogWarning("ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„ãŸã‚ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™");
            return false;
        }

        try
        {
            _logger.LogInformation("ONNX OCR ã‚¨ãƒ³ã‚¸ãƒ³ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—é–‹å§‹");

            // ãƒ€ãƒŸãƒ¼ç”»åƒã§ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
            // PP-OCRv5 èªè­˜ãƒ¢ãƒ‡ãƒ«ã¯é«˜ã•48pxã‚’æœŸå¾…ã™ã‚‹ï¼ˆCRNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¨™æº–ï¼‰
            using var dummyImage = new Mat(48, 100, MatType.CV_8UC3, Scalar.White);
            var inputTensor = PreprocessImageForRecognition(dummyImage);

            if (_recognitionSession != null)
            {
                var inputs = new List<NamedOnnxValue>
                {
                    NamedOnnxValue.CreateFromTensor("x", inputTensor)
                };

                using var results = _recognitionSession.Run(inputs);
                _logger.LogInformation("ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Œäº†");
            }

            await Task.CompletedTask.ConfigureAwait(false);
            return true;
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ");
            return false;
        }
    }

    public async Task<OcrResults> RecognizeAsync(
        IImage image,
        IProgress<OcrProgress>? progressCallback = null,
        CancellationToken cancellationToken = default)
    {
        return await RecognizeAsync(image, null, progressCallback, cancellationToken).ConfigureAwait(false);
    }

    public async Task<OcrResults> RecognizeAsync(
        IImage image,
        Rectangle? regionOfInterest,
        IProgress<OcrProgress>? progressCallback = null,
        CancellationToken cancellationToken = default)
    {
        var context = new OcrContext(image, IntPtr.Zero, regionOfInterest, cancellationToken);
        return await RecognizeAsync(context, progressCallback).ConfigureAwait(false);
    }

    public async Task<OcrResults> RecognizeAsync(
        OcrContext context,
        IProgress<OcrProgress>? progressCallback = null)
    {
        // ğŸ” [ONNX_DIAG] RecognizeAsyncå‘¼ã³å‡ºã—ç¢ºèª
        Console.WriteLine($"ğŸ” [ONNX_DIAG] OnnxOcrEngine.RecognizeAsync é–‹å§‹ - IsInitialized: {_isInitialized}, Time: {DateTime.Now:HH:mm:ss.fff}");
        _logger.LogInformation("ğŸ” [ONNX_DIAG] OnnxOcrEngine.RecognizeAsync é–‹å§‹ - IsInitialized: {IsInit}", _isInitialized);

        if (!_isInitialized)
            throw new InvalidOperationException("OCR ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“");

        ObjectDisposedException.ThrowIf(_disposed, this);

        var stopwatch = Stopwatch.StartNew();
        var textRegions = new List<OcrTextRegion>();

        try
        {
            progressCallback?.Report(new OcrProgress(0.1, "å‰å‡¦ç†ä¸­") { Phase = OcrPhase.Preprocessing });

            // ç”»åƒã‚’Matã«å¤‰æ›
            using var mat = ConvertToMat(context.Image, context.CaptureRegion);

            if (mat.Empty())
            {
                _logger.LogWarning("å¤‰æ›å¾Œã®ç”»åƒãŒç©ºã§ã™");
                return CreateEmptyResult(context.Image, context.CaptureRegion, stopwatch.Elapsed);
            }

            // ğŸ‡¯ğŸ‡µ [PREPROCESS] PP-OCRv5æ—¥æœ¬èªæœ€é©åŒ–å‰å‡¦ç†ï¼ˆç¾åœ¨ç„¡åŠ¹åŒ– - ç²¾åº¦æ¤œè¨¼ä¸­ï¼‰
            Mat? matForOcr = mat;  // å‰å‡¦ç†ãªã—ã§å…ƒç”»åƒã‚’ä½¿ç”¨
            var shouldDisposeMatForOcr = false;

            _logger.LogInformation("ğŸ” [PREPROCESS_DISABLED] å‰å‡¦ç†ç„¡åŠ¹åŒ–ä¸­ - ç´ ã®ç”»åƒã§OCRå®Ÿè¡Œ (ONNX)");
            Console.WriteLine($"ğŸ” [PREPROCESS_DISABLED] å‰å‡¦ç†ç„¡åŠ¹åŒ–ä¸­ - ç´ ã®ç”»åƒã§OCRå®Ÿè¡Œ (ONNX) {DateTime.Now:HH:mm:ss.fff}");

            // TODO: å‰å‡¦ç†ã®åŠ¹æœã‚’æ¤œè¨¼å¾Œã€ä»¥ä¸‹ã‚’æœ‰åŠ¹åŒ–ã¾ãŸã¯èª¿æ•´
            /*
            _logger.LogInformation("ğŸ‡¯ğŸ‡µ [PREPROCESS] PP-OCRv5æ—¥æœ¬èªæœ€é©åŒ–å‰å‡¦ç†ã‚’é©ç”¨ä¸­ (ONNX)...");
            Console.WriteLine($"ğŸ‡¯ğŸ‡µ [PREPROCESS] PP-OCRv5æ—¥æœ¬èªæœ€é©åŒ–å‰å‡¦ç†ã‚’é©ç”¨ä¸­ (ONNX)... {DateTime.Now:HH:mm:ss.fff}");

            try
            {
                var preprocessedMat = PPOCRv5Preprocessor.ProcessGameImageForV5(mat, "jpn");
                if (preprocessedMat != null && !preprocessedMat.Empty())
                {
                    matForOcr = preprocessedMat;
                    shouldDisposeMatForOcr = true;
                    _logger.LogInformation("ğŸ‡¯ğŸ‡µ [PREPROCESS] å‰å‡¦ç†å®Œäº† (ONNX) - ã‚µã‚¤ã‚º: {Width}x{Height}", preprocessedMat.Width, preprocessedMat.Height);
                    Console.WriteLine($"ğŸ‡¯ğŸ‡µ [PREPROCESS] å‰å‡¦ç†å®Œäº† (ONNX) - ã‚µã‚¤ã‚º: {preprocessedMat.Width}x{preprocessedMat.Height}");
                }
                else
                {
                    _logger.LogWarning("ğŸ‡¯ğŸ‡µ [PREPROCESS] å‰å‡¦ç†çµæœãŒç„¡åŠ¹ã€å…ƒç”»åƒã§OCRå®Ÿè¡Œ (ONNX)");
                    matForOcr = mat;
                }
            }
            catch (Exception preprocessEx)
            {
                _logger.LogWarning(preprocessEx, "ğŸ‡¯ğŸ‡µ [PREPROCESS] å‰å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ã€å…ƒç”»åƒã§OCRå®Ÿè¡Œ (ONNX)");
                matForOcr = mat;
            }
            */

            progressCallback?.Report(new OcrProgress(0.3, "ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºä¸­") { Phase = OcrPhase.TextDetection });

            try
            {
                // ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºï¼ˆå‰å‡¦ç†æ¸ˆã¿ç”»åƒã‚’ä½¿ç”¨ï¼‰
                var detectedBoxes = await DetectTextAsync(matForOcr!, context.CancellationToken).ConfigureAwait(false);

                if (detectedBoxes.Count == 0)
                {
                    _logger.LogDebug("ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ");
                    return CreateEmptyResult(context.Image, context.CaptureRegion, stopwatch.Elapsed);
                }

                _logger.LogDebug("{Count} å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æ¤œå‡º", detectedBoxes.Count);

                progressCallback?.Report(new OcrProgress(0.5, "ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ä¸­") { Phase = OcrPhase.TextRecognition });

                // ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ï¼ˆå‰å‡¦ç†æ¸ˆã¿ç”»åƒã‚’ä½¿ç”¨ï¼‰
                for (int i = 0; i < detectedBoxes.Count; i++)
                {
                    context.CancellationToken.ThrowIfCancellationRequested();

                    var box = detectedBoxes[i];
                    var (text, confidence) = await RecognizeTextInRegionAsync(matForOcr!, box, context.CancellationToken).ConfigureAwait(false);

                    if (!string.IsNullOrWhiteSpace(text) && confidence >= _settings.RecognitionThreshold)
                    {
                        var bounds = GetBoundingRect(box);

                        // ROIåº§æ¨™å¤‰æ›
                        if (context.HasCaptureRegion)
                        {
                            bounds = new Rectangle(
                                bounds.X + context.CaptureRegion!.Value.X,
                                bounds.Y + context.CaptureRegion!.Value.Y,
                                bounds.Width,
                                bounds.Height);
                        }

                        textRegions.Add(new OcrTextRegion(
                            text,
                            bounds,
                            confidence,
                            box,
                            DetectTextDirection(box)));
                    }

                    progressCallback?.Report(new OcrProgress(
                        0.5 + (0.4 * (i + 1) / detectedBoxes.Count),
                        $"èªè­˜ä¸­ ({i + 1}/{detectedBoxes.Count})")
                    { Phase = OcrPhase.TextRecognition });
                }

                progressCallback?.Report(new OcrProgress(0.95, "å¾Œå‡¦ç†ä¸­") { Phase = OcrPhase.PostProcessing });

                stopwatch.Stop();
                UpdatePerformanceStats(stopwatch.Elapsed.TotalMilliseconds, true);

                progressCallback?.Report(new OcrProgress(1.0, "å®Œäº†") { Phase = OcrPhase.Completed });

                _logger.LogInformation("OCRå®Œäº†: {Count} é ˜åŸŸ, {Time}ms", textRegions.Count, stopwatch.ElapsedMilliseconds);

                return new OcrResults(
                    textRegions,
                    context.Image,
                    stopwatch.Elapsed,
                    _settings.Language,
                    context.CaptureRegion);
            }
            finally
            {
                // å‰å‡¦ç†ç”»åƒã®ãƒªã‚½ãƒ¼ã‚¹ç ´æ£„
                if (shouldDisposeMatForOcr && matForOcr != null)
                {
                    matForOcr.Dispose();
                }
            }
        }
        catch (OperationCanceledException)
        {
            _logger.LogDebug("OCRå‡¦ç†ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ");
            throw;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "OCRå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ");
            UpdatePerformanceStats(stopwatch.Elapsed.TotalMilliseconds, false);
            throw new OcrException("OCRå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ", ex);
        }
    }

    public Task<OcrResults> DetectTextRegionsAsync(IImage image, CancellationToken cancellationToken = default)
    {
        // ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºã®ã¿ï¼ˆèªè­˜ãªã—ï¼‰
        return RecognizeAsync(image, null, null, cancellationToken);
    }

    public OcrEngineSettings GetSettings() => _settings.Clone();

    public async Task ApplySettingsAsync(OcrEngineSettings settings, CancellationToken cancellationToken = default)
    {
        ArgumentNullException.ThrowIfNull(settings);

        if (!settings.IsValid())
            throw new ArgumentException("ç„¡åŠ¹ãªè¨­å®šã§ã™", nameof(settings));

        var languageChanged = _settings.Language != settings.Language;
        _settings = settings.Clone();

        if (languageChanged && _isInitialized)
        {
            _logger.LogInformation("è¨€èªè¨­å®šãŒå¤‰æ›´ã•ã‚ŒãŸãŸã‚ã€èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’å†ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™");

            // èªè­˜ãƒ¢ãƒ‡ãƒ«ã®å†ãƒ­ãƒ¼ãƒ‰
            var recModelPath = _modelConfig.GetRecognitionModelPath(_settings.Language);
            if (File.Exists(recModelPath))
            {
                var sessionOptions = await _gpuOptimizer.CreateOptimalSessionOptionsAsync(cancellationToken).ConfigureAwait(false);

                lock (_sessionLock)
                {
                    _recognitionSession?.Dispose();
                    _recognitionSession = new InferenceSession(recModelPath, sessionOptions);
                }

                // è¾æ›¸ã®å†ãƒ­ãƒ¼ãƒ‰
                var dictPath = _modelConfig.GetDictionaryPath(_settings.Language);
                if (File.Exists(dictPath))
                {
                    _characterDictionary = await File.ReadAllLinesAsync(dictPath, cancellationToken).ConfigureAwait(false);
                }
            }
        }
    }

    public IReadOnlyList<string> GetAvailableLanguages()
    {
        return ["jpn", "eng", "chi_sim"];
    }

    public IReadOnlyList<string> GetAvailableModels()
    {
        return ["ppocrv5-onnx"];
    }

    public async Task<bool> IsLanguageAvailableAsync(string languageCode, CancellationToken cancellationToken = default)
    {
        var modelPath = _modelConfig.GetRecognitionModelPath(languageCode);
        await Task.CompletedTask.ConfigureAwait(false);
        return File.Exists(modelPath);
    }

    public OcrPerformanceStats GetPerformanceStats()
    {
        var totalImages = _totalProcessedImages + _errorCount;
        return new OcrPerformanceStats
        {
            TotalProcessedImages = totalImages,
            AverageProcessingTimeMs = totalImages > 0 ? _totalProcessingTimeMs / totalImages : 0,
            MinProcessingTimeMs = _minProcessingTimeMs == double.MaxValue ? 0 : _minProcessingTimeMs,
            MaxProcessingTimeMs = _maxProcessingTimeMs,
            ErrorCount = _errorCount,
            SuccessRate = totalImages > 0 ? (double)_totalProcessedImages / totalImages : 0,
            StartTime = _startTime,
            LastUpdateTime = DateTime.UtcNow
        };
    }

    public void CancelCurrentOcrTimeout()
    {
        // ONNX Runtimeã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç®¡ç†ãŒç•°ãªã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä½•ã‚‚ã—ãªã„
    }

    public int GetConsecutiveFailureCount() => _consecutiveFailureCount;

    public void ResetFailureCounter()
    {
        _consecutiveFailureCount = 0;
    }

    #region Private Methods

    /// <summary>
    /// GPUåˆæœŸåŒ–å¤±æ•—æ™‚ã®CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨SessionOptionsã‚’ä½œæˆ
    /// Issue #181: ONNX Runtime ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç«¶åˆæ™‚ã®å®‰å…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    /// </summary>
    private static SessionOptions CreateCpuFallbackSessionOptions()
    {
        var options = new SessionOptions();

        // CPUæœ€é©åŒ–è¨­å®š
        options.EnableCpuMemArena = true;
        options.ExecutionMode = ExecutionMode.ORT_SEQUENTIAL;
        options.IntraOpNumThreads = Environment.ProcessorCount;
        options.EnableMemoryPattern = true;
        options.GraphOptimizationLevel = GraphOptimizationLevel.ORT_ENABLE_ALL;

        Console.WriteLine($"âœ… [Issue #181] CPU SessionOptionsä½œæˆå®Œäº† (Threads: {Environment.ProcessorCount})");

        return options;
    }

    private Mat ConvertToMat(IImage image, Rectangle? roi)
    {
        // LockPixelDataã‚’ä½¿ç”¨ã—ã¦ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ã§ãƒ”ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹
        using var pixelLock = image.LockPixelData();
        var pixelData = pixelLock.Data;
        var stride = pixelLock.Stride;

        var mat = new Mat(image.Height, image.Width, MatType.CV_8UC4);

        // Spanã‹ã‚‰Matã¸ã‚³ãƒ”ãƒ¼
        unsafe
        {
            fixed (byte* srcPtr = pixelData)
            {
                for (int y = 0; y < image.Height; y++)
                {
                    var srcRow = srcPtr + y * stride;
                    var dstRow = mat.Ptr(y);
                    Buffer.MemoryCopy(srcRow, (void*)dstRow, image.Width * 4, image.Width * 4);
                }
            }
        }

        // BGRA to BGR
        Cv2.CvtColor(mat, mat, ColorConversionCodes.BGRA2BGR);

        if (roi.HasValue)
        {
            var roiRect = new OpenCvSharp.Rect(roi.Value.X, roi.Value.Y, roi.Value.Width, roi.Value.Height);
            return new Mat(mat, roiRect);
        }

        return mat;
    }

    private async Task<List<DrawingPoint[]>> DetectTextAsync(Mat image, CancellationToken cancellationToken)
    {
        if (_detectionSession == null)
            return [];

        return await Task.Run(() =>
        {
            cancellationToken.ThrowIfCancellationRequested();

            // å‰å‡¦ç†
            var inputTensor = PreprocessImageForDetection(image);

            // æ¨è«–
            var inputs = new List<NamedOnnxValue>
            {
                NamedOnnxValue.CreateFromTensor("x", inputTensor)
            };

            using var results = _detectionSession.Run(inputs);
            var output = results.First().AsTensor<float>();

            // å¾Œå‡¦ç†ï¼ˆDBNetå‡ºåŠ›ã‹ã‚‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æŠ½å‡ºï¼‰
            return PostprocessDetection(output, image.Width, image.Height);
        }, cancellationToken).ConfigureAwait(false);
    }

    private async Task<(string text, double confidence)> RecognizeTextInRegionAsync(
        Mat image,
        DrawingPoint[] box,
        CancellationToken cancellationToken)
    {
        if (_recognitionSession == null || _characterDictionary == null || _characterDictionary.Length == 0)
            return (string.Empty, 0);

        return await Task.Run(() =>
        {
            cancellationToken.ThrowIfCancellationRequested();

            // ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã—
            using var cropped = CropAndRotateRegion(image, box);
            if (cropped.Empty())
                return (string.Empty, 0);

            // å‰å‡¦ç†
            var inputTensor = PreprocessImageForRecognition(cropped);

            // æ¨è«–
            var inputs = new List<NamedOnnxValue>
            {
                NamedOnnxValue.CreateFromTensor("x", inputTensor)
            };

            using var results = _recognitionSession.Run(inputs);
            var output = results.First().AsTensor<float>();

            // CTCãƒ‡ã‚³ãƒ¼ãƒ‰
            return CTCDecode(output);
        }, cancellationToken).ConfigureAwait(false);
    }

    private DenseTensor<float> PreprocessImageForDetection(Mat image)
    {
        // æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ç”¨ã®å‰å‡¦ç†
        // 1. ãƒªã‚µã‚¤ã‚ºï¼ˆDetectionTargetSize x DetectionTargetSize ã‚’æ¨å¥¨ï¼‰
        var scale = Math.Min((double)DetectionTargetSize / image.Width, (double)DetectionTargetSize / image.Height);
        var newWidth = (int)(image.Width * scale);
        var newHeight = (int)(image.Height * scale);

        // PaddingAlignment ã®å€æ•°ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        newWidth = ((newWidth + PaddingAlignment - 1) / PaddingAlignment) * PaddingAlignment;
        newHeight = ((newHeight + PaddingAlignment - 1) / PaddingAlignment) * PaddingAlignment;

        using var resized = new Mat();
        Cv2.Resize(image, resized, new OpenCvSharp.Size(newWidth, newHeight));

        // 2. ImageNetæ­£è¦åŒ–
        var tensor = new DenseTensor<float>([1, 3, newHeight, newWidth]);

        for (int y = 0; y < newHeight; y++)
        {
            for (int x = 0; x < newWidth; x++)
            {
                var pixel = resized.At<Vec3b>(y, x);
                // BGR -> RGBå¤‰æ›ã—ãªãŒã‚‰æ­£è¦åŒ–
                tensor[0, 0, y, x] = (pixel[2] / 255.0f - ImageNetMean[0]) / ImageNetStd[0]; // R
                tensor[0, 1, y, x] = (pixel[1] / 255.0f - ImageNetMean[1]) / ImageNetStd[1]; // G
                tensor[0, 2, y, x] = (pixel[0] / 255.0f - ImageNetMean[2]) / ImageNetStd[2]; // B
            }
        }

        return tensor;
    }

    private DenseTensor<float> PreprocessImageForRecognition(Mat image)
    {
        // èªè­˜ãƒ¢ãƒ‡ãƒ«ç”¨ã®å‰å‡¦ç†
        // é«˜ã•ã‚’RecognitionTargetHeightã«æ­£è¦åŒ–ã€å¹…ã¯ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒ
        var scale = (double)RecognitionTargetHeight / image.Height;
        var newWidth = Math.Max(1, (int)(image.Width * scale));

        // æœ€å¤§å¹…åˆ¶é™
        if (newWidth > RecognitionMaxWidth)
        {
            newWidth = RecognitionMaxWidth;
        }

        using var resized = new Mat();
        Cv2.Resize(image, resized, new OpenCvSharp.Size(newWidth, RecognitionTargetHeight));

        // æ­£è¦åŒ–ï¼ˆmean=0.5, std=0.5ï¼‰
        var tensor = new DenseTensor<float>([1, 3, RecognitionTargetHeight, newWidth]);

        for (int y = 0; y < RecognitionTargetHeight; y++)
        {
            for (int x = 0; x < newWidth; x++)
            {
                var pixel = resized.At<Vec3b>(y, x);
                // BGR -> RGBå¤‰æ›ã—ãªãŒã‚‰æ­£è¦åŒ–
                tensor[0, 0, y, x] = (pixel[2] / 255.0f - RecognitionNormFactor) / RecognitionNormFactor; // R
                tensor[0, 1, y, x] = (pixel[1] / 255.0f - RecognitionNormFactor) / RecognitionNormFactor; // G
                tensor[0, 2, y, x] = (pixel[0] / 255.0f - RecognitionNormFactor) / RecognitionNormFactor; // B
            }
        }

        return tensor;
    }

    private List<DrawingPoint[]> PostprocessDetection(Tensor<float> output, int originalWidth, int originalHeight)
    {
        var boxes = new List<DrawingPoint[]>();

        // DBNetå‡ºåŠ›ã‚’ãƒã‚¤ãƒŠãƒªãƒãƒƒãƒ—ã«å¤‰æ›
        var dims = output.Dimensions;
        var height = dims[2];
        var width = dims[3];

        using var binaryMap = new Mat(height, width, MatType.CV_8UC1);

        for (int y = 0; y < height; y++)
        {
            for (int x = 0; x < width; x++)
            {
                var value = output[0, 0, y, x];
                binaryMap.Set(y, x, (byte)(value > _settings.DetectionThreshold ? 255 : 0));
            }
        }

        // è¼ªéƒ­æ¤œå‡º
        Cv2.FindContours(binaryMap, out var contours, out _, RetrievalModes.External, ContourApproximationModes.ApproxSimple);

        // ã‚¹ã‚±ãƒ¼ãƒ«è¨ˆç®—
        var scaleX = (double)originalWidth / width;
        var scaleY = (double)originalHeight / height;

        foreach (var contour in contours)
        {
            var area = Cv2.ContourArea(contour);
            if (area < MinContourArea) continue; // å°ã•ã™ãã‚‹é ˜åŸŸã‚’é™¤å¤–

            // æœ€å°å¤–æ¥çŸ©å½¢
            var rect = Cv2.MinAreaRect(contour);
            var points2f = Cv2.BoxPoints(rect);

            // DrawingPoint[]ã«å¤‰æ›ã—ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            var points = points2f.Select(p => new DrawingPoint(
                (int)(p.X * scaleX),
                (int)(p.Y * scaleY)
            )).ToArray();

            boxes.Add(points);
        }

        return boxes;
    }

    private (string text, double confidence) CTCDecode(Tensor<float> output)
    {
        if (_characterDictionary == null || _characterDictionary.Length == 0)
            return (string.Empty, 0);

        var dims = output.Dimensions;
        var timeSteps = dims[1];
        var numClasses = dims[2];

        var result = new System.Text.StringBuilder();
        var confidences = new List<double>();
        int lastIndex = 0;

        for (int t = 0; t < timeSteps; t++)
        {
            // æœ€å¤§ç¢ºç‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            var maxProb = float.MinValue;
            var maxIndex = 0;

            for (int c = 0; c < numClasses; c++)
            {
                var prob = output[0, t, c];
                if (prob > maxProb)
                {
                    maxProb = prob;
                    maxIndex = c;
                }
            }

            // CTCãƒ–ãƒ©ãƒ³ã‚¯ã§ãªãã€å‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ç•°ãªã‚‹å ´åˆã«æ–‡å­—ã‚’è¿½åŠ 
            // é€šå¸¸ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹0ãŒãƒ–ãƒ©ãƒ³ã‚¯
            if (maxIndex != 0 && maxIndex != lastIndex)
            {
                if (maxIndex - 1 < _characterDictionary.Length)
                {
                    result.Append(_characterDictionary[maxIndex - 1]);
                    // PP-OCRv5 èªè­˜ãƒ¢ãƒ‡ãƒ«ã¯log-softmaxå‡ºåŠ›ã®ãŸã‚ã€expã§ç¢ºç‡ã«å¤‰æ›
                    // æ³¨æ„: ãƒ¢ãƒ‡ãƒ«ãŒsoftmaxå‡ºåŠ›ã®å ´åˆã¯Math.Expã‚’å‰Šé™¤ã™ã‚‹å¿…è¦ã‚ã‚Š
                    confidences.Add(Math.Exp(maxProb));
                }
            }

            lastIndex = maxIndex;
        }

        var avgConfidence = confidences.Count > 0 ? confidences.Average() : 0;
        return (result.ToString(), avgConfidence);
    }

    private Mat CropAndRotateRegion(Mat image, DrawingPoint[] box)
    {
        if (box.Length != 4)
            return new Mat();

        // å››è§’å½¢ã®é ‚ç‚¹ã‚’Point2fé…åˆ—ã«å¤‰æ›
        var srcPoints = box.Select(p => new Point2f(p.X, p.Y)).ToArray();

        // å¹…ã¨é«˜ã•ã‚’è¨ˆç®—
        var width = (int)Math.Max(
            Distance(srcPoints[0], srcPoints[1]),
            Distance(srcPoints[2], srcPoints[3]));
        var height = (int)Math.Max(
            Distance(srcPoints[0], srcPoints[3]),
            Distance(srcPoints[1], srcPoints[2]));

        if (width <= 0 || height <= 0)
            return new Mat();

        // å‡ºåŠ›å…ˆã®å››è§’å½¢
        var dstPoints = new Point2f[]
        {
            new(0, 0),
            new(width, 0),
            new(width, height),
            new(0, height)
        };

        // é€è¦–å¤‰æ›
        using var transform = Cv2.GetPerspectiveTransform(srcPoints, dstPoints);
        var result = new Mat();
        Cv2.WarpPerspective(image, result, transform, new OpenCvSharp.Size(width, height));

        return result;
    }

    private static double Distance(Point2f p1, Point2f p2)
    {
        return Math.Sqrt(Math.Pow(p2.X - p1.X, 2) + Math.Pow(p2.Y - p1.Y, 2));
    }

    private static Rectangle GetBoundingRect(DrawingPoint[] box)
    {
        var minX = box.Min(p => p.X);
        var minY = box.Min(p => p.Y);
        var maxX = box.Max(p => p.X);
        var maxY = box.Max(p => p.Y);

        return new Rectangle(minX, minY, maxX - minX, maxY - minY);
    }

    private static TextDirection DetectTextDirection(DrawingPoint[] box)
    {
        if (box.Length < 4)
            return TextDirection.Unknown;

        // ç°¡æ˜“çš„ãªæ–¹å‘åˆ¤å®š
        var width = Math.Max(
            Distance(new Point2f(box[0].X, box[0].Y), new Point2f(box[1].X, box[1].Y)),
            Distance(new Point2f(box[2].X, box[2].Y), new Point2f(box[3].X, box[3].Y)));
        var height = Math.Max(
            Distance(new Point2f(box[0].X, box[0].Y), new Point2f(box[3].X, box[3].Y)),
            Distance(new Point2f(box[1].X, box[1].Y), new Point2f(box[2].X, box[2].Y)));

        return height > width * VerticalTextRatio ? TextDirection.Vertical : TextDirection.Horizontal;
    }

    private OcrResults CreateEmptyResult(IImage image, Rectangle? roi, TimeSpan elapsed)
    {
        return new OcrResults(
            [],
            image,
            elapsed,
            _settings.Language,
            roi);
    }

    private void UpdatePerformanceStats(double elapsedMs, bool success)
    {
        if (success)
        {
            _totalProcessedImages++;
            _consecutiveFailureCount = 0;
        }
        else
        {
            _errorCount++;
            _consecutiveFailureCount++;
        }

        _totalProcessingTimeMs += elapsedMs;
        _minProcessingTimeMs = Math.Min(_minProcessingTimeMs, elapsedMs);
        _maxProcessingTimeMs = Math.Max(_maxProcessingTimeMs, elapsedMs);
    }

    #endregion

    public void Dispose()
    {
        if (_disposed)
            return;

        lock (_sessionLock)
        {
            _detectionSession?.Dispose();
            _recognitionSession?.Dispose();
            _detectionSession = null;
            _recognitionSession = null;
        }

        _disposed = true;
        _isInitialized = false;

        _logger.LogInformation("ONNX OCR ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ç ´æ£„ã—ã¾ã—ãŸ");
    }
}
