using System;
using System.Threading.Tasks;
using Baketa.Infrastructure.Translation.Local.Onnx.SentencePiece.Native;
using Microsoft.Extensions.Logging;

namespace Baketa;

/// <summary>
/// å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®èªå½™ã‚µã‚¤ã‚ºã‚’è©³ç´°ã«ãƒ†ã‚¹ãƒˆã™ã‚‹ãƒ„ãƒ¼ãƒ«
/// </summary>
public class VocabSizeTestSingle
{
    public static async Task Main(string[] args)
    {
        Console.WriteLine("=== HuggingFace target.spm è©³ç´°åˆ†æ ===");
        
        using var loggerFactory = LoggerFactory.Create(builder =>
            builder.AddConsole()
                   .SetMinimumLevel(LogLevel.Debug));
        
        var logger = loggerFactory.CreateLogger<OpusMtNativeTokenizer>();
        var modelPath = @"E:\dev\Baketa\Models\HuggingFace\opus-mt-ja-en\target.spm";
        
        try
        {
            Console.WriteLine($"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {modelPath}");
            
            var fileInfo = new System.IO.FileInfo(modelPath);
            Console.WriteLine($"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {fileInfo.Length:N0} bytes");
            Console.WriteLine($"æœ€çµ‚æ›´æ–°: {fileInfo.LastWriteTime}");
            
            // SentencePieceãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ
            var tokenizer = new OpusMtNativeTokenizer(modelPath, "HuggingFace Target", logger);
            
            Console.WriteLine($"âœ… èªå½™ã‚µã‚¤ã‚º: {tokenizer.VocabularySize:N0}");
            
            // ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³IDç¢ºèª
            var bosId = tokenizer.GetSpecialTokenId("BOS");
            var eosId = tokenizer.GetSpecialTokenId("EOS");
            var unkId = tokenizer.GetSpecialTokenId("UNK");
            var padId = tokenizer.GetSpecialTokenId("PAD");
            
            Console.WriteLine($"ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ - BOS: {bosId}, EOS: {eosId}, UNK: {unkId}, PAD: {padId}");
            
            // ONNXãƒ¢ãƒ‡ãƒ«ã¨ã®ä¸€è‡´åº¦ãƒã‚§ãƒƒã‚¯
            const int targetVocabSize = 60716;
            var difference = Math.Abs(tokenizer.VocabularySize - targetVocabSize);
            var matchPercentage = (1.0 - (double)difference / targetVocabSize) * 100;
            
            Console.WriteLine($"ONNXä¸€è‡´åº¦: {matchPercentage:F2}% (å·®åˆ†: {difference:N0})");
            
            if (tokenizer.VocabularySize == targetVocabSize)
            {
                Console.WriteLine("ğŸ¯ PERFECT MATCH! ã“ã®ãƒ¢ãƒ‡ãƒ«ãŒæ­£è§£ã§ã™");
            }
            else if (difference < 1000)
            {
                Console.WriteLine("âœ… éå¸¸ã«è¿‘ã„ - ä½¿ç”¨å¯èƒ½ãªå€™è£œ");
            }
            else
            {
                Console.WriteLine($"âŒ å¤§ããªå·® - æœŸå¾…: {targetVocabSize:N0}, å®Ÿéš›: {tokenizer.VocabularySize:N0}");
            }
            
            // ãƒ†ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³åŒ–
            var testText = "ãƒ†ã‚¹ãƒˆ";
            var tokens = tokenizer.Tokenize(testText);
            Console.WriteLine($"ãƒ†ã‚¹ãƒˆ '{testText}' -> [{string.Join(", ", tokens)}]");
            
            // èªå½™ç¯„å›²ã®ç¢ºèª
            Console.WriteLine($"æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³ID: {tokens.Max()}");
            Console.WriteLine($"èªå½™ã‚µã‚¤ã‚ºç¯„å›²: 0 - {tokenizer.VocabularySize - 1}");
            
            if (tokens.Any(t => t >= tokenizer.VocabularySize))
            {
                Console.WriteLine("âš ï¸ è­¦å‘Š: èªå½™ç¯„å›²å¤–ã®ãƒˆãƒ¼ã‚¯ãƒ³IDãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ");
            }

        }
        catch (Exception ex)
        {
            Console.WriteLine($"âŒ ã‚¨ãƒ©ãƒ¼: {ex.Message}");
            if (ex.InnerException != null)
            {
                Console.WriteLine($"   è©³ç´°: {ex.InnerException.Message}");
            }
        }
        
        Console.WriteLine("\nåˆ†æå®Œäº†ã€‚Enterã‚­ãƒ¼ã§çµ‚äº†...");
        Console.ReadLine();
    }
}