#!/usr/bin/env python3
"""
Baketa OPUS-MT Persistent Translation Server
å¸¸é§å‹é«˜é€Ÿç¿»è¨³ã‚µãƒ¼ãƒãƒ¼ - ãƒ¢ãƒ‡ãƒ«åˆå›ãƒ­ãƒ¼ãƒ‰å¾Œã¯0.1-0.5ç§’ã§ç¿»è¨³å®Ÿè¡Œ
"""

import sys
import json
import os
import warnings
import socket
import threading
import time
from datetime import datetime
import traceback

# è­¦å‘Šã‚’æŠ‘åˆ¶ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
warnings.filterwarnings("ignore", category=UserWarning)
os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # tokenizerã®ä¸¦åˆ—å‡¦ç†ã‚’ç„¡åŠ¹åŒ–

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, logging
import torch

# transformersã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã‚‹
logging.set_verbosity_error()

# ğŸ”„ å‹•çš„ãƒ¢ãƒ‡ãƒ«é¸æŠ: è¨€èªæ–¹å‘ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«IDã‚’æ±ºå®š
MODELS = {
    "ja-en": "Helsinki-NLP/opus-mt-ja-en",  # æ—¥â†’è‹±
    "en-ja": "Helsinki-NLP/opus-mt-en-jap"  # è‹±â†’æ—¥ï¼ˆæ­£å¼åç§°: "jap"ï¼‰
}
SERVER_HOST = "127.0.0.1"
SERVER_PORT = 7860  # Baketaå°‚ç”¨ãƒãƒ¼ãƒˆï¼ˆC#å´ã¨çµ±ä¸€ï¼‰

class PersistentOpusMtServer:
    """
    OPUS-MTå¸¸é§ç¿»è¨³ã‚µãƒ¼ãƒãƒ¼
    - 1å›ã®ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã§é«˜é€Ÿç¿»è¨³ã‚’ç¶™ç¶šæä¾›
    - TCP Socketé€šä¿¡ã§C#ã¨é€£æº
    - ãƒ—ãƒ­ã‚»ã‚¹æ­»æ´»ç›£è¦–å¯¾å¿œ
    """
    
    def __init__(self):
        # ğŸ”„ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«åŒæ™‚ã‚µãƒãƒ¼ãƒˆ: æ—¥â†’è‹±ã€è‹±â†’æ—¥ã®ä¸¡æ–¹å‘
        self.tokenizers = {}  # {"ja-en": tokenizer, "en-ja": tokenizer}
        self.models = {}      # {"ja-en": model, "en-ja": model}
        self.initialized = False
        self.server_socket = None
        self.running = False
        self.translation_count = 0
        self.start_time = datetime.now()
        
    def initialize_models(self):
        """
        ğŸ”„ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«åŒæ™‚åˆæœŸåŒ–: æ—¥â†’è‹±ã€è‹±â†’æ—¥ã®ä¸¡æ–¹å‘ã‚µãƒãƒ¼ãƒˆ
        """
        try:
            for direction, model_id in MODELS.items():
                print(f"ğŸ”„ [{datetime.now().strftime('%H:%M:%S')}] Loading tokenizer for {direction} ({model_id})...", 
                      file=sys.stderr, flush=True)
                self.tokenizers[direction] = AutoTokenizer.from_pretrained(model_id, local_files_only=False)
                
                print(f"ğŸ”„ [{datetime.now().strftime('%H:%M:%S')}] Loading model for {direction} ({model_id})...", 
                      file=sys.stderr, flush=True)
                self.models[direction] = AutoModelForSeq2SeqLM.from_pretrained(model_id, local_files_only=False)
                
                print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] Model {direction} loaded successfully!", 
                      file=sys.stderr, flush=True)
            
            print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] All models initialization complete! Ready for bidirectional translation.", 
                  file=sys.stderr, flush=True)
            self.initialized = True
            return True
        except Exception as e:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Models initialization failed: {e}", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ“„ Traceback:\n{traceback.format_exc()}", file=sys.stderr, flush=True)
            return False
    
    def translate(self, text, direction="ja-en"):
        """
        ğŸ”„ åŒæ–¹å‘ç¿»è¨³ï¼ˆé«˜é€Ÿå®Ÿè¡Œï¼š0.1-0.5ç§’ç›®æ¨™ï¼‰
        Args:
            text: ç¿»è¨³ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            direction: ç¿»è¨³æ–¹å‘ ("ja-en" or "en-ja")
        """
        if not self.initialized:
            return {"success": False, "error": "Service not initialized"}
        
        if direction not in self.models:
            return {"success": False, "error": f"Unsupported direction: {direction}"}
        
        start_time = time.time()
        
        try:
            # æŒ‡å®šã•ã‚ŒãŸè¨€èªæ–¹å‘ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            tokenizer = self.tokenizers[direction]
            model = self.models[direction]
            
            # HuggingFace Transformersæ¨™æº–å‡¦ç†
            inputs = tokenizer(text, return_tensors="pt")
            
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_length=128,
                    num_beams=3,
                    length_penalty=1.0,
                    early_stopping=True
                )
            
            translation = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¿½åŠ 
            print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [DEBUG_DECODE] Raw output tensor: {outputs[0][:10] if len(outputs[0]) > 10 else outputs[0]}", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [DEBUG_DECODE] Translation result: {repr(translation)}", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [DEBUG_DECODE] Translation bytes: {translation.encode('utf-8')}", 
                  file=sys.stderr, flush=True)
            
            processing_time = time.time() - start_time
            self.translation_count += 1
            
            print(f"âš¡ [{datetime.now().strftime('%H:%M:%S')}] Translation #{self.translation_count} [{direction}] completed in {processing_time:.3f}s: '{text}' â†’ '{translation}'", 
                  file=sys.stderr, flush=True)
            
            return {
                "success": True,
                "translation": translation,
                "source": text,
                "direction": direction,
                "processing_time": processing_time,
                "translation_count": self.translation_count
            }
            
        except Exception as e:
            processing_time = time.time() - start_time
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Translation failed after {processing_time:.3f}s: {e}", 
                  file=sys.stderr, flush=True)
            return {
                "success": False,
                "error": str(e),
                "source": text,
                "processing_time": processing_time
            }

    def translate_batch(self, texts, direction="ja-en"):
        """
        ğŸ”„ åŒæ–¹å‘ãƒãƒƒãƒç¿»è¨³ï¼šè¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€åº¦ã«å‡¦ç†ï¼ˆåŠ¹ç‡åŒ–ï¼‰
        Args:
            texts: ç¿»è¨³ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
            direction: ç¿»è¨³æ–¹å‘ ("ja-en" or "en-ja")
        """
        print(f"ğŸš€ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] translate_batch method called", 
              file=sys.stderr, flush=True)
        print(f"ğŸ“‹ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Parameters: texts={len(texts) if texts else 0}, direction={direction}", 
              file=sys.stderr, flush=True)
        
        if not self.initialized:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Service not initialized", 
                  file=sys.stderr, flush=True)
            return {"success": False, "error": "Service not initialized"}
        
        if direction not in self.models:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Unsupported direction: {direction}", 
                  file=sys.stderr, flush=True)
            return {"success": False, "error": f"Unsupported direction: {direction}"}
        
        start_time = time.time()
        translations = []
        sources = []
        
        try:
            print(f"ğŸ“¦ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Batch translation [{direction}] started - {len(texts)} texts", 
                  file=sys.stderr, flush=True)
            
            # ãƒ†ã‚­ã‚¹ãƒˆä¸€è¦§ã‚’ãƒ­ã‚°å‡ºåŠ›
            for i, text in enumerate(texts[:5]):  # æœ€åˆã®5å€‹ã¾ã§
                print(f"ğŸ“ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Text[{i}]: '{text[:50]}{'...' if len(text) > 50 else ''}'", 
                      file=sys.stderr, flush=True)
            
            # æŒ‡å®šã•ã‚ŒãŸè¨€èªæ–¹å‘ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            print(f"ğŸ”§ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Getting tokenizer and model for direction: {direction}", 
                  file=sys.stderr, flush=True)
            
            tokenizer = self.tokenizers[direction]
            model = self.models[direction]
            
            print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Tokenizer and model obtained successfully", 
                  file=sys.stderr, flush=True)
            
            # ãƒãƒƒãƒå‡¦ç†ï¼šè¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€åº¦ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Starting tokenizer encoding...", 
                  file=sys.stderr, flush=True)
            
            inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
            
            print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Tokenizer encoding completed", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ“Š [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Input tensor shape: {inputs.input_ids.shape if hasattr(inputs, 'input_ids') else 'N/A'}", 
                  file=sys.stderr, flush=True)
            
            print(f"ğŸš€ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Starting model generation (this might hang)...", 
                  file=sys.stderr, flush=True)
            
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_length=128,
                    num_beams=3,
                    length_penalty=1.0,
                    early_stopping=True
                )
            
            print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Model generation completed!", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ“Š [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Output tensor shape: {outputs.shape if hasattr(outputs, 'shape') else 'N/A'}", 
                  file=sys.stderr, flush=True)
            
            # å„å‡ºåŠ›ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
            print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Starting output decoding...", 
                  file=sys.stderr, flush=True)
            
            for i, output in enumerate(outputs):
                print(f"ğŸ”„ [{datetime.now().strftime('%H:%M:%S')}] [BATCH_VERIFICATION] Decoding output #{i+1}...", 
                      file=sys.stderr, flush=True)
                
                translation = tokenizer.decode(output, skip_special_tokens=True)
                translations.append(translation)
                sources.append(texts[i] if i < len(texts) else "")
                
                self.translation_count += 1
                
                print(f"âš¡ [{datetime.now().strftime('%H:%M:%S')}] Batch item #{i+1} [{direction}]: '{texts[i] if i < len(texts) else ''}' â†’ '{translation}'", 
                      file=sys.stderr, flush=True)
            
            processing_time = time.time() - start_time
            
            print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] Batch translation completed in {processing_time:.3f}s - {len(translations)} translations", 
                  file=sys.stderr, flush=True)
            
            return {
                "success": True,
                "translations": translations,
                "sources": sources,
                "direction": direction,
                "processing_time": processing_time,
                "translation_count": len(translations)
            }
            
        except Exception as e:
            processing_time = time.time() - start_time
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Batch translation failed after {processing_time:.3f}s: {e}", 
                  file=sys.stderr, flush=True)
            return {
                "success": False,
                "error": str(e),
                "sources": texts,
                "processing_time": processing_time
            }
    
    def handle_client(self, client_socket, client_address):
        """
        ğŸš€ [GEMINI_FIX] ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å‡¦ç†ã«ã‚ˆã‚‹TCPã‚¹ãƒ†ã‚£ãƒƒã‚­ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å•é¡Œè§£æ±º
        """
        print(f"ğŸ”— [{datetime.now().strftime('%H:%M:%S')}] Client connected from {client_address}", 
              file=sys.stderr, flush=True)
        
        buffer = ""  # ğŸš€ [GEMINI_FIX] ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å¤‰æ•°è¿½åŠ 
        try:
            while self.running:
                print(f"ğŸ“¡ [{datetime.now().strftime('%H:%M:%S')}] [BUFFERING] Waiting for client data...", 
                      file=sys.stderr, flush=True)
                
                # ğŸš€ [GEMINI_FIX] recv()ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                raw_data = client_socket.recv(4096)
                if not raw_data:
                    print(f"âš ï¸ [{datetime.now().strftime('%H:%M:%S')}] [BUFFERING] Empty data received - client disconnected", 
                          file=sys.stderr, flush=True)
                    break
                
                buffer += raw_data.decode('utf-8')
                
                print(f"ğŸ“¨ [{datetime.now().strftime('%H:%M:%S')}] [BUFFERING] Buffer length: {len(buffer)} chars", 
                      file=sys.stderr, flush=True)
                print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [BUFFERING] Buffer preview: {repr(buffer[:200])}", 
                      file=sys.stderr, flush=True)
                
                # ğŸš€ [GEMINI_FIX] ãƒãƒƒãƒ•ã‚¡å†…ã®æ”¹è¡Œã‚’å‡¦ç†ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ‡ã‚Šå‡ºã™
                while '\n' in buffer:
                    # æœ€åˆã®æ”¹è¡Œã¾ã§ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦åˆ‡ã‚Šå‡ºã™
                    message, buffer = buffer.split('\n', 1)
                    
                    if not message.strip():
                        continue  # ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã‚¹ã‚­ãƒƒãƒ—
                    
                    print(f"âœ‚ï¸ [{datetime.now().strftime('%H:%M:%S')}] [BUFFERING] Extracted message: {repr(message[:100])}", 
                          file=sys.stderr, flush=True)
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
                    self.process_message(message.strip(), client_socket)
                    
        except ConnectionResetError:
            print(f"ğŸ’¥ [{datetime.now().strftime('%H:%M:%S')}] Client closed connection abruptly", 
                  file=sys.stderr, flush=True)
        except Exception as e:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Client handling error: {e}", 
                  file=sys.stderr, flush=True)
        finally:
            client_socket.close()
            print(f"ğŸ”— [{datetime.now().strftime('%H:%M:%S')}] Client {client_address} disconnected", 
                  file=sys.stderr, flush=True)
    
    def process_message(self, data, client_socket):
        """
        ğŸš€ [GEMINI_FIX] å€‹åˆ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ï¼ˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã‹ã‚‰åˆ†é›¢ï¼‰
        """
        print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Processing message: {repr(data[:100])}", 
              file=sys.stderr, flush=True)
        
        # ç‰¹æ®Šã‚³ãƒãƒ³ãƒ‰å‡¦ç†
        if data == "PING":
            print(f"ğŸ“ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] PING command received", 
                  file=sys.stderr, flush=True)
            response = {"status": "alive", "uptime_seconds": (datetime.now() - self.start_time).total_seconds(), 
                       "translation_count": self.translation_count}
            client_socket.send((json.dumps(response, ensure_ascii=False) + "\n").encode('utf-8'))
            return
            
        elif data == "SHUTDOWN":
            print(f"ğŸ›‘ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] SHUTDOWN command received", 
                  file=sys.stderr, flush=True)
            self.running = False
            response = {"status": "shutting_down"}
            client_socket.send((json.dumps(response, ensure_ascii=False) + "\n").encode('utf-8'))
            return
        
        # ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†
        try:
            print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Attempting JSON parse...", 
                  file=sys.stderr, flush=True)
            
            request = json.loads(data)
            
            print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] JSON parse successful: {type(request)}", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ” [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Request keys: {list(request.keys())}", 
                  file=sys.stderr, flush=True)
            
            # ãƒãƒƒãƒç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ãƒã‚§ãƒƒã‚¯
            if "batch_texts" in request:
                texts = request.get("batch_texts", [])
                direction = request.get("direction", "ja-en")  # ğŸ”„ è¨€èªæ–¹å‘æƒ…å ±å–å¾—
                
                print(f"ğŸ“¦ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Batch request detected: {len(texts)} texts, direction={direction}", 
                      file=sys.stderr, flush=True)
                
                if not texts or not any(text.strip() for text in texts):
                    print(f"âš ï¸ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Empty batch texts detected", 
                          file=sys.stderr, flush=True)
                    response = {"success": False, "error": "Empty batch texts"}
                else:
                    print(f"ğŸš€ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Starting batch translation...", 
                          file=sys.stderr, flush=True)
                    response = self.translate_batch(texts, direction)
                    print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Batch translation completed: success={response.get('success', False)}", 
                          file=sys.stderr, flush=True)
            
            # å˜ä¸€ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            else:
                text = request.get("text", "")
                direction = request.get("direction", "ja-en")  # ğŸ”„ è¨€èªæ–¹å‘æƒ…å ±å–å¾—
                
                if not text:
                    response = {"success": False, "error": "Empty text"}
                else:
                    # æ”¹è¡Œæ–‡å­—ã‚’å«ã‚€å ´åˆã¯ãƒãƒƒãƒå‡¦ç†ã§å¯¾å¿œ
                    if "\n" in text:
                        # æ”¹è¡Œã§åˆ†å‰²ã—ã€ç©ºè¡Œã‚’é™¤å»
                        text_lines = [line.strip() for line in text.split("\n") if line.strip()]
                        
                        if not text_lines:
                            response = {"success": False, "error": "Empty text after splitting"}
                        elif len(text_lines) == 1:
                            # å®Ÿéš›ã¯1è¡Œã ã£ãŸå ´åˆã¯é€šå¸¸ç¿»è¨³
                            response = self.translate(text_lines[0], direction)
                        else:
                            # è¤‡æ•°è¡Œã®å ´åˆã¯ãƒãƒƒãƒç¿»è¨³ã—ã¦çµåˆ
                            print(f"ğŸ“„ [{datetime.now().strftime('%H:%M:%S')}] Multi-line text detected - splitting into {len(text_lines)} lines", 
                                  file=sys.stderr, flush=True)
                            batch_result = self.translate_batch(text_lines, direction)
                            
                            if batch_result["success"]:
                                # ãƒãƒƒãƒçµæœã‚’æ”¹è¡Œã§çµåˆ
                                combined_translation = "\n".join(batch_result["translations"])
                                response = {
                                    "success": True,
                                    "translation": combined_translation,
                                    "source": text,
                                    "processing_time": batch_result["processing_time"],
                                    "translation_count": batch_result["translation_count"],
                                    "split_lines": len(text_lines)  # ãƒ‡ãƒãƒƒã‚°ç”¨
                                }
                            else:
                                response = batch_result
                    else:
                        # æ”¹è¡Œãªã—ã®é€šå¸¸ç¿»è¨³
                        response = self.translate(text, direction)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€ä¿¡
            print(f"ğŸ“¤ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Preparing response...", 
                  file=sys.stderr, flush=True)
            
            response_json = json.dumps(response, ensure_ascii=False) + "\n"
            response_bytes = response_json.encode('utf-8')
            
            print(f"ğŸ“ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Response size: {len(response_bytes)} bytes", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ“„ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Response preview: {response_json[:200]}...", 
                  file=sys.stderr, flush=True)
            
            print(f"ğŸš€ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Sending response...", 
                  file=sys.stderr, flush=True)
            
            client_socket.send(response_bytes)
            
            print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Response sent successfully", 
                  file=sys.stderr, flush=True)
            
        except json.JSONDecodeError as e:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] JSON decode error: {str(e)}", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ“„ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Problem data: {repr(data)}", 
                  file=sys.stderr, flush=True)
            
            error_response = {"success": False, "error": f"Invalid JSON: {str(e)}"}
            error_json = json.dumps(error_response, ensure_ascii=False) + "\n"
            client_socket.send(error_json.encode('utf-8'))
            
            print(f"ğŸ“¤ [{datetime.now().strftime('%H:%M:%S')}] [MESSAGE_PROC] Error response sent", 
                  file=sys.stderr, flush=True)
    
    def start_server(self):
        """
        TCP socketã‚µãƒ¼ãƒãƒ¼é–‹å§‹
        """
        try:
            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.server_socket.bind((SERVER_HOST, SERVER_PORT))
            self.server_socket.listen(5)
            self.running = True
            
            print(f"ğŸš€ [{datetime.now().strftime('%H:%M:%S')}] OPUS-MT Persistent Server started on {SERVER_HOST}:{SERVER_PORT}", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ“Š [{datetime.now().strftime('%H:%M:%S')}] Server status: Model loaded, ready for high-speed translation", 
                  file=sys.stderr, flush=True)
            
            while self.running:
                try:
                    client_socket, client_address = self.server_socket.accept()
                    client_thread = threading.Thread(
                        target=self.handle_client, 
                        args=(client_socket, client_address),
                        daemon=True
                    )
                    client_thread.start()
                except Exception as e:
                    if self.running:  # ã‚µãƒ¼ãƒãƒ¼ãŒå®Ÿè¡Œä¸­ã®å ´åˆã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
                        print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Accept error: {e}", 
                              file=sys.stderr, flush=True)
                    
        except Exception as e:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Server startup failed: {e}", 
                  file=sys.stderr, flush=True)
            return False
        finally:
            self.cleanup()
        
        return True
    
    def cleanup(self):
        """
        ã‚µãƒ¼ãƒãƒ¼çµ‚äº†å‡¦ç†
        """
        self.running = False
        if self.server_socket:
            self.server_socket.close()
        print(f"ğŸ›‘ [{datetime.now().strftime('%H:%M:%S')}] Server stopped. Total translations: {self.translation_count}", 
              file=sys.stderr, flush=True)

def main():
    """
    å¸¸é§ã‚µãƒ¼ãƒãƒ¼ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
    """
    # Windowsç’°å¢ƒã§UTF-8å‡ºåŠ›ã‚’å¼·åˆ¶
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)
    
    print(f"ğŸ¯ [{datetime.now().strftime('%H:%M:%S')}] Baketa OPUS-MT Persistent Server starting...", 
          file=sys.stderr, flush=True)
    
    server = PersistentOpusMtServer()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    if not server.initialize_models():
        print(f"ğŸ’¥ [{datetime.now().strftime('%H:%M:%S')}] Failed to initialize model. Exiting.", 
              file=sys.stderr, flush=True)
        sys.exit(1)
    
    # ã‚µãƒ¼ãƒãƒ¼é–‹å§‹
    try:
        server.start_server()
    except KeyboardInterrupt:
        print(f"\nğŸ›‘ [{datetime.now().strftime('%H:%M:%S')}] Server interrupted by user", 
              file=sys.stderr, flush=True)
    except Exception as e:
        print(f"ğŸ’¥ [{datetime.now().strftime('%H:%M:%S')}] Server crashed: {e}", 
              file=sys.stderr, flush=True)
        print(f"ğŸ“„ Traceback:\n{traceback.format_exc()}", file=sys.stderr, flush=True)
        sys.exit(1)

if __name__ == "__main__":
    main()