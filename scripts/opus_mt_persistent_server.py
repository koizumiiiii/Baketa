#!/usr/bin/env python3
"""
Baketa OPUS-MT Persistent Translation Server
å¸¸é§å‹é«˜é€Ÿç¿»è¨³ã‚µãƒ¼ãƒãƒ¼ - ãƒ¢ãƒ‡ãƒ«åˆå›ãƒ­ãƒ¼ãƒ‰å¾Œã¯0.1-0.5ç§’ã§ç¿»è¨³å®Ÿè¡Œ
"""

import sys
import json
import os
import warnings
import socket
import threading
import time
from datetime import datetime
import traceback

# è­¦å‘Šã‚’æŠ‘åˆ¶ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
warnings.filterwarnings("ignore", category=UserWarning)
os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # tokenizerã®ä¸¦åˆ—å‡¦ç†ã‚’ç„¡åŠ¹åŒ–

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, logging
import torch

# transformersã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã‚‹
logging.set_verbosity_error()

MODEL_ID = "Helsinki-NLP/opus-mt-ja-en"
SERVER_HOST = "127.0.0.1"
SERVER_PORT = 29876  # Baketaå°‚ç”¨ãƒãƒ¼ãƒˆ

class PersistentOpusMtServer:
    """
    OPUS-MTå¸¸é§ç¿»è¨³ã‚µãƒ¼ãƒãƒ¼
    - 1å›ã®ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã§é«˜é€Ÿç¿»è¨³ã‚’ç¶™ç¶šæä¾›
    - TCP Socketé€šä¿¡ã§C#ã¨é€£æº
    - ãƒ—ãƒ­ã‚»ã‚¹æ­»æ´»ç›£è¦–å¯¾å¿œ
    """
    
    def __init__(self):
        self.tokenizer = None
        self.model = None
        self.initialized = False
        self.server_socket = None
        self.running = False
        self.translation_count = 0
        self.start_time = datetime.now()
        
    def initialize_model(self):
        """
        HuggingFace Transformersã§ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆ1å›ã®ã¿å®Ÿè¡Œï¼‰
        """
        try:
            print(f"ğŸ”„ [{datetime.now().strftime('%H:%M:%S')}] Loading tokenizer for {MODEL_ID}...", 
                  file=sys.stderr, flush=True)
            self.tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, local_files_only=False)
            
            print(f"ğŸ”„ [{datetime.now().strftime('%H:%M:%S')}] Loading model for {MODEL_ID}...", 
                  file=sys.stderr, flush=True)
            self.model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_ID, local_files_only=False)
            
            print(f"âœ… [{datetime.now().strftime('%H:%M:%S')}] Model initialization complete! Ready for high-speed translation.", 
                  file=sys.stderr, flush=True)
            self.initialized = True
            return True
        except Exception as e:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Model initialization failed: {e}", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ“„ Traceback:\n{traceback.format_exc()}", file=sys.stderr, flush=True)
            return False
    
    def translate(self, japanese_text):
        """
        æ—¥æœ¬èªâ†’è‹±èªç¿»è¨³ï¼ˆé«˜é€Ÿå®Ÿè¡Œï¼š0.1-0.5ç§’ç›®æ¨™ï¼‰
        """
        if not self.initialized:
            return {"success": False, "error": "Service not initialized"}
        
        start_time = time.time()
        
        try:
            # HuggingFace Transformersæ¨™æº–å‡¦ç†
            inputs = self.tokenizer(japanese_text, return_tensors="pt")
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=128,
                    num_beams=3,
                    length_penalty=1.0,
                    early_stopping=True
                )
            
            translation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            processing_time = time.time() - start_time
            self.translation_count += 1
            
            print(f"âš¡ [{datetime.now().strftime('%H:%M:%S')}] Translation #{self.translation_count} completed in {processing_time:.3f}s: '{japanese_text}' â†’ '{translation}'", 
                  file=sys.stderr, flush=True)
            
            return {
                "success": True,
                "translation": translation,
                "source": japanese_text,
                "processing_time": processing_time,
                "translation_count": self.translation_count
            }
            
        except Exception as e:
            processing_time = time.time() - start_time
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Translation failed after {processing_time:.3f}s: {e}", 
                  file=sys.stderr, flush=True)
            return {
                "success": False,
                "error": str(e),
                "source": japanese_text,
                "processing_time": processing_time
            }
    
    def handle_client(self, client_socket, client_address):
        """
        ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šå‡¦ç†
        """
        print(f"ğŸ”— [{datetime.now().strftime('%H:%M:%S')}] Client connected from {client_address}", 
              file=sys.stderr, flush=True)
        
        try:
            while self.running:
                # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚ŠJSONï¼‰
                data = client_socket.recv(4096).decode('utf-8').strip()
                if not data:
                    break
                
                # ç‰¹æ®Šã‚³ãƒãƒ³ãƒ‰å‡¦ç†
                if data == "PING":
                    response = {"status": "alive", "uptime_seconds": (datetime.now() - self.start_time).total_seconds(), 
                               "translation_count": self.translation_count}
                    client_socket.send((json.dumps(response, ensure_ascii=False) + "\n").encode('utf-8'))
                    continue
                elif data == "SHUTDOWN":
                    self.running = False
                    response = {"status": "shutting_down"}
                    client_socket.send((json.dumps(response, ensure_ascii=False) + "\n").encode('utf-8'))
                    break
                
                # ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†
                try:
                    request = json.loads(data)
                    japanese_text = request.get("text", "")
                    
                    if not japanese_text:
                        response = {"success": False, "error": "Empty text"}
                    else:
                        response = self.translate(japanese_text)
                    
                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€ä¿¡
                    response_json = json.dumps(response, ensure_ascii=False) + "\n"
                    client_socket.send(response_json.encode('utf-8'))
                    
                except json.JSONDecodeError as e:
                    error_response = {"success": False, "error": f"Invalid JSON: {str(e)}"}
                    client_socket.send((json.dumps(error_response, ensure_ascii=False) + "\n").encode('utf-8'))
                
        except Exception as e:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Client handling error: {e}", 
                  file=sys.stderr, flush=True)
        finally:
            client_socket.close()
            print(f"ğŸ”— [{datetime.now().strftime('%H:%M:%S')}] Client {client_address} disconnected", 
                  file=sys.stderr, flush=True)
    
    def start_server(self):
        """
        TCP socketã‚µãƒ¼ãƒãƒ¼é–‹å§‹
        """
        try:
            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.server_socket.bind((SERVER_HOST, SERVER_PORT))
            self.server_socket.listen(5)
            self.running = True
            
            print(f"ğŸš€ [{datetime.now().strftime('%H:%M:%S')}] OPUS-MT Persistent Server started on {SERVER_HOST}:{SERVER_PORT}", 
                  file=sys.stderr, flush=True)
            print(f"ğŸ“Š [{datetime.now().strftime('%H:%M:%S')}] Server status: Model loaded, ready for high-speed translation", 
                  file=sys.stderr, flush=True)
            
            while self.running:
                try:
                    client_socket, client_address = self.server_socket.accept()
                    client_thread = threading.Thread(
                        target=self.handle_client, 
                        args=(client_socket, client_address),
                        daemon=True
                    )
                    client_thread.start()
                except Exception as e:
                    if self.running:  # ã‚µãƒ¼ãƒãƒ¼ãŒå®Ÿè¡Œä¸­ã®å ´åˆã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
                        print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Accept error: {e}", 
                              file=sys.stderr, flush=True)
                    
        except Exception as e:
            print(f"âŒ [{datetime.now().strftime('%H:%M:%S')}] Server startup failed: {e}", 
                  file=sys.stderr, flush=True)
            return False
        finally:
            self.cleanup()
        
        return True
    
    def cleanup(self):
        """
        ã‚µãƒ¼ãƒãƒ¼çµ‚äº†å‡¦ç†
        """
        self.running = False
        if self.server_socket:
            self.server_socket.close()
        print(f"ğŸ›‘ [{datetime.now().strftime('%H:%M:%S')}] Server stopped. Total translations: {self.translation_count}", 
              file=sys.stderr, flush=True)

def main():
    """
    å¸¸é§ã‚µãƒ¼ãƒãƒ¼ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
    """
    # Windowsç’°å¢ƒã§UTF-8å‡ºåŠ›ã‚’å¼·åˆ¶
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)
    
    print(f"ğŸ¯ [{datetime.now().strftime('%H:%M:%S')}] Baketa OPUS-MT Persistent Server starting...", 
          file=sys.stderr, flush=True)
    
    server = PersistentOpusMtServer()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    if not server.initialize_model():
        print(f"ğŸ’¥ [{datetime.now().strftime('%H:%M:%S')}] Failed to initialize model. Exiting.", 
              file=sys.stderr, flush=True)
        sys.exit(1)
    
    # ã‚µãƒ¼ãƒãƒ¼é–‹å§‹
    try:
        server.start_server()
    except KeyboardInterrupt:
        print(f"\nğŸ›‘ [{datetime.now().strftime('%H:%M:%S')}] Server interrupted by user", 
              file=sys.stderr, flush=True)
    except Exception as e:
        print(f"ğŸ’¥ [{datetime.now().strftime('%H:%M:%S')}] Server crashed: {e}", 
              file=sys.stderr, flush=True)
        print(f"ğŸ“„ Traceback:\n{traceback.format_exc()}", file=sys.stderr, flush=True)
        sys.exit(1)

if __name__ == "__main__":
    main()