#!/usr/bin/env python3
"""
SentencePiece Golden Data Verification Script

C# Nativeãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®å®Ÿè£…ã‚’Python SentencePieceãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨æ¯”è¼ƒæ¤œè¨¼ã™ã‚‹
"""

import sys
import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
import unicodedata

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” SentencePiece Implementation Verification")
    print("=" * 60)
    
    # SentencePieceãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
    try:
        import sentencepiece as ssp
        print(f"âœ“ SentencePiece library found: version {ssp.__version__}")
    except ImportError:
        print("âœ— SentencePiece library not found")
        print("Installing SentencePiece...")
        import subprocess
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "sentencepiece"])
            import sentencepiece as ssp
            print(f"âœ“ SentencePiece installed: version {ssp.__version__}")
        except Exception as e:
            print(f"âœ— Failed to install SentencePiece: {e}")
            return 1
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆç¢ºèª
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    print(f"ğŸ“‚ Project root: {project_root}")
    
    # åŸºæœ¬çš„ãªæ­£è¦åŒ–ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {"id": "basic_en", "text": "Hello World", "category": "basic"},
        {"id": "basic_ja", "text": "ã“ã‚“ã«ã¡ã¯", "category": "basic"},
        {"id": "unicode_fullwidth", "text": "ï½ˆï½…ï½Œï½Œï½", "category": "unicode"},
        {"id": "unicode_mixed", "text": "ï¼¨ï½…ï½Œï½Œï½ä¸–ç•Œ", "category": "unicode"},
        {"id": "control_tab", "text": "hello\tworld", "category": "control"},
        {"id": "multiple_spaces", "text": "hello   world", "category": "whitespace"},
        {"id": "empty_string", "text": "", "category": "boundary"},
    ]
    
    print("\nğŸ§ª Testing basic normalization cases...")
    
    results = []
    for test_case in test_cases:
        text = test_case["text"]
        
        # Pythonæ¨™æº–ã®NFKCæ­£è¦åŒ–ã‚’é©ç”¨
        try:
            normalized = unicodedata.normalize('NFKC', text)
            
            # SentencePieceé¢¨ã®åŸºæœ¬å‡¦ç†
            # åˆ¶å¾¡æ–‡å­—ã®å‡¦ç†
            filtered = ""
            for char in normalized:
                if unicodedata.category(char).startswith('C'):
                    if char in ['\t', '\n', '\r']:
                        filtered += ' '
                    # ãã®ä»–ã®åˆ¶å¾¡æ–‡å­—ã¯é™¤å»
                else:
                    filtered += char
            
            # è¤‡æ•°ç©ºç™½ã‚’å˜ä¸€ã«
            import re
            whitespace_normalized = re.sub(r'\s+', ' ', filtered).strip()
            
            # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚¹ãƒšãƒ¼ã‚¹è¨˜å·ã®ä»˜ä¸
            if whitespace_normalized:
                final_result = '\u2581' + whitespace_normalized.replace(' ', '\u2581')
            else:
                final_result = ''
            
            result = {
                "test_case_id": test_case["id"],
                "category": test_case["category"],
                "input": text,
                "expected_normalized": final_result,
                "steps": {
                    "nfkc": normalized,
                    "control_filtered": filtered,
                    "whitespace_normalized": whitespace_normalized,
                    "final": final_result
                }
            }
            results.append(result)
            
            print(f"  âœ“ {test_case['id']}: '{text}' -> '{final_result}'")
            
        except Exception as e:
            print(f"  âœ— {test_case['id']}: Error - {e}")
            continue
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_dir = project_root / "tests" / "test_data"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_file = output_dir / "normalization_verification.json"
    
    output_data = {
        "generated_by": "Python verification script",
        "test_cases": results,
        "statistics": {
            "total_cases": len(results),
            "categories": list(set(r["category"] for r in results))
        }
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ Verification data saved to: {output_file}")
    print(f"ğŸ“Š Total test cases: {len(results)}")
    print(f"ğŸ“‹ Categories: {', '.join(output_data['statistics']['categories'])}")
    
    print("\nâœ… Basic verification completed!")
    print("\nNext steps:")
    print("  1. Run C# tests with: dotnet test --filter SentencePieceNormalizerTests")
    print("  2. Compare C# results with expected normalized values")
    print("  3. Analyze any discrepancies")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())