#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‹•çš„ãƒãƒ¼ãƒˆå¯¾å¿œç¿»è¨³ã‚µãƒ¼ãƒãƒ¼
Issue #147 Phase 5: ãƒãƒ¼ãƒˆç«¶åˆé˜²æ­¢æ©Ÿæ§‹

æ—¢å­˜ã®optimized_translation_server.pyã‚’ãƒ™ãƒ¼ã‚¹ã«å‹•çš„ãƒãƒ¼ãƒˆå¯¾å¿œã‚’è¿½åŠ 
"""

import argparse
import asyncio
import json
import logging
import socket
import sys
import time
import traceback
from typing import Dict, Optional, Any, List

import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, MarianMTModel, MarianTokenizer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('translation_server.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class DynamicPortTranslationServer:
    """å‹•çš„ãƒãƒ¼ãƒˆå¯¾å¿œç¿»è¨³ã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, port: int = 5555, language_pair: str = "ja-en"):
        self.port = port
        self.language_pair = language_pair
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.models: Dict[str, tuple] = {}
        self.server_socket: Optional[socket.socket] = None
        self.is_running = False
        
        logger.info(f"ğŸš€ DynamicPortTranslationServeråˆæœŸåŒ–")
        logger.info(f"   Port: {port}")
        logger.info(f"   Language Pair: {language_pair}")
        logger.info(f"   Device: {self.device}")
        
    async def initialize_models(self):
        """ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
        try:
            logger.info("ğŸ”„ ç¿»è¨³ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–é–‹å§‹")
            
            # æŒ‡å®šã•ã‚ŒãŸè¨€èªãƒšã‚¢ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
            if self.language_pair == "ja-en":
                await self._load_ja_en_model()
            elif self.language_pair == "en-ja":
                await self._load_en_ja_model()
            else:
                logger.warning(f"âš ï¸ æœªå¯¾å¿œã®è¨€èªãƒšã‚¢: {self.language_pair}. ja-enãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™")
                await self._load_ja_en_model()
                
            logger.info("âœ… ç¿»è¨³ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    async def _load_ja_en_model(self):
        """æ—¥æœ¬èªâ†’è‹±èªãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            model_name = "Helsinki-NLP/opus-mt-ja-en"
            logger.info(f"ğŸ”„ æ—¥æœ¬èªâ†’è‹±èªãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {model_name}")
            
            tokenizer = MarianTokenizer.from_pretrained(model_name)
            model = MarianMTModel.from_pretrained(model_name).to(self.device)
            model.eval()
            
            self.models["ja-en"] = (model, tokenizer)
            logger.info("âœ… æ—¥æœ¬èªâ†’è‹±èªãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ æ—¥æœ¬èªâ†’è‹±èªãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            raise
    
    async def _load_en_ja_model(self):
        """è‹±èªâ†’æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆNLLB-200ä½¿ç”¨ï¼‰"""
        try:
            # Phase 4ã§å®Ÿè£…ã•ã‚ŒãŸNLLB-200ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            model_name = "facebook/nllb-200-distilled-600M"
            logger.info(f"ğŸ”„ è‹±èªâ†’æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ï¼ˆNLLB-200ï¼‰ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {model_name}")
            
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(self.device)
            model.eval()
            
            self.models["en-ja"] = (model, tokenizer)
            logger.info("âœ… è‹±èªâ†’æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ï¼ˆNLLB-200ï¼‰ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ è‹±èªâ†’æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ï¼ˆNLLB-200ï¼‰ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Helsinki-NLPãƒ¢ãƒ‡ãƒ«ï¼ˆæ±šæŸ“å•é¡Œã‚ã‚Šï¼‰
            try:
                model_name_fallback = "Helsinki-NLP/opus-mt-en-jap"
                logger.warning(f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {model_name_fallback}ã‚’è©¦è¡Œï¼ˆæ±šæŸ“ãƒªã‚¹ã‚¯ã‚ã‚Šï¼‰")
                
                tokenizer = MarianTokenizer.from_pretrained(model_name_fallback)
                model = MarianMTModel.from_pretrained(model_name_fallback).to(self.device)
                model.eval()
                
                self.models["en-ja"] = (model, tokenizer)
                logger.warning("âš ï¸ è‹±èªâ†’æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ï¼ˆHelsinki-NLPï¼‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†")
                
            except Exception as fallback_error:
                logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚‚å¤±æ•—: {fallback_error}")
                raise
    
    async def start_server(self):
        """ã‚µãƒ¼ãƒãƒ¼é–‹å§‹"""
        try:
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            await self.initialize_models()
            
            # ã‚½ã‚±ãƒƒãƒˆä½œæˆãƒ»ãƒã‚¤ãƒ³ãƒ‰
            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.server_socket.bind(('127.0.0.1', self.port))
            self.server_socket.listen(5)
            self.server_socket.setblocking(False)
            
            self.is_running = True
            
            logger.info(f"ğŸŒŸ ç¿»è¨³ã‚µãƒ¼ãƒãƒ¼èµ·å‹•å®Œäº†")
            logger.info(f"   Address: 127.0.0.1:{self.port}")
            logger.info(f"   Language Pair: {self.language_pair}")
            logger.info(f"   Models Loaded: {list(self.models.keys())}")
            
            # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šå¾…æ©Ÿ
            while self.is_running:
                try:
                    # éåŒæœŸã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šã‚’å¾…æ©Ÿ
                    client_socket, client_addr = await asyncio.get_event_loop().sock_accept(self.server_socket)
                    
                    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‡¦ç†ã‚’éåŒæœŸã§å®Ÿè¡Œ
                    asyncio.create_task(self._handle_client(client_socket, client_addr))
                    
                except asyncio.CancelledError:
                    logger.info("ğŸ“´ ã‚µãƒ¼ãƒãƒ¼åœæ­¢è¦æ±‚ã‚’å—ä¿¡")
                    break
                except Exception as e:
                    logger.error(f"âŒ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                    await asyncio.sleep(0.1)
                    
        except Exception as e:
            logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
            raise
        finally:
            await self._cleanup()
    
    async def _handle_client(self, client_socket: socket.socket, client_addr):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‡¦ç†"""
        try:
            logger.debug(f"ğŸ”— ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š: {client_addr}")
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡
            client_socket.settimeout(30.0)  # 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            
            # ãƒ‡ãƒ¼ã‚¿å—ä¿¡ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰
            data = b""
            while b'\n' not in data:
                chunk = client_socket.recv(4096)
                if not chunk:
                    break
                data += chunk
            
            if not data:
                logger.warning(f"âš ï¸ ç©ºã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {client_addr}")
                return
            
            # JSONè§£æ
            request_text = data.decode('utf-8').strip()
            request = json.loads(request_text)
            
            # ç¿»è¨³å‡¦ç†
            response = await self._process_translation_request(request)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€ä¿¡
            response_json = json.dumps(response, ensure_ascii=False)
            client_socket.sendall(response_json.encode('utf-8'))
            
            logger.debug(f"âœ… ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‡¦ç†å®Œäº†: {client_addr}")
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            error_response = {"success": False, "error": "Invalid JSON format"}
            client_socket.sendall(json.dumps(error_response).encode('utf-8'))
            
        except Exception as e:
            logger.error(f"âŒ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            error_response = {"success": False, "error": str(e)}
            try:
                client_socket.sendall(json.dumps(error_response).encode('utf-8'))
            except:
                pass
        finally:
            try:
                client_socket.close()
            except:
                pass
    
    async def _process_translation_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        start_time = time.time()
        
        try:
            text = request.get("text", "")
            source_lang = request.get("source_lang", "ja")
            target_lang = request.get("target_lang", "en")
            
            if not text.strip():
                return {
                    "success": False,
                    "error": "Empty text provided",
                    "processing_time": time.time() - start_time
                }
            
            # è¨€èªãƒšã‚¢æ±ºå®š
            lang_pair = f"{source_lang}-{target_lang}"
            
            # ãƒ¢ãƒ‡ãƒ«é¸æŠ
            if lang_pair in self.models:
                model, tokenizer = self.models[lang_pair]
            elif lang_pair == "en-ja" and "en-ja" in self.models:
                model, tokenizer = self.models["en-ja"]
            elif lang_pair == "ja-en" and "ja-en" in self.models:
                model, tokenizer = self.models["ja-en"]
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åˆ©ç”¨å¯èƒ½ãªæœ€åˆã®ãƒ¢ãƒ‡ãƒ«
                if self.models:
                    model, tokenizer = next(iter(self.models.values()))
                    logger.warning(f"âš ï¸ è¨€èªãƒšã‚¢ {lang_pair} æœªå¯¾å¿œã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨")
                else:
                    return {
                        "success": False,
                        "error": f"No model available for language pair: {lang_pair}",
                        "processing_time": time.time() - start_time
                    }
            
            # ç¿»è¨³å®Ÿè¡Œ
            translation = await self._translate_text(text, model, tokenizer, source_lang, target_lang)
            
            processing_time = time.time() - start_time
            
            return {
                "success": True,
                "translation": translation,
                "processing_time": processing_time,
                "language_pair": lang_pair,
                "model_info": {
                    "device": self.device,
                    "server_port": self.port
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ç¿»è¨³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e),
                "processing_time": time.time() - start_time
            }
    
    async def _translate_text(self, text: str, model, tokenizer, source_lang: str, target_lang: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³å®Ÿè¡Œ"""
        try:
            # NLLB-200ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã®è¨€èªã‚³ãƒ¼ãƒ‰å¤‰æ›
            if "nllb" in str(type(model)).lower():
                # BCP-47è¨€èªã‚³ãƒ¼ãƒ‰ã¸ã®å¤‰æ›
                lang_code_map = {
                    "en": "eng_Latn",
                    "ja": "jpn_Jpan"
                }
                src_code = lang_code_map.get(source_lang, source_lang)
                
                # NLLB-200ç”¨ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
                inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # å¼·åˆ¶è¨€èªIDè¨­å®š
                forced_bos_token_id = tokenizer.lang_code_to_id.get(lang_code_map.get(target_lang, target_lang))
                
                with torch.no_grad():
                    outputs = model.generate(
                        **inputs,
                        forced_bos_token_id=forced_bos_token_id,
                        max_length=512,
                        num_beams=4,
                        early_stopping=True
                    )
                
                translation = tokenizer.decode(outputs[0], skip_special_tokens=True)
                
            else:
                # Helsinki-NLP OPUS-MTãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
                inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                with torch.no_grad():
                    outputs = model.generate(
                        **inputs,
                        max_length=512,
                        num_beams=4,
                        early_stopping=True
                    )
                
                translation = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            return translation.strip()
            
        except Exception as e:
            logger.error(f"âŒ ç¿»è¨³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    async def _cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.info("ğŸ§¹ ã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
        
        self.is_running = False
        
        if self.server_socket:
            try:
                self.server_socket.close()
            except Exception as e:
                logger.warning(f"âš ï¸ ã‚µãƒ¼ãƒãƒ¼ã‚½ã‚±ãƒƒãƒˆã‚¯ãƒ­ãƒ¼ã‚ºã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒ¢ãƒªè§£æ”¾
        for lang_pair, (model, tokenizer) in self.models.items():
            try:
                del model
                del tokenizer
                logger.debug(f"ğŸ§¹ {lang_pair}ãƒ¢ãƒ‡ãƒ«è§£æ”¾å®Œäº†")
            except Exception as e:
                logger.warning(f"âš ï¸ {lang_pair}ãƒ¢ãƒ‡ãƒ«è§£æ”¾ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.models.clear()
        
        # GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            logger.debug("ğŸ§¹ GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢å®Œäº†")
        
        logger.info("âœ… ã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

def parse_arguments():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è§£æ"""
    parser = argparse.ArgumentParser(description="Dynamic Port Translation Server")
    parser.add_argument("--port", type=int, default=5555, 
                       help="Server port (default: 5555)")
    parser.add_argument("--language-pair", type=str, default="ja-en",
                       choices=["ja-en", "en-ja"],
                       help="Language pair (default: ja-en)")
    parser.add_argument("--log-level", type=str, default="INFO",
                       choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                       help="Log level (default: INFO)")
    
    return parser.parse_args()

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        args = parse_arguments()
        
        # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
        logging.getLogger().setLevel(getattr(logging, args.log_level))
        
        logger.info("ğŸš€ Dynamic Port Translation Server èµ·å‹•")
        logger.info(f"   Port: {args.port}")
        logger.info(f"   Language Pair: {args.language_pair}")
        logger.info(f"   Log Level: {args.log_level}")
        
        # ã‚µãƒ¼ãƒãƒ¼ä½œæˆãƒ»èµ·å‹•
        server = DynamicPortTranslationServer(
            port=args.port,
            language_pair=args.language_pair
        )
        
        await server.start_server()
        
    except KeyboardInterrupt:
        logger.info("ğŸ“´ Ctrl+C ã«ã‚ˆã‚‹åœæ­¢è¦æ±‚")
    except Exception as e:
        logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"âŒ ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:\n{traceback.format_exc()}")
        sys.exit(1)
    finally:
        logger.info("ğŸ‘‹ Dynamic Port Translation Server çµ‚äº†")

if __name__ == "__main__":
    asyncio.run(main())