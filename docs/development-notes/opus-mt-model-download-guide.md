# OPUS-MT SentencePieceãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¬ã‚¤ãƒ‰

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€å®Ÿéš›ã®OPUS-MT SentencePieceãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦Baketaãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ“‹ æ¦‚è¦

OPUS-MTãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€Helsinki-NLPã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚ŒãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®æ©Ÿæ¢°ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯Hugging Faceãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§é…å¸ƒã•ã‚Œã¦ãŠã‚Šã€SentencePieceãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚

## ğŸ¯ å¿…è¦ãªãƒ¢ãƒ‡ãƒ«

Baketaãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ãŒæ¨å¥¨ã•ã‚Œã¾ã™ï¼š

### åŸºæœ¬è¨€èªãƒšã‚¢
1. **æ—¥æœ¬èª â†’ è‹±èª**: `Helsinki-NLP/opus-mt-ja-en`
2. **è‹±èª â†’ æ—¥æœ¬èª**: `Helsinki-NLP/opus-mt-en-jap`

### æ‹¡å¼µè¨€èªãƒšã‚¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
3. **ä¸­å›½èª(ç°¡ä½“å­—) â†’ è‹±èª**: `Helsinki-NLP/opus-mt-zh-en`
4. **è‹±èª â†’ ä¸­å›½èª(ç°¡ä½“å­—)**: `Helsinki-NLP/opus-mt-en-zh`

## ğŸ”§ å–å¾—æ–¹æ³•

### æ–¹æ³•1: Hugging Face Hub CLIä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰

```bash
# Hugging Face Hub CLIã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install huggingface_hub

# æ—¥æœ¬èªâ†’è‹±èªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
huggingface-cli download Helsinki-NLP/opus-mt-ja-en --include="*.model" --cache-dir ./models --local-dir ./Models/SentencePiece

# è‹±èªâ†’æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
huggingface-cli download Helsinki-NLP/opus-mt-en-jap --include="*.model" --cache-dir ./models --local-dir ./Models/SentencePiece
```

### æ–¹æ³•2: Python transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨

```python
from transformers import AutoTokenizer
import shutil
import os

def download_sentencepiece_model(model_name, output_dir):
    """OPUS-MTãƒ¢ãƒ‡ãƒ«ã‹ã‚‰SentencePieceãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡º"""
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰SentencePieceãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    cache_dir = tokenizer.name_or_path
    if os.path.exists(cache_dir):
        for file in os.listdir(cache_dir):
            if file.endswith('.model'):
                source_path = os.path.join(cache_dir, file)
                dest_path = os.path.join(output_dir, f"{model_name.replace('/', '-')}.model")
                shutil.copy2(source_path, dest_path)
                print(f"ã‚³ãƒ”ãƒ¼å®Œäº†: {dest_path}")
                return dest_path
    
    # ä»£æ›¿æ–¹æ³•: tokenizer.save_pretrained()ã‚’ä½¿ç”¨
    temp_dir = f"./temp_{model_name.replace('/', '-')}"
    tokenizer.save_pretrained(temp_dir)
    
    for file in os.listdir(temp_dir):
        if file.endswith('.model'):
            source_path = os.path.join(temp_dir, file)
            dest_path = os.path.join(output_dir, f"{model_name.replace('/', '-')}.model")
            shutil.copy2(source_path, dest_path)
            print(f"ã‚³ãƒ”ãƒ¼å®Œäº†: {dest_path}")
            
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
            shutil.rmtree(temp_dir)
            return dest_path
    
    raise FileNotFoundError(f"SentencePieceãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_name}")

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    os.makedirs("./Models/SentencePiece", exist_ok=True)
    
    models = [
        "Helsinki-NLP/opus-mt-ja-en",
        "Helsinki-NLP/opus-mt-en-jap",
    ]
    
    for model in models:
        try:
            path = download_sentencepiece_model(model, "./Models/SentencePiece")
            print(f"âœ… {model} â†’ {path}")
        except Exception as e:
            print(f"âŒ {model}: {e}")
```

### æ–¹æ³•3: ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

ä»¥ä¸‹ã®URLã‹ã‚‰ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼š

```bash
# æ—¥æœ¬èªâ†’è‹±èªãƒ¢ãƒ‡ãƒ«
curl -L "https://huggingface.co/Helsinki-NLP/opus-mt-ja-en/resolve/main/source.spm" -o "./Models/SentencePiece/opus-mt-ja-en.model"

# è‹±èªâ†’æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«
curl -L "https://huggingface.co/Helsinki-NLP/opus-mt-en-jap/resolve/main/source.spm" -o "./Models/SentencePiece/opus-mt-en-jap.model"
```

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®

ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸSentencePieceãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„ï¼š

```
E:\dev\Baketa\Models\SentencePiece\
â”œâ”€â”€ opus-mt-ja-en.model      # æ—¥æœ¬èªâ†’è‹±èª
â”œâ”€â”€ opus-mt-en-jap.model     # è‹±èªâ†’æ—¥æœ¬èª
â”œâ”€â”€ opus-mt-zh-en.model      # ä¸­å›½èªâ†’è‹±èªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
â””â”€â”€ opus-mt-en-zh.model      # è‹±èªâ†’ä¸­å›½èªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```

## âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°

`appsettings.json`ã§ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’è¡Œã„ã¾ã™ï¼š

```json
{
  "SentencePiece": {
    "ModelsDirectory": "Models/SentencePiece",
    "DefaultModel": "opus-mt-ja-en",
    "DownloadUrl": "https://huggingface.co/Helsinki-NLP/{0}/resolve/main/source.spm",
    "ModelCacheDays": 30,
    "MaxDownloadRetries": 3,
    "DownloadTimeoutMinutes": 5,
    "EnableChecksumValidation": false,
    "EnableAutoCleanup": true,
    "CleanupThresholdDays": 90
  }
}
```

## ğŸ” ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼

ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´åˆæ€§ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼š

```python
import os
import hashlib

def verify_model_file(file_path):
    """SentencePieceãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬æ¤œè¨¼"""
    
    if not os.path.exists(file_path):
        return False, "ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    size = os.path.getsize(file_path)
    if size < 1000:  # 1KBæœªæº€ã¯ç•°å¸¸
        return False, f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã¾ã™: {size} bytes"
    
    # ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆSentencePieceã¯é€šå¸¸ãƒã‚¤ãƒŠãƒªï¼‰
    try:
        with open(file_path, 'rb') as f:
            header = f.read(16)
            # SentencePieceãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯é€šå¸¸ãƒã‚¤ãƒŠãƒª
            if header.startswith(b'#') or header.startswith(b'trainer_spec'):
                return False, "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ˆã†ã§ã™ï¼ˆãƒã‚¤ãƒŠãƒªã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰"
    except Exception as e:
        return False, f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"
    
    return True, f"æ¤œè¨¼æˆåŠŸ (ã‚µã‚¤ã‚º: {size:,} bytes)"

# æ¤œè¨¼å®Ÿè¡Œ
model_dir = "./Models/SentencePiece"
for file_name in os.listdir(model_dir):
    if file_name.endswith('.model'):
        file_path = os.path.join(model_dir, file_name)
        is_valid, message = verify_model_file(file_path)
        status = "âœ…" if is_valid else "âŒ"
        print(f"{status} {file_name}: {message}")
```

## ğŸš€ è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Baketaãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ã®çµ±åˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼š

```bash
#!/bin/bash
# download_opus_models.sh

set -e

# è¨­å®š
MODELS_DIR="./Models/SentencePiece"
MODELS=(
    "Helsinki-NLP/opus-mt-ja-en"
    "Helsinki-NLP/opus-mt-en-jap"
)

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p "$MODELS_DIR"

echo "ğŸš€ OPUS-MT SentencePieceãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹"

# å„ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
for model in "${MODELS[@]}"; do
    echo "ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: $model"
    
    # ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    filename=$(echo "$model" | sed 's|Helsinki-NLP/||' | sed 's|/|-|g')
    output_path="$MODELS_DIR/${filename}.model"
    
    # Hugging Face Hub CLIã‚’ä½¿ç”¨
    if command -v huggingface-cli &> /dev/null; then
        huggingface-cli download "$model" source.spm --cache-dir ./temp --local-dir ./temp
        mv "./temp/source.spm" "$output_path"
        rm -rf ./temp
    else
        # curlã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        url="https://huggingface.co/$model/resolve/main/source.spm"
        curl -L "$url" -o "$output_path"
    fi
    
    if [ -f "$output_path" ]; then
        size=$(stat -f%z "$output_path" 2>/dev/null || stat -c%s "$output_path")
        echo "âœ… å®Œäº†: $output_path (${size} bytes)"
    else
        echo "âŒ å¤±æ•—: $model"
    fi
done

echo "ğŸ‰ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†"
echo "ğŸ“ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: $MODELS_DIR"
ls -la "$MODELS_DIR"
```

## ğŸ“ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

1. **ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„**
   ```
   ã‚¨ãƒ©ãƒ¼: SentencePieceãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“
   è§£æ±º: ãƒ•ã‚¡ã‚¤ãƒ«åã¨ãƒ‘ã‚¹ã‚’ç¢ºèªã€‚source.spmã‚’*.modelã«ãƒªãƒãƒ¼ãƒ 
   ```

2. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã™ã‚‹**
   ```
   ã‚¨ãƒ©ãƒ¼: HTTP 404 ã¾ãŸã¯æ¥ç¶šã‚¨ãƒ©ãƒ¼
   è§£æ±º: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šç¢ºèªã€URLã®ç¢ºèªã€ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
   ```

3. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒç•°å¸¸**
   ```
   ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹ï¼ˆHTMLã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ãªã©ï¼‰
   è§£æ±º: ç›´æ¥ãƒ–ãƒ©ã‚¦ã‚¶ã§URLã‚’ç¢ºèªã€èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹
   ```

4. **ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã‚ãªã„**
   ```
   ã‚¨ãƒ©ãƒ¼: Microsoft.ML.Tokenizersã§èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼
   è§£æ±º: ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ç¢ºèªã€ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
   ```

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- [OPUS-MT Project](https://github.com/Helsinki-NLP/Opus-MT)
- [Helsinki-NLP Models on Hugging Face](https://huggingface.co/Helsinki-NLP)
- [SentencePiece Documentation](https://github.com/google/sentencepiece)
- [Microsoft.ML.Tokenizers Documentation](https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.tokenizers)

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

OPUS-MTãƒ¢ãƒ‡ãƒ«ã¯**CC-BY 4.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**ã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚å•†ç”¨åˆ©ç”¨å¯èƒ½ã§ã™ãŒã€é©åˆ‡ãªã‚¯ãƒ¬ã‚¸ãƒƒãƒˆè¡¨è¨˜ãŒå¿…è¦ã§ã™ã€‚

```
OPUS-MT models by Helsinki-NLP
Licensed under CC-BY 4.0
https://github.com/Helsinki-NLP/Opus-MT
```
